{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyyN-2qyK_T2"
      },
      "source": [
        "# Hyperparameter tuning with Optuna\n",
        "\n",
        "Github repo: https://github.com/araffin/tools-for-robotic-rl-icra2022\n",
        "\n",
        "Optuna: https://github.com/optuna/optuna\n",
        "\n",
        "Stable-Baselines3: https://github.com/DLR-RM/stable-baselines3\n",
        "\n",
        "Documentation: https://stable-baselines3.readthedocs.io/en/master/\n",
        "\n",
        "SB3 Contrib: https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\n",
        "\n",
        "RL Baselines3 zoo: https://github.com/DLR-RM/rl-baselines3-zoo\n",
        "\n",
        "[RL Baselines3 Zoo](https://github.com/DLR-RM/rl-baselines3-zoo) is a collection of pre-trained Reinforcement Learning agents using Stable-Baselines3.\n",
        "\n",
        "It also provides basic scripts for training, evaluating agents, tuning hyperparameters and recording videos.\n",
        "\n",
        "\n",
        "## Introduction\n",
        "\n",
        "In this notebook, you will learn the importance of tuning hyperparameters. You will first try to optimize the parameters manually and then we will see how to automate the search using Optuna.\n",
        "\n",
        "\n",
        "## Install Dependencies and Stable Baselines3 Using Pip\n",
        "\n",
        "List of full dependencies can be found in the [README](https://github.com/DLR-RM/stable-baselines3).\n",
        "\n",
        "\n",
        "```\n",
        "pip install stable-baselines3[extra]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hYdv2ygjLaFL",
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74b29ddd-8f70-4e8a-a4fe-55574376459c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting stable-baselines3\n",
            "  Downloading stable_baselines3-1.5.0-py3-none-any.whl (177 kB)\n",
            "\u001b[K     |████████████████████████████████| 177 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from stable-baselines3) (1.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable-baselines3) (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable-baselines3) (1.21.6)\n",
            "Collecting gym==0.21\n",
            "  Downloading gym-0.21.0.tar.gz (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 52.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable-baselines3) (3.2.2)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3) (1.11.0+cu113)\n",
            "Requirement already satisfied: importlib_metadata>=4.8.1 in /usr/local/lib/python3.7/dist-packages (from gym==0.21->stable-baselines3) (4.11.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib_metadata>=4.8.1->gym==0.21->stable-baselines3) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib_metadata>=4.8.1->gym==0.21->stable-baselines3) (3.8.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3) (1.4.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->stable-baselines3) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->stable-baselines3) (2022.1)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616826 sha256=061130aa21f51d6194f0c367cba80a8029d2dadf7c3524cc379a3de0f2e9482c\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/ee/9c/36bfe3e079df99acf5ae57f4e3464ff2771b34447d6d2f2148\n",
            "Successfully built gym\n",
            "Installing collected packages: gym, stable-baselines3\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.17.3\n",
            "    Uninstalling gym-0.17.3:\n",
            "      Successfully uninstalled gym-0.17.3\n",
            "Successfully installed gym-0.21.0 stable-baselines3-1.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install stable-baselines3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oexj67yWN5_k",
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d118d607-0545-4537-da50-b1b1aebff0ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sb3-contrib\n",
            "  Downloading sb3_contrib-1.5.0-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 937 kB/s \n",
            "\u001b[?25hRequirement already satisfied: stable-baselines3>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from sb3-contrib) (1.5.0)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3>=1.5.0->sb3-contrib) (1.11.0+cu113)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable-baselines3>=1.5.0->sb3-contrib) (1.3.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable-baselines3>=1.5.0->sb3-contrib) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable-baselines3>=1.5.0->sb3-contrib) (1.21.6)\n",
            "Requirement already satisfied: gym==0.21 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3>=1.5.0->sb3-contrib) (0.21.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from stable-baselines3>=1.5.0->sb3-contrib) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.1 in /usr/local/lib/python3.7/dist-packages (from gym==0.21->stable-baselines3>=1.5.0->sb3-contrib) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.1->gym==0.21->stable-baselines3>=1.5.0->sb3-contrib) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.1->gym==0.21->stable-baselines3>=1.5.0->sb3-contrib) (4.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3>=1.5.0->sb3-contrib) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3>=1.5.0->sb3-contrib) (1.4.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3>=1.5.0->sb3-contrib) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3>=1.5.0->sb3-contrib) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->stable-baselines3>=1.5.0->sb3-contrib) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->stable-baselines3>=1.5.0->sb3-contrib) (2022.1)\n",
            "Installing collected packages: sb3-contrib\n",
            "Successfully installed sb3-contrib-1.5.0\n"
          ]
        }
      ],
      "source": [
        "# Optional: install SB3 contrib to have access to additional algorithms\n",
        "!pip install sb3-contrib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NNah91r9x9EL",
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6229956-4b60-4034-e50e-c9123cc62d9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-2.10.1-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.37)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.8.0-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 58.2 MB/s \n",
            "\u001b[?25hCollecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 8.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.4)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.7.1)\n",
            "Collecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.1-py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 69.7 MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.9.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 52.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.3.0)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 7.7 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (4.1.1)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=c1a79cb79845ab8e63618a97acf0e6406540db71212cdae649350055dac540e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.2.0 alembic-1.8.0 autopage-0.5.1 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.1 colorlog-6.6.0 optuna-2.10.1 pbr-5.9.0 pyperclip-1.8.2 stevedore-3.5.0\n"
          ]
        }
      ],
      "source": [
        "# Optuna will be used in the last part when doing hyperparameter tuning\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtY8FhliLsGm"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BIedd7Pz9sOs",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ae32CtgzTG3R"
      },
      "source": [
        "The first thing you need to import is the RL model, check the documentation to know what you can use on which problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "R7tKaBFrTR0a",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from stable_baselines3 import PPO, A2C, SAC, TD3, DQN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EcsXmYRMON9W",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Algorithms from the contrib repo\n",
        "# https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\n",
        "from sb3_contrib import QRDQN, TQC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kLwjcfvuqtGE",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.evaluation import evaluate_policy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-khNkrgcI6Z1"
      },
      "source": [
        "# Part I: The Importance Of Tuned Hyperparameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PytOtL9GdmrE"
      },
      "source": [
        "When compared with Supervised Learning, Deep Reinforcement Learning is far more sensitive to the choice of hyper-parameters such as learning rate, number of neurons, number of layers, optimizer ... etc. \n",
        "\n",
        "Poor choice of hyper-parameters can lead to poor/unstable convergence. This challenge is compounded by the variability in performance across random seeds (used to initialize the network weights and the environment)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hk8HSIC3qUjc"
      },
      "source": [
        "In addition to hyperparameters, selecting the appropriate algorithm is also an important choice. We will demonstrate it on the simple Pendulum task.\n",
        "\n",
        "See [gym doc](https://gym.openai.com/envs/Pendulum-v0/): \"The inverted pendulum swingup problem is a classic problem in the control literature. In this version  of the problem, the pendulum starts in a random position, and the goal is to swing it up so it stays upright.\"\n",
        "\n",
        "\n",
        "Let's try first with PPO and a small budget of 4000 steps (20 episodes):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4ToIvihGq2N0",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "env_id = \"Pendulum-v1\"\n",
        "# Env used only for evaluation\n",
        "eval_envs = make_vec_env(env_id, n_envs=10)\n",
        "# 4000 training timesteps\n",
        "budget_pendulum = 4000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWT2r6QE4yew"
      },
      "source": [
        "### PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KCHk_-_4ndux",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "ppo_model = PPO(\"MlpPolicy\", env_id, seed=0, verbose=0).learn(budget_pendulum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP9C9AqLndxz",
        "outputId": "53df66ca-1d77-4fc1-c4a9-baba53c3cd52",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PPO Mean episode reward: -1146.56 +/- 288.72\n"
          ]
        }
      ],
      "source": [
        "mean_reward, std_reward = evaluate_policy(ppo_model, eval_envs, n_eval_episodes=100, deterministic=True)\n",
        "\n",
        "print(f\"PPO Mean episode reward: {mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHmJaJLl5ds4"
      },
      "source": [
        "### A2C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BLL_pws25jh0",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Define and train a A2C model\n",
        "a2c_model = A2C(\"MlpPolicy\", env_id, seed=0, verbose=0).learn(budget_pendulum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ic83jZwB5nVk",
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a510824f-67e9-4aaa-f3b0-8081b8f16495"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A2C Mean episode reward: -1508.75 +/- 227.82\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the train A2C model\n",
        "mean_reward, std_reward = evaluate_policy(a2c_model, eval_envs, n_eval_episodes=100, deterministic=True)\n",
        "\n",
        "print(f\"A2C Mean episode reward: {mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_z1zFx2rVpG"
      },
      "source": [
        "Both are far from solving the env (mean reward around -200).\n",
        "Now, let's try with an off-policy algorithm:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wYaVZJU5VL5"
      },
      "source": [
        "### Training longer PPO ?\n",
        "\n",
        "Maybe training longer would help?\n",
        "\n",
        "You can try with 10x the budget, but in the case of A2C/PPO, training longer won't help much, finding better hyperparameters is needed instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "hHsHpnQY6TWA",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# train longer\n",
        "new_budget = 10 * budget_pendulum\n",
        "\n",
        "ppo_model = PPO(\"MlpPolicy\", env_id, seed=0, verbose=0).learn(new_budget)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "7OD9y1o36Xta",
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ff4ae1b-0dc9-44bb-d22b-24462536a7e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PPO Mean episode reward: -1123.23 +/- 240.16\n"
          ]
        }
      ],
      "source": [
        "mean_reward, std_reward = evaluate_policy(ppo_model, eval_envs, n_eval_episodes=100, deterministic=True)\n",
        "\n",
        "print(f\"PPO Mean episode reward: {mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEvQ9SJ15Xmh"
      },
      "source": [
        "### PPO - Tuned Hyperparameters\n",
        "\n",
        "Using Optuna, we can in fact tune the hyperparameters and find a working solution (from the [RL Zoo](https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/hyperparams/ppo.yml)):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "S-D_vvsb6jOZ",
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02b31082-21f6-4735-89a1-b58ef8eae11f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Creating environment from the given name 'Pendulum-v1'\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -1.21e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 905         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 11          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.027510857 |\n",
            "|    clip_fraction        | 0.267       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.65       |\n",
            "|    explained_variance   | 0.82        |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 11.1        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0242     |\n",
            "|    std                  | 0.926       |\n",
            "|    value_loss           | 37.1        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -1.04e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 897         |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 22          |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.028516037 |\n",
            "|    clip_fraction        | 0.211       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.26       |\n",
            "|    explained_variance   | 0.971       |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 4.86        |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.0325     |\n",
            "|    std                  | 0.468       |\n",
            "|    value_loss           | 11.8        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -623        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 907         |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 33          |\n",
            "|    total_timesteps      | 30720       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.033041876 |\n",
            "|    clip_fraction        | 0.206       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.56       |\n",
            "|    explained_variance   | 0.992       |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 1.22        |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.0154     |\n",
            "|    std                  | 0.273       |\n",
            "|    value_loss           | 2.45        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 200        |\n",
            "|    ep_rew_mean          | -315       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 915        |\n",
            "|    iterations           | 20         |\n",
            "|    time_elapsed         | 44         |\n",
            "|    total_timesteps      | 40960      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.06547433 |\n",
            "|    clip_fraction        | 0.255      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.19      |\n",
            "|    explained_variance   | 0.994      |\n",
            "|    learning_rate        | 0.001      |\n",
            "|    loss                 | 0.125      |\n",
            "|    n_updates            | 190        |\n",
            "|    policy_gradient_loss | -0.0235    |\n",
            "|    std                  | 0.204      |\n",
            "|    value_loss           | 1.63       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 200        |\n",
            "|    ep_rew_mean          | -234       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 913        |\n",
            "|    iterations           | 25         |\n",
            "|    time_elapsed         | 56         |\n",
            "|    total_timesteps      | 51200      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.10626703 |\n",
            "|    clip_fraction        | 0.271      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.977     |\n",
            "|    explained_variance   | 0.999      |\n",
            "|    learning_rate        | 0.001      |\n",
            "|    loss                 | 0.0436     |\n",
            "|    n_updates            | 240        |\n",
            "|    policy_gradient_loss | -0.0111    |\n",
            "|    std                  | 0.174      |\n",
            "|    value_loss           | 0.179      |\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "tuned_params = {\n",
        "    \"gamma\": 0.9,\n",
        "    \"use_sde\": True,\n",
        "    \"sde_sample_freq\": 4,\n",
        "    \"learning_rate\": 1e-3,\n",
        "}\n",
        "\n",
        "# budget = 10 * budget_pendulum\n",
        "ppo_tuned_model = PPO(\"MlpPolicy\", env_id, seed=1, verbose=1, **tuned_params).learn(50_000, log_interval=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLuxoLxt67xO",
        "outputId": "06b97e7c-3ed5-40be-eaaf-1eef82bcf752",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuned PPO Mean episode reward: -209.50 +/- 178.61\n"
          ]
        }
      ],
      "source": [
        "mean_reward, std_reward = evaluate_policy(ppo_tuned_model, eval_envs, n_eval_episodes=100, deterministic=True)\n",
        "\n",
        "print(f\"Tuned PPO Mean episode reward: {mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H33u_apWPp5"
      },
      "source": [
        "Note: if you try SAC on the simple MountainCarContinuous environment, you will encounter some issues without tuned hyperparameters: https://github.com/rail-berkeley/softlearning/issues/76\n",
        "\n",
        "Simple environments can be challenging even for SOTA algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vdpPJ04nebx"
      },
      "source": [
        "# Part II: Grad Student Descent\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8PNN9kcgolk"
      },
      "source": [
        "### Challenge (10 minutes): \"Grad Student Descent\" \n",
        "The challenge is to find the best hyperparameters (max performance) for A2C on `CartPole-v1` with a limited budget of 20 000 training steps.\n",
        "\n",
        "\n",
        "Maximum reward: 500 on `CartPole-v1`\n",
        "\n",
        "The hyperparameters should work for different random seeds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "s6aqxsini7H3",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "budget = 20_000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDQ805DBi3KM"
      },
      "source": [
        "#### The baseline: default hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "pyOCKf4Vt-HK",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "eval_envs_cartpole = make_vec_env(\"CartPole-v1\", n_envs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "D1PSNGcsi2dP",
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aa09882-fb3b-4849-ec24-68f8d4989d5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Creating environment from the given name 'CartPole-v1'\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 10.9     |\n",
            "|    ep_rew_mean        | 10.9     |\n",
            "| time/                 |          |\n",
            "|    fps                | 952      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 0        |\n",
            "|    total_timesteps    | 500      |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.325   |\n",
            "|    explained_variance | 0.495    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 99       |\n",
            "|    policy_loss        | 0.311    |\n",
            "|    value_loss         | 4.87     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 10.8     |\n",
            "|    ep_rew_mean        | 10.8     |\n",
            "| time/                 |          |\n",
            "|    fps                | 947      |\n",
            "|    iterations         | 200      |\n",
            "|    time_elapsed       | 1        |\n",
            "|    total_timesteps    | 1000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.201   |\n",
            "|    explained_variance | 0.934    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 199      |\n",
            "|    policy_loss        | -0.0195  |\n",
            "|    value_loss         | 0.194    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 12.8     |\n",
            "|    ep_rew_mean        | 12.8     |\n",
            "| time/                 |          |\n",
            "|    fps                | 963      |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 1        |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.692   |\n",
            "|    explained_variance | 0.22     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | 1.39     |\n",
            "|    value_loss         | 4.92     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 15.5     |\n",
            "|    ep_rew_mean        | 15.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 974      |\n",
            "|    iterations         | 400      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 2000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.676   |\n",
            "|    explained_variance | 0.00158  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | 1.79     |\n",
            "|    value_loss         | 7.42     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 18.8     |\n",
            "|    ep_rew_mean        | 18.8     |\n",
            "| time/                 |          |\n",
            "|    fps                | 971      |\n",
            "|    iterations         | 500      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 2500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.677   |\n",
            "|    explained_variance | -0.0782  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 499      |\n",
            "|    policy_loss        | 1.24     |\n",
            "|    value_loss         | 6.24     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 22.5     |\n",
            "|    ep_rew_mean        | 22.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 965      |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 3000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.544   |\n",
            "|    explained_variance | 0.00921  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | 1.4      |\n",
            "|    value_loss         | 5.73     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 25.7     |\n",
            "|    ep_rew_mean        | 25.7     |\n",
            "| time/                 |          |\n",
            "|    fps                | 971      |\n",
            "|    iterations         | 700      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 3500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.664   |\n",
            "|    explained_variance | -0.00296 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 699      |\n",
            "|    policy_loss        | 1.1      |\n",
            "|    value_loss         | 5.09     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 30.7     |\n",
            "|    ep_rew_mean        | 30.7     |\n",
            "| time/                 |          |\n",
            "|    fps                | 972      |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 4000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.625   |\n",
            "|    explained_variance | -0.0546  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | 1.11     |\n",
            "|    value_loss         | 4.45     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 34.6     |\n",
            "|    ep_rew_mean        | 34.6     |\n",
            "| time/                 |          |\n",
            "|    fps                | 974      |\n",
            "|    iterations         | 900      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 4500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.56    |\n",
            "|    explained_variance | 0.000962 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 899      |\n",
            "|    policy_loss        | 1.15     |\n",
            "|    value_loss         | 3.9      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 38.4     |\n",
            "|    ep_rew_mean        | 38.4     |\n",
            "| time/                 |          |\n",
            "|    fps                | 969      |\n",
            "|    iterations         | 1000     |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 5000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.68    |\n",
            "|    explained_variance | 0.00128  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | 0.954    |\n",
            "|    value_loss         | 3.37     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 44.5     |\n",
            "|    ep_rew_mean        | 44.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 970      |\n",
            "|    iterations         | 1100     |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 5500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.583   |\n",
            "|    explained_variance | 0.00281  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1099     |\n",
            "|    policy_loss        | 1.01     |\n",
            "|    value_loss         | 2.9      |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 49.1      |\n",
            "|    ep_rew_mean        | 49.1      |\n",
            "| time/                 |           |\n",
            "|    fps                | 970       |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 6         |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.61     |\n",
            "|    explained_variance | -0.000983 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | 0.785     |\n",
            "|    value_loss         | 2.44      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 52.7     |\n",
            "|    ep_rew_mean        | 52.7     |\n",
            "| time/                 |          |\n",
            "|    fps                | 972      |\n",
            "|    iterations         | 1300     |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 6500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.556   |\n",
            "|    explained_variance | -0.00225 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1299     |\n",
            "|    policy_loss        | 0.434    |\n",
            "|    value_loss         | 2.02     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 57.9     |\n",
            "|    ep_rew_mean        | 57.9     |\n",
            "| time/                 |          |\n",
            "|    fps                | 974      |\n",
            "|    iterations         | 1400     |\n",
            "|    time_elapsed       | 7        |\n",
            "|    total_timesteps    | 7000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.548   |\n",
            "|    explained_variance | 0.000208 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1399     |\n",
            "|    policy_loss        | 0.432    |\n",
            "|    value_loss         | 1.64     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 62.1     |\n",
            "|    ep_rew_mean        | 62.1     |\n",
            "| time/                 |          |\n",
            "|    fps                | 976      |\n",
            "|    iterations         | 1500     |\n",
            "|    time_elapsed       | 7        |\n",
            "|    total_timesteps    | 7500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.569   |\n",
            "|    explained_variance | 1.32e-05 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1499     |\n",
            "|    policy_loss        | 0.539    |\n",
            "|    value_loss         | 1.31     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 66.1     |\n",
            "|    ep_rew_mean        | 66.1     |\n",
            "| time/                 |          |\n",
            "|    fps                | 976      |\n",
            "|    iterations         | 1600     |\n",
            "|    time_elapsed       | 8        |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.463   |\n",
            "|    explained_variance | 0.000142 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1599     |\n",
            "|    policy_loss        | 0.328    |\n",
            "|    value_loss         | 1.02     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 70.5     |\n",
            "|    ep_rew_mean        | 70.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 978      |\n",
            "|    iterations         | 1700     |\n",
            "|    time_elapsed       | 8        |\n",
            "|    total_timesteps    | 8500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.564   |\n",
            "|    explained_variance | 6.02e-06 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1699     |\n",
            "|    policy_loss        | 0.239    |\n",
            "|    value_loss         | 0.761    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 75.1     |\n",
            "|    ep_rew_mean        | 75.1     |\n",
            "| time/                 |          |\n",
            "|    fps                | 980      |\n",
            "|    iterations         | 1800     |\n",
            "|    time_elapsed       | 9        |\n",
            "|    total_timesteps    | 9000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.624   |\n",
            "|    explained_variance | 0.000309 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | 0.249    |\n",
            "|    value_loss         | 0.532    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 79.3     |\n",
            "|    ep_rew_mean        | 79.3     |\n",
            "| time/                 |          |\n",
            "|    fps                | 980      |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 9        |\n",
            "|    total_timesteps    | 9500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.539   |\n",
            "|    explained_variance | 8.34e-06 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | 0.221    |\n",
            "|    value_loss         | 0.351    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 83       |\n",
            "|    ep_rew_mean        | 83       |\n",
            "| time/                 |          |\n",
            "|    fps                | 979      |\n",
            "|    iterations         | 2000     |\n",
            "|    time_elapsed       | 10       |\n",
            "|    total_timesteps    | 10000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.401   |\n",
            "|    explained_variance | 3.38e-05 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1999     |\n",
            "|    policy_loss        | 0.207    |\n",
            "|    value_loss         | 0.207    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 87.5     |\n",
            "|    ep_rew_mean        | 87.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 974      |\n",
            "|    iterations         | 2100     |\n",
            "|    time_elapsed       | 10       |\n",
            "|    total_timesteps    | 10500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.315   |\n",
            "|    explained_variance | 0.000259 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2099     |\n",
            "|    policy_loss        | 0.244    |\n",
            "|    value_loss         | 0.0992   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 91.7     |\n",
            "|    ep_rew_mean        | 91.7     |\n",
            "| time/                 |          |\n",
            "|    fps                | 977      |\n",
            "|    iterations         | 2200     |\n",
            "|    time_elapsed       | 11       |\n",
            "|    total_timesteps    | 11000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.547   |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2199     |\n",
            "|    policy_loss        | 0.0704   |\n",
            "|    value_loss         | 0.0296   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 96.3     |\n",
            "|    ep_rew_mean        | 96.3     |\n",
            "| time/                 |          |\n",
            "|    fps                | 975      |\n",
            "|    iterations         | 2300     |\n",
            "|    time_elapsed       | 11       |\n",
            "|    total_timesteps    | 11500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.221   |\n",
            "|    explained_variance | 0.000258 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2299     |\n",
            "|    policy_loss        | 0.0556   |\n",
            "|    value_loss         | 0.00158  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 99.4     |\n",
            "|    ep_rew_mean        | 99.4     |\n",
            "| time/                 |          |\n",
            "|    fps                | 975      |\n",
            "|    iterations         | 2400     |\n",
            "|    time_elapsed       | 12       |\n",
            "|    total_timesteps    | 12000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.509   |\n",
            "|    explained_variance | 6.97e-06 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2399     |\n",
            "|    policy_loss        | 0.00111  |\n",
            "|    value_loss         | 7.51e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 104      |\n",
            "|    ep_rew_mean        | 104      |\n",
            "| time/                 |          |\n",
            "|    fps                | 974      |\n",
            "|    iterations         | 2500     |\n",
            "|    time_elapsed       | 12       |\n",
            "|    total_timesteps    | 12500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.51    |\n",
            "|    explained_variance | 7.88e-05 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2499     |\n",
            "|    policy_loss        | 0.000217 |\n",
            "|    value_loss         | 1.02e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 110      |\n",
            "|    ep_rew_mean        | 110      |\n",
            "| time/                 |          |\n",
            "|    fps                | 976      |\n",
            "|    iterations         | 2600     |\n",
            "|    time_elapsed       | 13       |\n",
            "|    total_timesteps    | 13000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.416   |\n",
            "|    explained_variance | 0.00564  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2599     |\n",
            "|    policy_loss        | 0.00159  |\n",
            "|    value_loss         | 2.94e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 113      |\n",
            "|    ep_rew_mean        | 113      |\n",
            "| time/                 |          |\n",
            "|    fps                | 975      |\n",
            "|    iterations         | 2700     |\n",
            "|    time_elapsed       | 13       |\n",
            "|    total_timesteps    | 13500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.528   |\n",
            "|    explained_variance | 1.08e-05 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2699     |\n",
            "|    policy_loss        | 0.000396 |\n",
            "|    value_loss         | 1.18e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 117      |\n",
            "|    ep_rew_mean        | 117      |\n",
            "| time/                 |          |\n",
            "|    fps                | 976      |\n",
            "|    iterations         | 2800     |\n",
            "|    time_elapsed       | 14       |\n",
            "|    total_timesteps    | 14000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.481   |\n",
            "|    explained_variance | 0.000593 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2799     |\n",
            "|    policy_loss        | 5.18e-05 |\n",
            "|    value_loss         | 2.24e-08 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 119      |\n",
            "|    ep_rew_mean        | 119      |\n",
            "| time/                 |          |\n",
            "|    fps                | 976      |\n",
            "|    iterations         | 2900     |\n",
            "|    time_elapsed       | 14       |\n",
            "|    total_timesteps    | 14500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.552   |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2899     |\n",
            "|    policy_loss        | -0       |\n",
            "|    value_loss         | 0        |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 127      |\n",
            "|    ep_rew_mean        | 127      |\n",
            "| time/                 |          |\n",
            "|    fps                | 978      |\n",
            "|    iterations         | 3000     |\n",
            "|    time_elapsed       | 15       |\n",
            "|    total_timesteps    | 15000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.538   |\n",
            "|    explained_variance | 0.0356   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2999     |\n",
            "|    policy_loss        | 8.35e-05 |\n",
            "|    value_loss         | 1.13e-07 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 131      |\n",
            "|    ep_rew_mean        | 131      |\n",
            "| time/                 |          |\n",
            "|    fps                | 978      |\n",
            "|    iterations         | 3100     |\n",
            "|    time_elapsed       | 15       |\n",
            "|    total_timesteps    | 15500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.519   |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3099     |\n",
            "|    policy_loss        | 1.2e-05  |\n",
            "|    value_loss         | 6.4e-10  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 136      |\n",
            "|    ep_rew_mean        | 136      |\n",
            "| time/                 |          |\n",
            "|    fps                | 979      |\n",
            "|    iterations         | 3200     |\n",
            "|    time_elapsed       | 16       |\n",
            "|    total_timesteps    | 16000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.495   |\n",
            "|    explained_variance | 0.0312   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3199     |\n",
            "|    policy_loss        | 9.83e-05 |\n",
            "|    value_loss         | 4.17e-08 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 140      |\n",
            "|    ep_rew_mean        | 140      |\n",
            "| time/                 |          |\n",
            "|    fps                | 980      |\n",
            "|    iterations         | 3300     |\n",
            "|    time_elapsed       | 16       |\n",
            "|    total_timesteps    | 16500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.573   |\n",
            "|    explained_variance | 0.399    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3299     |\n",
            "|    policy_loss        | 0.000314 |\n",
            "|    value_loss         | 1.25e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 142      |\n",
            "|    ep_rew_mean        | 142      |\n",
            "| time/                 |          |\n",
            "|    fps                | 979      |\n",
            "|    iterations         | 3400     |\n",
            "|    time_elapsed       | 17       |\n",
            "|    total_timesteps    | 17000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.417   |\n",
            "|    explained_variance | 0.065    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3399     |\n",
            "|    policy_loss        | 0.00441  |\n",
            "|    value_loss         | 4.04e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 145      |\n",
            "|    ep_rew_mean        | 145      |\n",
            "| time/                 |          |\n",
            "|    fps                | 979      |\n",
            "|    iterations         | 3500     |\n",
            "|    time_elapsed       | 17       |\n",
            "|    total_timesteps    | 17500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.49    |\n",
            "|    explained_variance | 0.0222   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3499     |\n",
            "|    policy_loss        | 0.00241  |\n",
            "|    value_loss         | 0.000122 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 146      |\n",
            "|    ep_rew_mean        | 146      |\n",
            "| time/                 |          |\n",
            "|    fps                | 977      |\n",
            "|    iterations         | 3600     |\n",
            "|    time_elapsed       | 18       |\n",
            "|    total_timesteps    | 18000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.299   |\n",
            "|    explained_variance | 0.715    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3599     |\n",
            "|    policy_loss        | -0.00324 |\n",
            "|    value_loss         | 5.01e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 143      |\n",
            "|    ep_rew_mean        | 143      |\n",
            "| time/                 |          |\n",
            "|    fps                | 978      |\n",
            "|    iterations         | 3700     |\n",
            "|    time_elapsed       | 18       |\n",
            "|    total_timesteps    | 18500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.469   |\n",
            "|    explained_variance | -33      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3699     |\n",
            "|    policy_loss        | -5.71    |\n",
            "|    value_loss         | 544      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 139      |\n",
            "|    ep_rew_mean        | 139      |\n",
            "| time/                 |          |\n",
            "|    fps                | 977      |\n",
            "|    iterations         | 3800     |\n",
            "|    time_elapsed       | 19       |\n",
            "|    total_timesteps    | 19000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.461   |\n",
            "|    explained_variance | -1.49    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3799     |\n",
            "|    policy_loss        | -1.74    |\n",
            "|    value_loss         | 61.2     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 133      |\n",
            "|    ep_rew_mean        | 133      |\n",
            "| time/                 |          |\n",
            "|    fps                | 978      |\n",
            "|    iterations         | 3900     |\n",
            "|    time_elapsed       | 19       |\n",
            "|    total_timesteps    | 19500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.516   |\n",
            "|    explained_variance | 0.0703   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3899     |\n",
            "|    policy_loss        | 0.464    |\n",
            "|    value_loss         | 4.68     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 127      |\n",
            "|    ep_rew_mean        | 127      |\n",
            "| time/                 |          |\n",
            "|    fps                | 978      |\n",
            "|    iterations         | 4000     |\n",
            "|    time_elapsed       | 20       |\n",
            "|    total_timesteps    | 20000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.424   |\n",
            "|    explained_variance | 0.923    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3999     |\n",
            "|    policy_loss        | 0.318    |\n",
            "|    value_loss         | 2.25     |\n",
            "------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = A2C(\"MlpPolicy\", \"CartPole-v1\", seed=8, verbose=1).learn(budget)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d3X0G0ng2OE",
        "outputId": "06d758b9-574e-4145-fe27-c4e437dbbddb",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_reward:113.06 +/- 78.24\n"
          ]
        }
      ],
      "source": [
        "mean_reward, std_reward = evaluate_policy(model, eval_envs_cartpole, n_eval_episodes=50, deterministic=True)\n",
        "\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-fi1-oKnUI2"
      },
      "source": [
        "**Your goal is to beat that baseline and get closer to the optimal score of 500**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvq8zizok1X_"
      },
      "source": [
        "Time to tune!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "UaqCCH4gkRH_",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "uDUfeZcyjPKS",
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68c7d8f8-a473-4e97-90fa-f8e4b0be48ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Creating environment from the given name 'CartPole-v1'\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 20.8     |\n",
            "|    ep_rew_mean        | 20.8     |\n",
            "| time/                 |          |\n",
            "|    fps                | 1007     |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 0        |\n",
            "|    total_timesteps    | 500      |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.692   |\n",
            "|    explained_variance | -28.8    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 99       |\n",
            "|    policy_loss        | -0.038   |\n",
            "|    value_loss         | 0.0113   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 22.2     |\n",
            "|    ep_rew_mean        | 22.2     |\n",
            "| time/                 |          |\n",
            "|    fps                | 1009     |\n",
            "|    iterations         | 200      |\n",
            "|    time_elapsed       | 0        |\n",
            "|    total_timesteps    | 1000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.691   |\n",
            "|    explained_variance | -0.74    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 199      |\n",
            "|    policy_loss        | -0.0296  |\n",
            "|    value_loss         | 0.00295  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 24.5     |\n",
            "|    ep_rew_mean        | 24.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 1012     |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 1        |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.68    |\n",
            "|    explained_variance | 0.842    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | -0.091   |\n",
            "|    value_loss         | 0.014    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 24.5     |\n",
            "|    ep_rew_mean        | 24.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 1010     |\n",
            "|    iterations         | 400      |\n",
            "|    time_elapsed       | 1        |\n",
            "|    total_timesteps    | 2000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.69    |\n",
            "|    explained_variance | -32.8    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | 0.0416   |\n",
            "|    value_loss         | 0.00547  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 25.4     |\n",
            "|    ep_rew_mean        | 25.4     |\n",
            "| time/                 |          |\n",
            "|    fps                | 1011     |\n",
            "|    iterations         | 500      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 2500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.688   |\n",
            "|    explained_variance | -1.78    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 499      |\n",
            "|    policy_loss        | 0.0554   |\n",
            "|    value_loss         | 0.00918  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 26.7     |\n",
            "|    ep_rew_mean        | 26.7     |\n",
            "| time/                 |          |\n",
            "|    fps                | 1004     |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 3000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.691   |\n",
            "|    explained_variance | -1.11    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | 0.0823   |\n",
            "|    value_loss         | 0.0174   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 26.3     |\n",
            "|    ep_rew_mean        | 26.3     |\n",
            "| time/                 |          |\n",
            "|    fps                | 999      |\n",
            "|    iterations         | 700      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 3500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.69    |\n",
            "|    explained_variance | -124     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 699      |\n",
            "|    policy_loss        | 0.0632   |\n",
            "|    value_loss         | 0.014    |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 25.9      |\n",
            "|    ep_rew_mean        | 25.9      |\n",
            "| time/                 |           |\n",
            "|    fps                | 1002      |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 3         |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.688    |\n",
            "|    explained_variance | -2.15     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | -0.000701 |\n",
            "|    value_loss         | 0.00092   |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 26.3     |\n",
            "|    ep_rew_mean        | 26.3     |\n",
            "| time/                 |          |\n",
            "|    fps                | 1005     |\n",
            "|    iterations         | 900      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 4500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.691   |\n",
            "|    explained_variance | -15.2    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 899      |\n",
            "|    policy_loss        | 0.0165   |\n",
            "|    value_loss         | 0.00136  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 26.4     |\n",
            "|    ep_rew_mean        | 26.4     |\n",
            "| time/                 |          |\n",
            "|    fps                | 1007     |\n",
            "|    iterations         | 1000     |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 5000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.682   |\n",
            "|    explained_variance | 0.0765   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | -1.96    |\n",
            "|    value_loss         | 7.3      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 26       |\n",
            "|    ep_rew_mean        | 26       |\n",
            "| time/                 |          |\n",
            "|    fps                | 1010     |\n",
            "|    iterations         | 1100     |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 5500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.688   |\n",
            "|    explained_variance | -4.72    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1099     |\n",
            "|    policy_loss        | 0.0594   |\n",
            "|    value_loss         | 0.0136   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 27.4     |\n",
            "|    ep_rew_mean        | 27.4     |\n",
            "| time/                 |          |\n",
            "|    fps                | 1006     |\n",
            "|    iterations         | 1200     |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 6000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.684   |\n",
            "|    explained_variance | -49.5    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1199     |\n",
            "|    policy_loss        | 0.0566   |\n",
            "|    value_loss         | 0.0123   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 28.2     |\n",
            "|    ep_rew_mean        | 28.2     |\n",
            "| time/                 |          |\n",
            "|    fps                | 1006     |\n",
            "|    iterations         | 1300     |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 6500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.693   |\n",
            "|    explained_variance | -0.0206  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1299     |\n",
            "|    policy_loss        | 0.0242   |\n",
            "|    value_loss         | 0.00163  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 28.5     |\n",
            "|    ep_rew_mean        | 28.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 1006     |\n",
            "|    iterations         | 1400     |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 7000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.691   |\n",
            "|    explained_variance | -10.9    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1399     |\n",
            "|    policy_loss        | -0.00816 |\n",
            "|    value_loss         | 0.000803 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 27.8      |\n",
            "|    ep_rew_mean        | 27.8      |\n",
            "| time/                 |           |\n",
            "|    fps                | 1007      |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 7         |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.688    |\n",
            "|    explained_variance | -2.53e+05 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | -0.0223   |\n",
            "|    value_loss         | 0.00262   |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 28.8     |\n",
            "|    ep_rew_mean        | 28.8     |\n",
            "| time/                 |          |\n",
            "|    fps                | 1007     |\n",
            "|    iterations         | 1600     |\n",
            "|    time_elapsed       | 7        |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.689   |\n",
            "|    explained_variance | -2.38    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1599     |\n",
            "|    policy_loss        | 0.036    |\n",
            "|    value_loss         | 0.00515  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 28.9     |\n",
            "|    ep_rew_mean        | 28.9     |\n",
            "| time/                 |          |\n",
            "|    fps                | 1006     |\n",
            "|    iterations         | 1700     |\n",
            "|    time_elapsed       | 8        |\n",
            "|    total_timesteps    | 8500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.692   |\n",
            "|    explained_variance | -1.46    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1699     |\n",
            "|    policy_loss        | 0.0848   |\n",
            "|    value_loss         | 0.0187   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 28.2     |\n",
            "|    ep_rew_mean        | 28.2     |\n",
            "| time/                 |          |\n",
            "|    fps                | 1008     |\n",
            "|    iterations         | 1800     |\n",
            "|    time_elapsed       | 8        |\n",
            "|    total_timesteps    | 9000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.689   |\n",
            "|    explained_variance | 0.753    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | -0.0435  |\n",
            "|    value_loss         | 0.00421  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 28.2     |\n",
            "|    ep_rew_mean        | 28.2     |\n",
            "| time/                 |          |\n",
            "|    fps                | 1007     |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 9        |\n",
            "|    total_timesteps    | 9500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.68    |\n",
            "|    explained_variance | 0.207    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | -0.886   |\n",
            "|    value_loss         | 3.97     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 27.4     |\n",
            "|    ep_rew_mean        | 27.4     |\n",
            "| time/                 |          |\n",
            "|    fps                | 1006     |\n",
            "|    iterations         | 2000     |\n",
            "|    time_elapsed       | 9        |\n",
            "|    total_timesteps    | 10000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.69    |\n",
            "|    explained_variance | -0.509   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1999     |\n",
            "|    policy_loss        | 0.00516  |\n",
            "|    value_loss         | 0.00114  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 27.8     |\n",
            "|    ep_rew_mean        | 27.8     |\n",
            "| time/                 |          |\n",
            "|    fps                | 1002     |\n",
            "|    iterations         | 2100     |\n",
            "|    time_elapsed       | 10       |\n",
            "|    total_timesteps    | 10500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.691   |\n",
            "|    explained_variance | 0.369    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2099     |\n",
            "|    policy_loss        | 0.0071   |\n",
            "|    value_loss         | 0.000636 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 27.4     |\n",
            "|    ep_rew_mean        | 27.4     |\n",
            "| time/                 |          |\n",
            "|    fps                | 1001     |\n",
            "|    iterations         | 2200     |\n",
            "|    time_elapsed       | 10       |\n",
            "|    total_timesteps    | 11000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.676   |\n",
            "|    explained_variance | -2       |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2199     |\n",
            "|    policy_loss        | -0.0347  |\n",
            "|    value_loss         | 0.0114   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 27.9     |\n",
            "|    ep_rew_mean        | 27.9     |\n",
            "| time/                 |          |\n",
            "|    fps                | 986      |\n",
            "|    iterations         | 2300     |\n",
            "|    time_elapsed       | 11       |\n",
            "|    total_timesteps    | 11500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.66    |\n",
            "|    explained_variance | 0.399    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2299     |\n",
            "|    policy_loss        | 0.179    |\n",
            "|    value_loss         | 0.095    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 27.9     |\n",
            "|    ep_rew_mean        | 27.9     |\n",
            "| time/                 |          |\n",
            "|    fps                | 969      |\n",
            "|    iterations         | 2400     |\n",
            "|    time_elapsed       | 12       |\n",
            "|    total_timesteps    | 12000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.672   |\n",
            "|    explained_variance | 0.571    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2399     |\n",
            "|    policy_loss        | -0.64    |\n",
            "|    value_loss         | 1.28     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 27.7     |\n",
            "|    ep_rew_mean        | 27.7     |\n",
            "| time/                 |          |\n",
            "|    fps                | 958      |\n",
            "|    iterations         | 2500     |\n",
            "|    time_elapsed       | 13       |\n",
            "|    total_timesteps    | 12500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.686   |\n",
            "|    explained_variance | 0.0754   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2499     |\n",
            "|    policy_loss        | -0.0572  |\n",
            "|    value_loss         | 0.00685  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 28.2     |\n",
            "|    ep_rew_mean        | 28.2     |\n",
            "| time/                 |          |\n",
            "|    fps                | 958      |\n",
            "|    iterations         | 2600     |\n",
            "|    time_elapsed       | 13       |\n",
            "|    total_timesteps    | 13000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.685   |\n",
            "|    explained_variance | 0.0709   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2599     |\n",
            "|    policy_loss        | -0.311   |\n",
            "|    value_loss         | 2.88     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 28       |\n",
            "|    ep_rew_mean        | 28       |\n",
            "| time/                 |          |\n",
            "|    fps                | 958      |\n",
            "|    iterations         | 2700     |\n",
            "|    time_elapsed       | 14       |\n",
            "|    total_timesteps    | 13500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.686   |\n",
            "|    explained_variance | -0.546   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2699     |\n",
            "|    policy_loss        | 0.0408   |\n",
            "|    value_loss         | 0.00537  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 30.3     |\n",
            "|    ep_rew_mean        | 30.3     |\n",
            "| time/                 |          |\n",
            "|    fps                | 959      |\n",
            "|    iterations         | 2800     |\n",
            "|    time_elapsed       | 14       |\n",
            "|    total_timesteps    | 14000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.669   |\n",
            "|    explained_variance | -3.09    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2799     |\n",
            "|    policy_loss        | 0.148    |\n",
            "|    value_loss         | 0.107    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 29.2     |\n",
            "|    ep_rew_mean        | 29.2     |\n",
            "| time/                 |          |\n",
            "|    fps                | 958      |\n",
            "|    iterations         | 2900     |\n",
            "|    time_elapsed       | 15       |\n",
            "|    total_timesteps    | 14500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.692   |\n",
            "|    explained_variance | -5.64    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2899     |\n",
            "|    policy_loss        | 0.0225   |\n",
            "|    value_loss         | 0.00188  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 30.4     |\n",
            "|    ep_rew_mean        | 30.4     |\n",
            "| time/                 |          |\n",
            "|    fps                | 960      |\n",
            "|    iterations         | 3000     |\n",
            "|    time_elapsed       | 15       |\n",
            "|    total_timesteps    | 15000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.665   |\n",
            "|    explained_variance | -0.637   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2999     |\n",
            "|    policy_loss        | 0.12     |\n",
            "|    value_loss         | 0.0537   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 29.9     |\n",
            "|    ep_rew_mean        | 29.9     |\n",
            "| time/                 |          |\n",
            "|    fps                | 959      |\n",
            "|    iterations         | 3100     |\n",
            "|    time_elapsed       | 16       |\n",
            "|    total_timesteps    | 15500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.686   |\n",
            "|    explained_variance | -25.3    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3099     |\n",
            "|    policy_loss        | 0.0585   |\n",
            "|    value_loss         | 0.0117   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 30.8     |\n",
            "|    ep_rew_mean        | 30.8     |\n",
            "| time/                 |          |\n",
            "|    fps                | 961      |\n",
            "|    iterations         | 3200     |\n",
            "|    time_elapsed       | 16       |\n",
            "|    total_timesteps    | 16000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.69    |\n",
            "|    explained_variance | -103     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3199     |\n",
            "|    policy_loss        | -0.00132 |\n",
            "|    value_loss         | 8.12e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 31       |\n",
            "|    ep_rew_mean        | 31       |\n",
            "| time/                 |          |\n",
            "|    fps                | 959      |\n",
            "|    iterations         | 3300     |\n",
            "|    time_elapsed       | 17       |\n",
            "|    total_timesteps    | 16500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.651   |\n",
            "|    explained_variance | 0.321    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3299     |\n",
            "|    policy_loss        | -1.09    |\n",
            "|    value_loss         | 4.6      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 30.6     |\n",
            "|    ep_rew_mean        | 30.6     |\n",
            "| time/                 |          |\n",
            "|    fps                | 961      |\n",
            "|    iterations         | 3400     |\n",
            "|    time_elapsed       | 17       |\n",
            "|    total_timesteps    | 17000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.676   |\n",
            "|    explained_variance | 0.2      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3399     |\n",
            "|    policy_loss        | -1.64    |\n",
            "|    value_loss         | 6.08     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 30.9     |\n",
            "|    ep_rew_mean        | 30.9     |\n",
            "| time/                 |          |\n",
            "|    fps                | 960      |\n",
            "|    iterations         | 3500     |\n",
            "|    time_elapsed       | 18       |\n",
            "|    total_timesteps    | 17500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.688   |\n",
            "|    explained_variance | 0.729    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3499     |\n",
            "|    policy_loss        | 0.0391   |\n",
            "|    value_loss         | 0.005    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 29.6     |\n",
            "|    ep_rew_mean        | 29.6     |\n",
            "| time/                 |          |\n",
            "|    fps                | 961      |\n",
            "|    iterations         | 3600     |\n",
            "|    time_elapsed       | 18       |\n",
            "|    total_timesteps    | 18000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.676   |\n",
            "|    explained_variance | 0.318    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3599     |\n",
            "|    policy_loss        | -1.57    |\n",
            "|    value_loss         | 5.36     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 30.5     |\n",
            "|    ep_rew_mean        | 30.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 959      |\n",
            "|    iterations         | 3700     |\n",
            "|    time_elapsed       | 19       |\n",
            "|    total_timesteps    | 18500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.664   |\n",
            "|    explained_variance | 0.71     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3699     |\n",
            "|    policy_loss        | 0.0965   |\n",
            "|    value_loss         | 0.0374   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 30.3     |\n",
            "|    ep_rew_mean        | 30.3     |\n",
            "| time/                 |          |\n",
            "|    fps                | 961      |\n",
            "|    iterations         | 3800     |\n",
            "|    time_elapsed       | 19       |\n",
            "|    total_timesteps    | 19000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.667   |\n",
            "|    explained_variance | -3.48    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3799     |\n",
            "|    policy_loss        | 0.052    |\n",
            "|    value_loss         | 0.0321   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 30       |\n",
            "|    ep_rew_mean        | 30       |\n",
            "| time/                 |          |\n",
            "|    fps                | 960      |\n",
            "|    iterations         | 3900     |\n",
            "|    time_elapsed       | 20       |\n",
            "|    total_timesteps    | 19500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.678   |\n",
            "|    explained_variance | 0.393    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3899     |\n",
            "|    policy_loss        | -0.235   |\n",
            "|    value_loss         | 1.72     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 30.6     |\n",
            "|    ep_rew_mean        | 30.6     |\n",
            "| time/                 |          |\n",
            "|    fps                | 955      |\n",
            "|    iterations         | 4000     |\n",
            "|    time_elapsed       | 20       |\n",
            "|    total_timesteps    | 20000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.687   |\n",
            "|    explained_variance | -6.33    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3999     |\n",
            "|    policy_loss        | -0.0482  |\n",
            "|    value_loss         | 0.00639  |\n",
            "------------------------------------\n"
          ]
        }
      ],
      "source": [
        "policy_kwargs = dict(\n",
        "    net_arch=[\n",
        "      dict(vf=[64, 64], pi=[64, 64]), # network architectures for actor/critic\n",
        "    ],\n",
        "    activation_fn=nn.Tanh,\n",
        ")\n",
        "\n",
        "hyperparams = dict(\n",
        "    n_steps=5, # number of steps to collect data before updating policy\n",
        "    learning_rate=7e-4,\n",
        "    gamma=0.80, # discount factor\n",
        "    max_grad_norm=0.5, # The maximum value for the gradient clipping\n",
        "    ent_coef=0.4, # Entropy coefficient for the loss calculation\n",
        ")\n",
        "\n",
        "model = A2C(\"MlpPolicy\", \"CartPole-v1\", seed=8, verbose=1, **hyperparams).learn(budget)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "RkS5p-id-Nj9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f81c442-cacb-4536-da93-edae456163c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_reward:394.22 +/- 87.06\n"
          ]
        }
      ],
      "source": [
        "mean_reward, std_reward = evaluate_policy(model, eval_envs_cartpole, n_eval_episodes=50, deterministic=True)\n",
        "\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL_G9DurUV75"
      },
      "source": [
        "Hint - Recommended Hyperparameter Range\n",
        "\n",
        "```python\n",
        "gamma = trial.suggest_float(\"gamma\", 0.9, 0.99999, log=True)\n",
        "max_grad_norm = trial.suggest_float(\"max_grad_norm\", 0.3, 5.0, log=True)\n",
        "# from 2**3 = 8 to 2**10 = 1024\n",
        "n_steps = 2 ** trial.suggest_int(\"exponent_n_steps\", 3, 10)\n",
        "learning_rate = trial.suggest_float(\"lr\", 1e-5, 1, log=True)\n",
        "ent_coef = trial.suggest_float(\"ent_coef\", 0.00000001, 0.1, log=True)\n",
        "# net_arch tiny: {\"pi\": [64], \"vf\": [64]}\n",
        "# net_arch default: {\"pi\": [64, 64], \"vf\": [64, 64]}\n",
        "# activation_fn = nn.Tanh / nn.ReLU\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwFOp0j-ga-_"
      },
      "source": [
        "# Part III: Automatic Hyperparameter Tuning\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88x7wMyyud5p"
      },
      "source": [
        "In this part we will create a script that allows to search for the best hyperparameters automatically."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auwR-30IvHeY"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "VM6tUr-yuekR",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from optuna.pruners import MedianPruner\n",
        "from optuna.samplers import TPESampler\n",
        "from optuna.visualization import plot_optimization_history, plot_param_importances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQVfmM1dzA1d"
      },
      "source": [
        "### Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "yyBTVcAGzCRk",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "N_TRIALS = 100  # Maximum number of trials\n",
        "N_JOBS = 1 # Number of jobs to run in parallel\n",
        "N_STARTUP_TRIALS = 5  # Stop random sampling after N_STARTUP_TRIALS\n",
        "N_EVALUATIONS = 2  # Number of evaluations during the training\n",
        "N_TIMESTEPS = int(2e4)  # Training budget\n",
        "EVAL_FREQ = int(N_TIMESTEPS / N_EVALUATIONS)\n",
        "N_EVAL_ENVS = 5\n",
        "N_EVAL_EPISODES = 10\n",
        "TIMEOUT = int(60 * 15)  # 15 minutes\n",
        "\n",
        "ENV_ID = \"CartPole-v1\"\n",
        "\n",
        "DEFAULT_HYPERPARAMS = {\n",
        "    \"policy\": \"MlpPolicy\",\n",
        "    \"env\": ENV_ID,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25HgcDYzvJ0b"
      },
      "source": [
        "### Exercise (5 minutes): Define the search space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "KXo8AwGAvN8Q",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from typing import Any, Dict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def sample_a2c_params(trial: optuna.Trial) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Sampler for A2C hyperparameters.\n",
        "\n",
        "    :param trial: Optuna trial object\n",
        "    :return: The sampled hyperparameters for the given trial.\n",
        "    \"\"\"\n",
        "    # Discount factor between 0.9 and 0.9999\n",
        "    gamma = 1.0 - trial.suggest_float(\"gamma\", 0.0001, 0.1, log=True)\n",
        "    max_grad_norm = trial.suggest_float(\"max_grad_norm\", 0.3, 5.0, log=True)\n",
        "    # 8, 16, 32, ... 1024\n",
        "    n_steps = 2 ** trial.suggest_int(\"exponent_n_steps\", 3, 10)\n",
        "\n",
        "    ### YOUR CODE HERE\n",
        "    # TODO:\n",
        "    # - define the learning rate search space [1e-5, 1] (log) -> `suggest_float`\n",
        "    # - define the network architecture search space [\"tiny\", \"small\"] -> `suggest_categorical`\n",
        "    # - define the activation function search space [\"tanh\", \"relu\"]\n",
        "    learning_rate = trial.suggest_float(\"gamma\", 1e-5, 1, log=True)\n",
        "    net_arch = trial.suggest_categorical(\"net_arch\", [\"timy\", \"small\"])\n",
        "    activation_fn = trial.suggest_categorical(\"activation_fn\", [\"tanh\", \"relu\"])\n",
        "\n",
        "    ### END OF YOUR CODE\n",
        "\n",
        "    # Display true values\n",
        "    trial.set_user_attr(\"gamma_\", gamma)\n",
        "    trial.set_user_attr(\"n_steps\", n_steps)\n",
        "\n",
        "    net_arch = [\n",
        "        {\"pi\": [64], \"vf\": [64]}\n",
        "        if net_arch == \"tiny\"\n",
        "        else {\"pi\": [64, 64], \"vf\": [64, 64]}\n",
        "    ]\n",
        "\n",
        "    activation_fn = {\"tanh\": nn.Tanh, \"relu\": nn.ReLU}[activation_fn]\n",
        "\n",
        "    return {\n",
        "        \"n_steps\": n_steps,\n",
        "        \"gamma\": gamma,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"max_grad_norm\": max_grad_norm,\n",
        "        \"policy_kwargs\": {\n",
        "            \"net_arch\": net_arch,\n",
        "            \"activation_fn\": activation_fn,\n",
        "        },\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iybymNiJxNu7"
      },
      "source": [
        "### Define the objective function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJY8Z8tuxai7"
      },
      "source": [
        "First we define a custom callback to report the results of periodic evaluations to Optuna:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "U5ijWTPzxSmd",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "\n",
        "class TrialEvalCallback(EvalCallback):\n",
        "    \"\"\"\n",
        "    Callback used for evaluating and reporting a trial.\n",
        "    \n",
        "    :param eval_env: Evaluation environement\n",
        "    :param trial: Optuna trial object\n",
        "    :param n_eval_episodes: Number of evaluation episodes\n",
        "    :param eval_freq:   Evaluate the agent every ``eval_freq`` call of the callback.\n",
        "    :param deterministic: Whether the evaluation should\n",
        "        use a stochastic or deterministic policy.\n",
        "    :param verbose:\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        eval_env: gym.Env,\n",
        "        trial: optuna.Trial,\n",
        "        n_eval_episodes: int = 5,\n",
        "        eval_freq: int = 10000,\n",
        "        deterministic: bool = True,\n",
        "        verbose: int = 0,\n",
        "    ):\n",
        "\n",
        "        super().__init__(\n",
        "            eval_env=eval_env,\n",
        "            n_eval_episodes=n_eval_episodes,\n",
        "            eval_freq=eval_freq,\n",
        "            deterministic=deterministic,\n",
        "            verbose=verbose,\n",
        "        )\n",
        "        self.trial = trial\n",
        "        self.eval_idx = 0\n",
        "        self.is_pruned = False\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        if self.eval_freq > 0 and self.n_calls % self.eval_freq == 0:\n",
        "            # Evaluate policy (done in the parent class)\n",
        "            super()._on_step()\n",
        "            self.eval_idx += 1\n",
        "            # Send report to Optuna\n",
        "            self.trial.report(self.last_mean_reward, self.eval_idx)\n",
        "            # Prune trial if need\n",
        "            if self.trial.should_prune():\n",
        "                self.is_pruned = True\n",
        "                return False\n",
        "        return True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cHNM_cFO3vs"
      },
      "source": [
        "### Exercise (10 minutes): Define the objective function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76voi9AXxlCq"
      },
      "source": [
        "Then we define the objective function that is in charge of sampling hyperparameters, creating the model and then returning the result to Optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "E0yEokTDxhrC",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def objective(trial: optuna.Trial) -> float:\n",
        "    \"\"\"\n",
        "    Objective function using by Optuna to evaluate\n",
        "    one configuration (i.e., one set of hyperparameters).\n",
        "\n",
        "    Given a trial object, it will sample hyperparameters,\n",
        "    evaluate it and report the result (mean episodic reward after training)\n",
        "\n",
        "    :param trial: Optuna trial object\n",
        "    :return: Mean episodic reward after training\n",
        "    \"\"\"\n",
        "\n",
        "    kwargs = DEFAULT_HYPERPARAMS.copy()\n",
        "    ### YOUR CODE HERE\n",
        "    # TODO: \n",
        "    # 1. Sample hyperparameters and update the default keyword arguments: `kwargs.update(other_params)`\n",
        "    # 2. Create the evaluation envs\n",
        "    # 3. Create the `TrialEvalCallback`\n",
        "\n",
        "    # 1. Sample hyperparameters and update the keyword arguments\n",
        "    kwargs.update(sample_a2c_params(trial))\n",
        "\n",
        "    # Create the RL model\n",
        "    model = A2C(**kwargs)\n",
        "\n",
        "    # 2. Create envs used for evaluation using `make_vec_env`, `ENV_ID` and `N_EVAL_ENVS`\n",
        "    eval_envs = make_vec_env(ENV_ID, N_EVAL_ENVS)\n",
        "\n",
        "    # 3. Create the `TrialEvalCallback` callback defined above that will periodically evaluate\n",
        "    # and report the performance using `N_EVAL_EPISODES` every `EVAL_FREQ`\n",
        "    # TrialEvalCallback signature:\n",
        "    # TrialEvalCallback(eval_env, trial, n_eval_episodes, eval_freq, deterministic, verbose)\n",
        "    eval_callback = TrialEvalCallback(eval_envs,\n",
        "                                      trial,\n",
        "                                      N_EVAL_EPISODES,\n",
        "                                      EVAL_FREQ,\n",
        "                                      deterministic=True)\n",
        "\n",
        "    ### END OF YOUR CODE\n",
        "\n",
        "    nan_encountered = False\n",
        "    try:\n",
        "        # Train the model\n",
        "        model.learn(N_TIMESTEPS, callback=eval_callback)\n",
        "    except AssertionError as e:\n",
        "        # Sometimes, random hyperparams can generate NaN\n",
        "        print(e)\n",
        "        nan_encountered = True\n",
        "    finally:\n",
        "        # Free memory\n",
        "        model.env.close()\n",
        "        eval_envs.close()\n",
        "\n",
        "    # Tell the optimizer that the trial failed\n",
        "    if nan_encountered:\n",
        "        return float(\"nan\")\n",
        "\n",
        "    if eval_callback.is_pruned:\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return eval_callback.last_mean_reward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMFLu_M0ymzj"
      },
      "source": [
        "### The optimization loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "4UU17YpjymPr",
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "64da7562-3013-4db6-8278-0ab82c9b5740"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-21 12:40:51,638]\u001b[0m A new study created in memory with name: no-name-41c7a891-8015-40ee-b57f-4253fc29eb62\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:41:03,537]\u001b[0m Trial 0 finished with value: 164.7 and parameters: {'gamma': 0.0002532354691581366, 'max_grad_norm': 1.166731055635991, 'exponent_n_steps': 7, 'net_arch': 'timy', 'activation_fn': 'relu'}. Best is trial 0 with value: 164.7.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:41:15,304]\u001b[0m Trial 1 finished with value: 110.9 and parameters: {'gamma': 0.00011971031714215872, 'max_grad_norm': 0.7868026427971981, 'exponent_n_steps': 9, 'net_arch': 'timy', 'activation_fn': 'relu'}. Best is trial 0 with value: 164.7.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:41:32,187]\u001b[0m Trial 2 finished with value: 9.4 and parameters: {'gamma': 0.0895525301820842, 'max_grad_norm': 0.6395218967190066, 'exponent_n_steps': 3, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: 164.7.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:41:45,823]\u001b[0m Trial 3 finished with value: 9.2 and parameters: {'gamma': 0.08829801547949473, 'max_grad_norm': 0.34452872622463115, 'exponent_n_steps': 4, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 0 with value: 164.7.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:41:59,644]\u001b[0m Trial 4 finished with value: 9.5 and parameters: {'gamma': 0.010146110318723214, 'max_grad_norm': 3.886426741936195, 'exponent_n_steps': 4, 'net_arch': 'timy', 'activation_fn': 'relu'}. Best is trial 0 with value: 164.7.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:42:11,359]\u001b[0m Trial 5 finished with value: 109.0 and parameters: {'gamma': 0.0001311141389650859, 'max_grad_norm': 2.2031781683200626, 'exponent_n_steps': 8, 'net_arch': 'timy', 'activation_fn': 'tanh'}. Best is trial 0 with value: 164.7.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:42:23,766]\u001b[0m Trial 6 finished with value: 500.0 and parameters: {'gamma': 0.0010243021139195424, 'max_grad_norm': 1.4938951522542587, 'exponent_n_steps': 6, 'net_arch': 'timy', 'activation_fn': 'relu'}. Best is trial 6 with value: 500.0.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:42:35,453]\u001b[0m Trial 7 finished with value: 114.8 and parameters: {'gamma': 0.00246995781631689, 'max_grad_norm': 2.1332926983624825, 'exponent_n_steps': 6, 'net_arch': 'timy', 'activation_fn': 'relu'}. Best is trial 6 with value: 500.0.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:42:47,312]\u001b[0m Trial 8 finished with value: 373.3 and parameters: {'gamma': 0.0011527732889979327, 'max_grad_norm': 4.86243507950815, 'exponent_n_steps': 10, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 6 with value: 500.0.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:42:59,425]\u001b[0m Trial 9 finished with value: 113.3 and parameters: {'gamma': 0.013245003960060306, 'max_grad_norm': 2.0193575486166977, 'exponent_n_steps': 6, 'net_arch': 'timy', 'activation_fn': 'relu'}. Best is trial 6 with value: 500.0.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:43:12,505]\u001b[0m Trial 10 finished with value: 277.5 and parameters: {'gamma': 0.0007312146449920395, 'max_grad_norm': 0.373457872670275, 'exponent_n_steps': 5, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 6 with value: 500.0.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:43:24,565]\u001b[0m Trial 11 finished with value: 495.1 and parameters: {'gamma': 0.0011187747155069559, 'max_grad_norm': 4.608055382514245, 'exponent_n_steps': 10, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 6 with value: 500.0.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:43:36,133]\u001b[0m Trial 12 finished with value: 392.9 and parameters: {'gamma': 0.0006244905426600173, 'max_grad_norm': 3.6898898281385284, 'exponent_n_steps': 8, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 6 with value: 500.0.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:43:47,756]\u001b[0m Trial 13 finished with value: 265.2 and parameters: {'gamma': 0.0048193815639474636, 'max_grad_norm': 1.361673451161519, 'exponent_n_steps': 10, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 6 with value: 500.0.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:43:53,357]\u001b[0m Trial 14 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:44:05,507]\u001b[0m Trial 15 finished with value: 472.8 and parameters: {'gamma': 0.0004684681686297877, 'max_grad_norm': 1.3883165919224847, 'exponent_n_steps': 7, 'net_arch': 'timy', 'activation_fn': 'tanh'}. Best is trial 6 with value: 500.0.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:44:18,925]\u001b[0m Trial 16 finished with value: 500.0 and parameters: {'gamma': 0.00835771653784241, 'max_grad_norm': 0.6732411257733567, 'exponent_n_steps': 5, 'net_arch': 'timy', 'activation_fn': 'relu'}. Best is trial 6 with value: 500.0.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:44:25,110]\u001b[0m Trial 17 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:44:31,203]\u001b[0m Trial 18 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:44:39,576]\u001b[0m Trial 19 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:44:51,569]\u001b[0m Trial 20 finished with value: 290.6 and parameters: {'gamma': 0.0046662712309649005, 'max_grad_norm': 0.9233634104467607, 'exponent_n_steps': 6, 'net_arch': 'timy', 'activation_fn': 'relu'}. Best is trial 6 with value: 500.0.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:44:59,146]\u001b[0m Trial 21 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:45:04,896]\u001b[0m Trial 22 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:45:10,481]\u001b[0m Trial 23 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:45:23,610]\u001b[0m Trial 24 finished with value: 9.7 and parameters: {'gamma': 0.008546886272579764, 'max_grad_norm': 0.6471789263582984, 'exponent_n_steps': 5, 'net_arch': 'timy', 'activation_fn': 'relu'}. Best is trial 6 with value: 500.0.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:45:29,666]\u001b[0m Trial 25 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:45:35,232]\u001b[0m Trial 26 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:45:40,815]\u001b[0m Trial 27 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:45:47,330]\u001b[0m Trial 28 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:45:53,161]\u001b[0m Trial 29 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:46:00,095]\u001b[0m Trial 30 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:46:06,134]\u001b[0m Trial 31 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:46:11,915]\u001b[0m Trial 32 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:46:17,313]\u001b[0m Trial 33 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:46:22,803]\u001b[0m Trial 34 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:46:34,746]\u001b[0m Trial 35 finished with value: 500.0 and parameters: {'gamma': 0.0007846396463008333, 'max_grad_norm': 0.716867124891602, 'exponent_n_steps': 7, 'net_arch': 'timy', 'activation_fn': 'tanh'}. Best is trial 6 with value: 500.0.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:46:41,803]\u001b[0m Trial 36 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:46:54,406]\u001b[0m Trial 37 finished with value: 500.0 and parameters: {'gamma': 0.007788777445100236, 'max_grad_norm': 0.6304941639817605, 'exponent_n_steps': 6, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 6 with value: 500.0.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:47:07,058]\u001b[0m Trial 38 finished with value: 500.0 and parameters: {'gamma': 0.008857840985872884, 'max_grad_norm': 0.7410196325789227, 'exponent_n_steps': 6, 'net_arch': 'timy', 'activation_fn': 'relu'}. Best is trial 6 with value: 500.0.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:47:13,322]\u001b[0m Trial 39 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:47:19,493]\u001b[0m Trial 40 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:47:25,518]\u001b[0m Trial 41 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:47:31,595]\u001b[0m Trial 42 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:47:37,432]\u001b[0m Trial 43 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:47:43,001]\u001b[0m Trial 44 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:47:49,109]\u001b[0m Trial 45 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:48:01,044]\u001b[0m Trial 46 finished with value: 163.0 and parameters: {'gamma': 0.003108285866588103, 'max_grad_norm': 0.36994568128049804, 'exponent_n_steps': 6, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 6 with value: 500.0.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:48:13,105]\u001b[0m Trial 47 finished with value: 460.3 and parameters: {'gamma': 0.007424394573852653, 'max_grad_norm': 0.7641773426191376, 'exponent_n_steps': 7, 'net_arch': 'timy', 'activation_fn': 'relu'}. Best is trial 6 with value: 500.0.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:48:26,429]\u001b[0m Trial 48 finished with value: 500.0 and parameters: {'gamma': 0.010987580080667947, 'max_grad_norm': 0.5637726199148444, 'exponent_n_steps': 5, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 6 with value: 500.0.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:48:38,324]\u001b[0m Trial 49 finished with value: 500.0 and parameters: {'gamma': 0.012081431236131193, 'max_grad_norm': 0.49999923147983283, 'exponent_n_steps': 8, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 6 with value: 500.0.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:48:43,967]\u001b[0m Trial 50 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:48:55,736]\u001b[0m Trial 51 finished with value: 378.9 and parameters: {'gamma': 0.004288998093416867, 'max_grad_norm': 0.48967593879776833, 'exponent_n_steps': 8, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 6 with value: 500.0.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:49:01,467]\u001b[0m Trial 52 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:49:07,123]\u001b[0m Trial 53 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:49:13,606]\u001b[0m Trial 54 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:49:19,166]\u001b[0m Trial 55 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:49:26,037]\u001b[0m Trial 56 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:49:39,216]\u001b[0m Trial 57 finished with value: 235.0 and parameters: {'gamma': 0.009002261790572943, 'max_grad_norm': 0.8254923675575234, 'exponent_n_steps': 5, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 6 with value: 500.0.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:49:44,994]\u001b[0m Trial 58 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:49:51,884]\u001b[0m Trial 59 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:50:00,042]\u001b[0m Trial 60 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:50:12,584]\u001b[0m Trial 61 finished with value: 500.0 and parameters: {'gamma': 0.006067730093183046, 'max_grad_norm': 0.6974898648633189, 'exponent_n_steps': 6, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 6 with value: 500.0.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:50:18,414]\u001b[0m Trial 62 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:50:24,341]\u001b[0m Trial 63 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:50:36,395]\u001b[0m Trial 64 finished with value: 500.0 and parameters: {'gamma': 0.011117783047066794, 'max_grad_norm': 0.712814415700638, 'exponent_n_steps': 7, 'net_arch': 'timy', 'activation_fn': 'relu'}. Best is trial 6 with value: 500.0.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:50:42,108]\u001b[0m Trial 65 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:50:47,691]\u001b[0m Trial 66 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:50:53,720]\u001b[0m Trial 67 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:51:00,631]\u001b[0m Trial 68 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:51:06,229]\u001b[0m Trial 69 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:51:19,521]\u001b[0m Trial 70 finished with value: 478.6 and parameters: {'gamma': 0.009746183004350553, 'max_grad_norm': 0.5546590168478717, 'exponent_n_steps': 5, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 6 with value: 500.0.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:51:31,756]\u001b[0m Trial 71 finished with value: 500.0 and parameters: {'gamma': 0.0068933112950470415, 'max_grad_norm': 2.370751563256403, 'exponent_n_steps': 7, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 6 with value: 500.0.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:51:37,583]\u001b[0m Trial 72 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:51:43,267]\u001b[0m Trial 73 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:51:55,233]\u001b[0m Trial 74 finished with value: 500.0 and parameters: {'gamma': 0.006962664252954531, 'max_grad_norm': 2.97338218244586, 'exponent_n_steps': 7, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 6 with value: 500.0.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:52:00,868]\u001b[0m Trial 75 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:52:07,082]\u001b[0m Trial 76 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:52:19,106]\u001b[0m Trial 77 finished with value: 500.0 and parameters: {'gamma': 0.0024558627262292417, 'max_grad_norm': 1.4687329421782878, 'exponent_n_steps': 8, 'net_arch': 'timy', 'activation_fn': 'tanh'}. Best is trial 6 with value: 500.0.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:52:24,913]\u001b[0m Trial 78 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:52:30,766]\u001b[0m Trial 79 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:52:36,591]\u001b[0m Trial 80 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:52:41,970]\u001b[0m Trial 81 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:52:48,082]\u001b[0m Trial 82 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:52:53,557]\u001b[0m Trial 83 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:52:59,345]\u001b[0m Trial 84 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:53:05,029]\u001b[0m Trial 85 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:53:10,867]\u001b[0m Trial 86 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:53:17,217]\u001b[0m Trial 87 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:53:23,374]\u001b[0m Trial 88 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:53:29,419]\u001b[0m Trial 89 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:53:35,688]\u001b[0m Trial 90 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:53:41,298]\u001b[0m Trial 91 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:53:47,189]\u001b[0m Trial 92 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:53:52,914]\u001b[0m Trial 93 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:54:04,811]\u001b[0m Trial 94 finished with value: 499.9 and parameters: {'gamma': 0.0018323234617497234, 'max_grad_norm': 2.003935535114197, 'exponent_n_steps': 8, 'net_arch': 'timy', 'activation_fn': 'tanh'}. Best is trial 6 with value: 500.0.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:54:10,979]\u001b[0m Trial 95 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:54:16,602]\u001b[0m Trial 96 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:54:23,327]\u001b[0m Trial 97 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:54:29,230]\u001b[0m Trial 98 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/trial/_trial.py:780: RuntimeWarning: Inconsistent parameter values for distribution with name \"gamma\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0001, 'high': 0.1}\n",
            "  RuntimeWarning,\n",
            "\u001b[32m[I 2022-06-21 12:54:36,166]\u001b[0m Trial 99 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of finished trials:  100\n",
            "Best trial:\n",
            "  Value: 500.0\n",
            "  Params: \n",
            "    gamma: 0.0010243021139195424\n",
            "    max_grad_norm: 1.4938951522542587\n",
            "    exponent_n_steps: 6\n",
            "    net_arch: timy\n",
            "    activation_fn: relu\n",
            "  User attrs:\n",
            "    gamma_: 0.9989756978860804\n",
            "    n_steps: 64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"777d0494-5a7f-4040-8f85-7d0528e1ea12\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"777d0494-5a7f-4040-8f85-7d0528e1ea12\")) {                    Plotly.newPlot(                        \"777d0494-5a7f-4040-8f85-7d0528e1ea12\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,15,16,20,24,35,37,38,46,47,48,49,51,57,61,64,70,71,74,77,94],\"y\":[164.7,110.9,9.4,9.2,9.5,109.0,500.0,114.8,373.3,113.3,277.5,495.1,392.9,265.2,472.8,500.0,290.6,9.7,500.0,500.0,500.0,163.0,460.3,500.0,500.0,378.9,235.0,500.0,500.0,478.6,500.0,500.0,500.0,499.9],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,15,16,20,24,35,37,38,46,47,48,49,51,57,61,64,70,71,74,77,94],\"y\":[164.7,164.7,164.7,164.7,164.7,164.7,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"#Trials\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('777d0494-5a7f-4040-8f85-7d0528e1ea12');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"2cd9689f-cd2d-4d1f-93e5-d1c3d5e705a6\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2cd9689f-cd2d-4d1f-93e5-d1c3d5e705a6\")) {                    Plotly.newPlot(                        \"2cd9689f-cd2d-4d1f-93e5-d1c3d5e705a6\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"activation_fn (CategoricalDistribution): 0.015389424597840285<extra></extra>\",\"net_arch (CategoricalDistribution): 0.03840685536492351<extra></extra>\",\"max_grad_norm (LogUniformDistribution): 0.11004756247423553<extra></extra>\",\"gamma (LogUniformDistribution): 0.33000150415653823<extra></extra>\",\"exponent_n_steps (IntUniformDistribution): 0.5061546534064625<extra></extra>\"],\"marker\":{\"color\":\"rgb(66,146,198)\"},\"orientation\":\"h\",\"text\":[\"0.015389424597840285\",\"0.03840685536492351\",\"0.11004756247423553\",\"0.33000150415653823\",\"0.5061546534064625\"],\"textposition\":\"outside\",\"texttemplate\":\"%{text:.2f}\",\"x\":[0.015389424597840285,0.03840685536492351,0.11004756247423553,0.33000150415653823,0.5061546534064625],\"y\":[\"activation_fn\",\"net_arch\",\"max_grad_norm\",\"gamma\",\"exponent_n_steps\"],\"type\":\"bar\"}],                        {\"showlegend\":false,\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Importance for Objective Value\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('2cd9689f-cd2d-4d1f-93e5-d1c3d5e705a6');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch as th\n",
        "\n",
        "# Set pytorch num threads to 1 for faster training\n",
        "th.set_num_threads(1)\n",
        "# Select the sampler, can be random, TPESampler, CMAES, ...\n",
        "sampler = TPESampler(n_startup_trials=N_STARTUP_TRIALS)\n",
        "# Do not prune before 1/3 of the max budget is used\n",
        "pruner = MedianPruner(\n",
        "    n_startup_trials=N_STARTUP_TRIALS, n_warmup_steps=N_EVALUATIONS // 3\n",
        ")\n",
        "# Create the study and start the hyperparameter optimization\n",
        "study = optuna.create_study(sampler=sampler, pruner=pruner, direction=\"maximize\")\n",
        "\n",
        "try:\n",
        "    study.optimize(objective, n_trials=N_TRIALS, n_jobs=N_JOBS, timeout=TIMEOUT)\n",
        "except KeyboardInterrupt:\n",
        "    pass\n",
        "\n",
        "print(\"Number of finished trials: \", len(study.trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(f\"  Value: {trial.value}\")\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(f\"    {key}: {value}\")\n",
        "\n",
        "print(\"  User attrs:\")\n",
        "for key, value in trial.user_attrs.items():\n",
        "    print(f\"    {key}: {value}\")\n",
        "\n",
        "# Write report\n",
        "study.trials_dataframe().to_csv(\"study_results_a2c_cartpole.csv\")\n",
        "\n",
        "fig1 = plot_optimization_history(study)\n",
        "fig2 = plot_param_importances(study)\n",
        "\n",
        "fig1.show()\n",
        "fig2.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCbep6z1h3D1"
      },
      "source": [
        "Complete example: https://github.com/DLR-RM/rl-baselines3-zoo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yUeYnfJVpB2"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "What we have seen in this notebook:\n",
        "- the importance of good hyperparameters\n",
        "- how to do automatic hyperparameter search with optuna\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-gqIPXqV7zZ",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "icra22_optuna_lab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}