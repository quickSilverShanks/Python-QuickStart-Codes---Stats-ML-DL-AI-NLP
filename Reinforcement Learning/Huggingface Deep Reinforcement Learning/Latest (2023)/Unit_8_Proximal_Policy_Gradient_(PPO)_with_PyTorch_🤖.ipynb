{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cf5-oDPjwf8"
      },
      "source": [
        "# Unit 8: Proximal Policy Gradient (PPO) with PyTorch ü§ñ\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit9/thumbnail.png\" alt=\"Unit 8\"/>\n",
        "\n",
        "\n",
        "In this notebook, you'll learn to **code your PPO agent from scratch with PyTorch using CleanRL implementation as model**.\n",
        "\n",
        "To test its robustness, we're going to train it in:\n",
        "\n",
        "- [LunarLander-v2 üöÄ](https://www.gymlibrary.dev/environments/box2d/lunar_lander/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Fl6Rxt0lc0O"
      },
      "source": [
        "‚¨áÔ∏è Here is an example of what you will achieve. ‚¨áÔ∏è"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DbKfCj5ilgqT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "5f7749ae-fde2-4236-a4f9-019d00858e52"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<video controls autoplay><source src=\"https://huggingface.co/sb3/ppo-LunarLander-v2/resolve/main/replay.mp4\" type=\"video/mp4\"></video>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "%%html\n",
        "<video controls autoplay><source src=\"https://huggingface.co/sb3/ppo-LunarLander-v2/resolve/main/replay.mp4\" type=\"video/mp4\"></video>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcOFdWpnlxNf"
      },
      "source": [
        "We're constantly trying to improve our tutorials, so **if you find some issues in this notebook**, please [open an issue on the GitHub Repo](https://github.com/huggingface/deep-rl-class/issues)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objectives of this notebook üèÜ\n",
        "\n",
        "At the end of the notebook, you will:\n",
        "\n",
        "- Be able to **code your PPO agent from scratch using PyTorch**.\n",
        "- Be able to **push your trained agent and the code to the Hub** with a nice video replay and an evaluation score üî•.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "T6lIPYFghhYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This notebook is from the Deep Reinforcement Learning Course\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/deep-rl-course-illustration.jpg\" alt=\"Deep RL Course illustration\"/>\n",
        "\n",
        "In this free course, you will:\n",
        "\n",
        "- üìñ Study Deep Reinforcement Learning in **theory and practice**.\n",
        "- üßë‚Äçüíª Learn to **use famous Deep RL libraries** such as Stable Baselines3, RL Baselines3 Zoo, CleanRL and Sample Factory 2.0.\n",
        "- ü§ñ Train **agents in unique environments** \n",
        "\n",
        "Don‚Äôt forget to **<a href=\"http://eepurl.com/ic5ZUD\">sign up to the course</a>** (we are collecting your email to be able to¬†**send you the links when each Unit is published and give you information about the challenges and updates).**\n",
        "\n",
        "\n",
        "The best way to keep in touch is to join our discord server to exchange with the community and with us üëâüèª https://discord.gg/ydHrjt3WP5"
      ],
      "metadata": {
        "id": "Wp-rD6Fuhq31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites üèóÔ∏è\n",
        "Before diving into the notebook, you need to:\n",
        "\n",
        "üî≤ üìö Study [PPO by reading Unit 8](https://huggingface.co/deep-rl-course/unit8/introduction) ü§ó  "
      ],
      "metadata": {
        "id": "rasqqGQlhujA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To validate this hands-on for the [certification process](https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process), you need to push one model, we don't ask for a minimal result but we **advise you to try different hyperparameters settings to get better results**.\n",
        "\n",
        "If you don't find your model, **go to the bottom of the page and click on the refresh button**\n",
        "\n",
        "For more information about the certification process, check this section üëâ https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process"
      ],
      "metadata": {
        "id": "PUFfMGOih3CW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set the GPU üí™\n",
        "- To **accelerate the agent's training, we'll use a GPU**. To do that, go to `Runtime > Change Runtime type`\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/gpu-step1.jpg\" alt=\"GPU Step 1\">"
      ],
      "metadata": {
        "id": "PU4FVzaoM6fC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `Hardware Accelerator > GPU`\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/gpu-step2.jpg\" alt=\"GPU Step 2\">"
      ],
      "metadata": {
        "id": "KV0NyFdQM9ZG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a virtual display üîΩ\n",
        "\n",
        "During the notebook, we'll need to generate a replay video. To do so, with colab, **we need to have a virtual screen to be able to render the environment** (and thus record the frames). \n",
        "\n",
        "Hence the following cell will install the librairies and create and run a virtual screen üñ•"
      ],
      "metadata": {
        "id": "bTpYcVZVMzUI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jV6wjQ7Be7p5"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!apt install python-opengl\n",
        "!apt install ffmpeg\n",
        "!apt install xvfb\n",
        "!apt install swig cmake\n",
        "!pip install pyglet==1.5\n",
        "!pip3 install pyvirtualdisplay"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Virtual display\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()"
      ],
      "metadata": {
        "id": "ww5PQH1gNLI4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b33e59ea-8972-47bf-8597-027f2883cded"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7f3a3a109bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install setuptools==65.5.0  wheel==0.38.4 # QuickSilver007 added wheel to avoid gym installation error"
      ],
      "metadata": {
        "id": "Fd731S8-NuJA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5437792c-9b63-45c6-e267-e5a30ea2b3bd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: setuptools==65.5.0 in /usr/local/lib/python3.10/dist-packages (65.5.0)\n",
            "Requirement already satisfied: wheel==0.38.4 in /usr/local/lib/python3.10/dist-packages (0.38.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncIgfNf3mOtc"
      },
      "source": [
        "## Install dependencies üîΩ\n",
        "For this exercise, we use `gym==0.21` because the video was recorded using Gym.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install gym==0.21 # QuickSilver007 commented due to some error with box2d\n",
        "!pip install gym[box2d]==0.21\n",
        "!pip install imageio-ffmpeg\n",
        "!pip install huggingface_hub\n",
        "!pip install box2d"
      ],
      "metadata": {
        "id": "9xZQFTPcsKUK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fc2211c-0fed-4022-b987-65487ee26934"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym[box2d]==0.21 in /usr/local/lib/python3.10/dist-packages (0.21.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]==0.21) (1.22.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]==0.21) (2.2.1)\n",
            "Requirement already satisfied: box2d-py==2.3.5 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]==0.21) (2.3.5)\n",
            "Requirement already satisfied: pyglet>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]==0.21) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pyglet>=1.4.0->gym[box2d]==0.21) (0.18.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.10/dist-packages (0.4.8)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.14.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: box2d in /usr/local/lib/python3.10/dist-packages (2.3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDkUufewmq6v"
      },
      "source": [
        "## Let's code PPO from scratch with Costa Huang tutorial\n",
        "- For the core implementation of PPO we're going to use the excellent [Costa Huang](https://costa.sh/) tutorial.\n",
        "- In addition to the tutorial, to go deeper you can read the 37 core implementation details: https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/\n",
        "\n",
        "üëâ The video tutorial: https://youtu.be/MEt6rrxH8W4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aNgEL1_uvhaq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "98e1a201-36a6-423f-e6f0-90a00dc0f9c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/display.py:724: UserWarning: Consider using IPython.display.IFrame instead\n",
            "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/MEt6rrxH8W4\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/MEt6rrxH8W4\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f34ILn7AvTbt"
      },
      "source": [
        "- The best is to code first on the cell below, this way, if you kill the machine **you don't loose the implementation**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bE708C6mhE7"
      },
      "outputs": [],
      "source": [
        "### Your code here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk-a9CmNuS2W"
      },
      "source": [
        "## Add the Hugging Face Integration ü§ó\n",
        "- In order to push our model to the Hub, we need to define a function `package_to_hub`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPi1Nme-oGWd"
      },
      "source": [
        "- Add dependencies we need to push our model to the Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Sj8bz-AmoNVj"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import HfApi, upload_folder\n",
        "from huggingface_hub.repocard import metadata_eval_result, metadata_save\n",
        "\n",
        "from pathlib import Path\n",
        "import datetime\n",
        "import tempfile\n",
        "import json\n",
        "import shutil\n",
        "import imageio\n",
        "\n",
        "from wasabi import Printer\n",
        "msg = Printer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rDr8-lWn0zi"
      },
      "source": [
        "- Add new argument in `parse_args()` function to define the repo-id where we want to push the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHQiqQEFn0QH"
      },
      "outputs": [],
      "source": [
        "# Adding HuggingFace argument\n",
        "parser.add_argument(\"--repo-id\", type=str, default=\"ThomasSimonini/ppo-CartPole-v1\", help=\"id of the model repository from the Hugging Face Hub {username/repo_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blLZMiBAoUVT"
      },
      "source": [
        "- Next, we add the methods needed to push the model to the Hub\n",
        "\n",
        "- These methods will:\n",
        "  - `_evalutate_agent()`: evaluate the agent.\n",
        "  - `_generate_model_card()`: generate the model card of your agent.\n",
        "  - `_record_video()`: record a video of your agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WlLcz4L9odXs"
      },
      "outputs": [],
      "source": [
        "def package_to_hub(repo_id, \n",
        "                model,\n",
        "                hyperparameters,\n",
        "                eval_env,\n",
        "                video_fps=30,\n",
        "                commit_message=\"Push agent to the Hub\",\n",
        "                token= None,\n",
        "                logs=None\n",
        "                ):\n",
        "  \"\"\"\n",
        "  Evaluate, Generate a video and Upload a model to Hugging Face Hub.\n",
        "  This method does the complete pipeline:\n",
        "  - It evaluates the model\n",
        "  - It generates the model card\n",
        "  - It generates a replay video of the agent\n",
        "  - It pushes everything to the hub\n",
        "  :param repo_id: id of the model repository from the Hugging Face Hub\n",
        "  :param model: trained model\n",
        "  :param eval_env: environment used to evaluate the agent\n",
        "  :param fps: number of fps for rendering the video\n",
        "  :param commit_message: commit message\n",
        "  :param logs: directory on local machine of tensorboard logs you'd like to upload\n",
        "  \"\"\"\n",
        "  msg.info(\n",
        "        \"This function will save, evaluate, generate a video of your agent, \"\n",
        "        \"create a model card and push everything to the hub. \"\n",
        "        \"It might take up to 1min. \\n \"\n",
        "        \"This is a work in progress: if you encounter a bug, please open an issue.\"\n",
        "    )\n",
        "  # Step 1: Clone or create the repo\n",
        "  repo_url = HfApi().create_repo(\n",
        "        repo_id=repo_id,\n",
        "        token=token,\n",
        "        private=False,\n",
        "        exist_ok=True,\n",
        "    )\n",
        "  \n",
        "  with tempfile.TemporaryDirectory() as tmpdirname:\n",
        "    tmpdirname = Path(tmpdirname)\n",
        "\n",
        "    # Step 2: Save the model\n",
        "    torch.save(model.state_dict(), tmpdirname / \"model.pt\")\n",
        "  \n",
        "    # Step 3: Evaluate the model and build JSON\n",
        "    mean_reward, std_reward = _evaluate_agent(eval_env, \n",
        "                                           10, \n",
        "                                           model)\n",
        "\n",
        "    # First get datetime\n",
        "    eval_datetime = datetime.datetime.now()\n",
        "    eval_form_datetime = eval_datetime.isoformat()\n",
        "\n",
        "    evaluate_data = {\n",
        "        \"env_id\": hyperparameters.env_id, \n",
        "        \"mean_reward\": mean_reward,\n",
        "        \"std_reward\": std_reward,\n",
        "        \"n_evaluation_episodes\": 10,\n",
        "        \"eval_datetime\": eval_form_datetime,\n",
        "    }\n",
        " \n",
        "    # Write a JSON file\n",
        "    with open(tmpdirname / \"results.json\", \"w\") as outfile:\n",
        "      json.dump(evaluate_data, outfile)\n",
        "\n",
        "    # Step 4: Generate a video\n",
        "    video_path =  tmpdirname / \"replay.mp4\"\n",
        "    record_video(eval_env, model, video_path, video_fps)\n",
        "  \n",
        "    # Step 5: Generate the model card\n",
        "    generated_model_card, metadata = _generate_model_card(\"PPO\", hyperparameters.env_id, mean_reward, std_reward, hyperparameters)\n",
        "    _save_model_card(tmpdirname, generated_model_card, metadata)\n",
        "\n",
        "    # Step 6: Add logs if needed\n",
        "    if logs:\n",
        "      _add_logdir(tmpdirname, Path(logs))\n",
        "  \n",
        "    msg.info(f\"Pushing repo {repo_id} to the Hugging Face Hub\")\n",
        "  \n",
        "    repo_url = upload_folder(\n",
        "            repo_id=repo_id,\n",
        "            folder_path=tmpdirname,\n",
        "            path_in_repo=\"\",\n",
        "            commit_message=commit_message,\n",
        "            token=token,\n",
        "        )\n",
        "\n",
        "    msg.info(f\"Your model is pushed to the Hub. You can view your model here: {repo_url}\")\n",
        "  return repo_url\n",
        "\n",
        "\n",
        "def _evaluate_agent(env, n_eval_episodes, policy):\n",
        "  \"\"\"\n",
        "  Evaluate the agent for ``n_eval_episodes`` episodes and returns average reward and std of reward.\n",
        "  :param env: The evaluation environment\n",
        "  :param n_eval_episodes: Number of episode to evaluate the agent\n",
        "  :param policy: The agent\n",
        "  \"\"\"\n",
        "  episode_rewards = []\n",
        "  for episode in range(n_eval_episodes):\n",
        "    state = env.reset()\n",
        "    step = 0\n",
        "    done = False\n",
        "    total_rewards_ep = 0\n",
        "    \n",
        "    while done is False:\n",
        "      state = torch.Tensor(state).to(device)\n",
        "      action, _, _, _ = policy.get_action_and_value(state)\n",
        "      new_state, reward, done, info = env.step(action.cpu().numpy())\n",
        "      total_rewards_ep += reward    \n",
        "      if done:\n",
        "        break\n",
        "      state = new_state\n",
        "    episode_rewards.append(total_rewards_ep)\n",
        "  mean_reward = np.mean(episode_rewards)\n",
        "  std_reward = np.std(episode_rewards)\n",
        "\n",
        "  return mean_reward, std_reward\n",
        "\n",
        "\n",
        "def record_video(env, policy, out_directory, fps=30):\n",
        "  images = []  \n",
        "  done = False\n",
        "  state = env.reset()\n",
        "  img = env.render(mode='rgb_array')\n",
        "  images.append(img)\n",
        "  while not done:\n",
        "    state = torch.Tensor(state).to(device)\n",
        "    # Take the action (index) that have the maximum expected future reward given that state\n",
        "    action, _, _, _  = policy.get_action_and_value(state)\n",
        "    state, reward, done, info = env.step(action.cpu().numpy()) # We directly put next_state = state for recording logic\n",
        "    img = env.render(mode='rgb_array')\n",
        "    images.append(img)\n",
        "  imageio.mimsave(out_directory, [np.array(img) for i, img in enumerate(images)], fps=fps)\n",
        "\n",
        "\n",
        "def _generate_model_card(model_name, env_id, mean_reward, std_reward, hyperparameters):\n",
        "  \"\"\"\n",
        "  Generate the model card for the Hub\n",
        "  :param model_name: name of the model\n",
        "  :env_id: name of the environment\n",
        "  :mean_reward: mean reward of the agent\n",
        "  :std_reward: standard deviation of the mean reward of the agent\n",
        "  :hyperparameters: training arguments\n",
        "  \"\"\"\n",
        "  # Step 1: Select the tags\n",
        "  metadata = generate_metadata(model_name, env_id, mean_reward, std_reward)\n",
        "\n",
        "  # Transform the hyperparams namespace to string\n",
        "  converted_dict = vars(hyperparameters)\n",
        "  converted_str = str(converted_dict)\n",
        "  converted_str = converted_str.split(\", \")\n",
        "  converted_str = '\\n'.join(converted_str)\n",
        " \n",
        "  # Step 2: Generate the model card\n",
        "  model_card = f\"\"\"\n",
        "  # PPO Agent Playing {env_id}\n",
        "\n",
        "  This is a trained model of a PPO agent playing {env_id}.\n",
        "    \n",
        "  # Hyperparameters\n",
        "  ```python\n",
        "  {converted_str}\n",
        "  ```\n",
        "  \"\"\"\n",
        "  return model_card, metadata\n",
        "\n",
        "\n",
        "def generate_metadata(model_name, env_id, mean_reward, std_reward):\n",
        "  \"\"\"\n",
        "  Define the tags for the model card\n",
        "  :param model_name: name of the model\n",
        "  :param env_id: name of the environment\n",
        "  :mean_reward: mean reward of the agent\n",
        "  :std_reward: standard deviation of the mean reward of the agent\n",
        "  \"\"\"\n",
        "  metadata = {}\n",
        "  metadata[\"tags\"] = [\n",
        "        env_id,\n",
        "        \"ppo\",\n",
        "        \"deep-reinforcement-learning\",\n",
        "        \"reinforcement-learning\",\n",
        "        \"custom-implementation\",\n",
        "        \"deep-rl-course\"\n",
        "  ]\n",
        "\n",
        "  # Add metrics\n",
        "  eval = metadata_eval_result(\n",
        "      model_pretty_name=model_name,\n",
        "      task_pretty_name=\"reinforcement-learning\",\n",
        "      task_id=\"reinforcement-learning\",\n",
        "      metrics_pretty_name=\"mean_reward\",\n",
        "      metrics_id=\"mean_reward\",\n",
        "      metrics_value=f\"{mean_reward:.2f} +/- {std_reward:.2f}\",\n",
        "      dataset_pretty_name=env_id,\n",
        "      dataset_id=env_id,\n",
        "  )\n",
        "\n",
        "  # Merges both dictionaries\n",
        "  metadata = {**metadata, **eval}\n",
        "\n",
        "  return metadata\n",
        "\n",
        "\n",
        "def _save_model_card(local_path, generated_model_card, metadata):\n",
        "    \"\"\"Saves a model card for the repository.\n",
        "    :param local_path: repository directory\n",
        "    :param generated_model_card: model card generated by _generate_model_card()\n",
        "    :param metadata: metadata\n",
        "    \"\"\"\n",
        "    readme_path = local_path / \"README.md\"\n",
        "    readme = \"\"\n",
        "    if readme_path.exists():\n",
        "        with readme_path.open(\"r\", encoding=\"utf8\") as f:\n",
        "            readme = f.read()\n",
        "    else:\n",
        "        readme = generated_model_card\n",
        "\n",
        "    with readme_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(readme)\n",
        "\n",
        "    # Save our metrics to Readme metadata\n",
        "    metadata_save(readme_path, metadata)\n",
        "\n",
        "\n",
        "def _add_logdir(local_path: Path, logdir: Path):\n",
        "  \"\"\"Adds a logdir to the repository.\n",
        "  :param local_path: repository directory\n",
        "  :param logdir: logdir directory\n",
        "  \"\"\"\n",
        "  if logdir.exists() and logdir.is_dir():\n",
        "    # Add the logdir to the repository under new dir called logs\n",
        "    repo_logdir = local_path / \"logs\"\n",
        "    \n",
        "    # Delete current logs if they exist\n",
        "    if repo_logdir.exists():\n",
        "      shutil.rmtree(repo_logdir)\n",
        "\n",
        "    # Copy logdir into repo logdir\n",
        "    shutil.copytree(logdir, repo_logdir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqX8z8_rooD6"
      },
      "source": [
        "- Finally, we call this function at the end of the PPO training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8V1vNiTo2hL"
      },
      "outputs": [],
      "source": [
        "# Create the evaluation environment\n",
        "eval_env = gym.make(args.env_id)\n",
        "\n",
        "package_to_hub(repo_id = args.repo_id,\n",
        "                model = agent, # The model we want to save\n",
        "                hyperparameters = args,\n",
        "                eval_env = gym.make(args.env_id),\n",
        "                logs= f\"runs/{run_name}\",\n",
        "                )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muCCzed4o5TC"
      },
      "source": [
        "- Here's what look the ppo.py final file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LviRdtXgo7kF"
      },
      "outputs": [],
      "source": [
        "# docs and experiment results can be found at https://docs.cleanrl.dev/rl-algorithms/ppo/#ppopy\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "from distutils.util import strtobool\n",
        "\n",
        "import gym\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.distributions.categorical import Categorical\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from huggingface_hub import HfApi, upload_folder\n",
        "from huggingface_hub.repocard import metadata_eval_result, metadata_save\n",
        "\n",
        "from pathlib import Path\n",
        "import datetime\n",
        "import tempfile\n",
        "import json\n",
        "import shutil\n",
        "import imageio\n",
        "\n",
        "from wasabi import Printer\n",
        "msg = Printer()\n",
        "\n",
        "def parse_args():\n",
        "    # fmt: off\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--exp-name\", type=str, default=os.path.basename(__file__).rstrip(\".py\"),\n",
        "        help=\"the name of this experiment\")\n",
        "    parser.add_argument(\"--seed\", type=int, default=1,\n",
        "        help=\"seed of the experiment\")\n",
        "    parser.add_argument(\"--torch-deterministic\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
        "        help=\"if toggled, `torch.backends.cudnn.deterministic=False`\")\n",
        "    parser.add_argument(\"--cuda\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
        "        help=\"if toggled, cuda will be enabled by default\")\n",
        "    parser.add_argument(\"--track\", type=lambda x: bool(strtobool(x)), default=False, nargs=\"?\", const=True,\n",
        "        help=\"if toggled, this experiment will be tracked with Weights and Biases\")\n",
        "    parser.add_argument(\"--wandb-project-name\", type=str, default=\"cleanRL\",\n",
        "        help=\"the wandb's project name\")\n",
        "    parser.add_argument(\"--wandb-entity\", type=str, default=None,\n",
        "        help=\"the entity (team) of wandb's project\")\n",
        "    parser.add_argument(\"--capture-video\", type=lambda x: bool(strtobool(x)), default=False, nargs=\"?\", const=True,\n",
        "        help=\"weather to capture videos of the agent performances (check out `videos` folder)\")\n",
        "\n",
        "    # Algorithm specific arguments\n",
        "    parser.add_argument(\"--env-id\", type=str, default=\"CartPole-v1\",\n",
        "        help=\"the id of the environment\")\n",
        "    parser.add_argument(\"--total-timesteps\", type=int, default=50000,\n",
        "        help=\"total timesteps of the experiments\")\n",
        "    parser.add_argument(\"--learning-rate\", type=float, default=2.5e-4,\n",
        "        help=\"the learning rate of the optimizer\")\n",
        "    parser.add_argument(\"--num-envs\", type=int, default=4,\n",
        "        help=\"the number of parallel game environments\")\n",
        "    parser.add_argument(\"--num-steps\", type=int, default=128,\n",
        "        help=\"the number of steps to run in each environment per policy rollout\")\n",
        "    parser.add_argument(\"--anneal-lr\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
        "        help=\"Toggle learning rate annealing for policy and value networks\")\n",
        "    parser.add_argument(\"--gae\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
        "        help=\"Use GAE for advantage computation\")\n",
        "    parser.add_argument(\"--gamma\", type=float, default=0.99,\n",
        "        help=\"the discount factor gamma\")\n",
        "    parser.add_argument(\"--gae-lambda\", type=float, default=0.95,\n",
        "        help=\"the lambda for the general advantage estimation\")\n",
        "    parser.add_argument(\"--num-minibatches\", type=int, default=4,\n",
        "        help=\"the number of mini-batches\")\n",
        "    parser.add_argument(\"--update-epochs\", type=int, default=4,\n",
        "        help=\"the K epochs to update the policy\")\n",
        "    parser.add_argument(\"--norm-adv\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
        "        help=\"Toggles advantages normalization\")\n",
        "    parser.add_argument(\"--clip-coef\", type=float, default=0.2,\n",
        "        help=\"the surrogate clipping coefficient\")\n",
        "    parser.add_argument(\"--clip-vloss\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
        "        help=\"Toggles whether or not to use a clipped loss for the value function, as per the paper.\")\n",
        "    parser.add_argument(\"--ent-coef\", type=float, default=0.01,\n",
        "        help=\"coefficient of the entropy\")\n",
        "    parser.add_argument(\"--vf-coef\", type=float, default=0.5,\n",
        "        help=\"coefficient of the value function\")\n",
        "    parser.add_argument(\"--max-grad-norm\", type=float, default=0.5,\n",
        "        help=\"the maximum norm for the gradient clipping\")\n",
        "    parser.add_argument(\"--target-kl\", type=float, default=None,\n",
        "        help=\"the target KL divergence threshold\")\n",
        "    \n",
        "    # Adding HuggingFace argument\n",
        "    parser.add_argument(\"--repo-id\", type=str, default=\"QuickSilver007/rl2v2unit8_ppo-CartPole-v1\", help=\"id of the model repository from the Hugging Face Hub {username/repo_name}\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    args.batch_size = int(args.num_envs * args.num_steps)\n",
        "    args.minibatch_size = int(args.batch_size // args.num_minibatches)\n",
        "    # fmt: on\n",
        "    return args\n",
        "\n",
        "def package_to_hub(repo_id, \n",
        "                model,\n",
        "                hyperparameters,\n",
        "                eval_env,\n",
        "                video_fps=30,\n",
        "                commit_message=\"Push agent to the Hub\",\n",
        "                token= None,\n",
        "                logs=None\n",
        "                ):\n",
        "  \"\"\"\n",
        "  Evaluate, Generate a video and Upload a model to Hugging Face Hub.\n",
        "  This method does the complete pipeline:\n",
        "  - It evaluates the model\n",
        "  - It generates the model card\n",
        "  - It generates a replay video of the agent\n",
        "  - It pushes everything to the hub\n",
        "  :param repo_id: id of the model repository from the Hugging Face Hub\n",
        "  :param model: trained model\n",
        "  :param eval_env: environment used to evaluate the agent\n",
        "  :param fps: number of fps for rendering the video\n",
        "  :param commit_message: commit message\n",
        "  :param logs: directory on local machine of tensorboard logs you'd like to upload\n",
        "  \"\"\"\n",
        "  msg.info(\n",
        "        \"This function will save, evaluate, generate a video of your agent, \"\n",
        "        \"create a model card and push everything to the hub. \"\n",
        "        \"It might take up to 1min. \\n \"\n",
        "        \"This is a work in progress: if you encounter a bug, please open an issue.\"\n",
        "    )\n",
        "  # Step 1: Clone or create the repo\n",
        "  repo_url = HfApi().create_repo(\n",
        "        repo_id=repo_id,\n",
        "        token=token,\n",
        "        private=False,\n",
        "        exist_ok=True,\n",
        "    )\n",
        "  \n",
        "  with tempfile.TemporaryDirectory() as tmpdirname:\n",
        "    tmpdirname = Path(tmpdirname)\n",
        "\n",
        "    # Step 2: Save the model\n",
        "    torch.save(model.state_dict(), tmpdirname / \"model.pt\")\n",
        "  \n",
        "    # Step 3: Evaluate the model and build JSON\n",
        "    mean_reward, std_reward = _evaluate_agent(eval_env, \n",
        "                                           10, \n",
        "                                           model)\n",
        "\n",
        "    # First get datetime\n",
        "    eval_datetime = datetime.datetime.now()\n",
        "    eval_form_datetime = eval_datetime.isoformat()\n",
        "\n",
        "    evaluate_data = {\n",
        "        \"env_id\": hyperparameters.env_id, \n",
        "        \"mean_reward\": mean_reward,\n",
        "        \"std_reward\": std_reward,\n",
        "        \"n_evaluation_episodes\": 10,\n",
        "        \"eval_datetime\": eval_form_datetime,\n",
        "    }\n",
        " \n",
        "    # Write a JSON file\n",
        "    with open(tmpdirname / \"results.json\", \"w\") as outfile:\n",
        "      json.dump(evaluate_data, outfile)\n",
        "\n",
        "    # Step 4: Generate a video\n",
        "    video_path =  tmpdirname / \"replay.mp4\"\n",
        "    record_video(eval_env, model, video_path, video_fps)\n",
        "  \n",
        "    # Step 5: Generate the model card\n",
        "    generated_model_card, metadata = _generate_model_card(\"PPO\", hyperparameters.env_id, mean_reward, std_reward, hyperparameters)\n",
        "    _save_model_card(tmpdirname, generated_model_card, metadata)\n",
        "\n",
        "    # Step 6: Add logs if needed\n",
        "    if logs:\n",
        "      _add_logdir(tmpdirname, Path(logs))\n",
        "  \n",
        "    msg.info(f\"Pushing repo {repo_id} to the Hugging Face Hub\")\n",
        "  \n",
        "    repo_url = upload_folder(\n",
        "            repo_id=repo_id,\n",
        "            folder_path=tmpdirname,\n",
        "            path_in_repo=\"\",\n",
        "            commit_message=commit_message,\n",
        "            token=token,\n",
        "        )\n",
        "\n",
        "    msg.info(f\"Your model is pushed to the Hub. You can view your model here: {repo_url}\")\n",
        "  return repo_url\n",
        "\n",
        "def _evaluate_agent(env, n_eval_episodes, policy):\n",
        "  \"\"\"\n",
        "  Evaluate the agent for ``n_eval_episodes`` episodes and returns average reward and std of reward.\n",
        "  :param env: The evaluation environment\n",
        "  :param n_eval_episodes: Number of episode to evaluate the agent\n",
        "  :param policy: The agent\n",
        "  \"\"\"\n",
        "  episode_rewards = []\n",
        "  for episode in range(n_eval_episodes):\n",
        "    state = env.reset()\n",
        "    step = 0\n",
        "    done = False\n",
        "    total_rewards_ep = 0\n",
        "    \n",
        "    while done is False:\n",
        "      state = torch.Tensor(state).to(device)\n",
        "      action, _, _, _ = policy.get_action_and_value(state)\n",
        "      new_state, reward, done, info = env.step(action.cpu().numpy())\n",
        "      total_rewards_ep += reward    \n",
        "      if done:\n",
        "        break\n",
        "      state = new_state\n",
        "    episode_rewards.append(total_rewards_ep)\n",
        "  mean_reward = np.mean(episode_rewards)\n",
        "  std_reward = np.std(episode_rewards)\n",
        "\n",
        "  return mean_reward, std_reward\n",
        "\n",
        "\n",
        "def record_video(env, policy, out_directory, fps=30):\n",
        "  images = []  \n",
        "  done = False\n",
        "  state = env.reset()\n",
        "  img = env.render(mode='rgb_array')\n",
        "  images.append(img)\n",
        "  while not done:\n",
        "    state = torch.Tensor(state).to(device)\n",
        "    # Take the action (index) that have the maximum expected future reward given that state\n",
        "    action, _, _, _  = policy.get_action_and_value(state)\n",
        "    state, reward, done, info = env.step(action.cpu().numpy()) # We directly put next_state = state for recording logic\n",
        "    img = env.render(mode='rgb_array')\n",
        "    images.append(img)\n",
        "  imageio.mimsave(out_directory, [np.array(img) for i, img in enumerate(images)], fps=fps)\n",
        "\n",
        "\n",
        "def _generate_model_card(model_name, env_id, mean_reward, std_reward, hyperparameters):\n",
        "  \"\"\"\n",
        "  Generate the model card for the Hub\n",
        "  :param model_name: name of the model\n",
        "  :env_id: name of the environment\n",
        "  :mean_reward: mean reward of the agent\n",
        "  :std_reward: standard deviation of the mean reward of the agent\n",
        "  :hyperparameters: training arguments\n",
        "  \"\"\"\n",
        "  # Step 1: Select the tags\n",
        "  metadata = generate_metadata(model_name, env_id, mean_reward, std_reward)\n",
        "\n",
        "  # Transform the hyperparams namespace to string\n",
        "  converted_dict = vars(hyperparameters)\n",
        "  converted_str = str(converted_dict)\n",
        "  converted_str = converted_str.split(\", \")\n",
        "  converted_str = '\\n'.join(converted_str)\n",
        " \n",
        "  # Step 2: Generate the model card\n",
        "  model_card = f\"\"\"\n",
        "  # PPO Agent Playing {env_id}\n",
        "\n",
        "  This is a trained model of a PPO agent playing {env_id}.\n",
        "    \n",
        "  # Hyperparameters\n",
        "  ```python\n",
        "  {converted_str}\n",
        "  ```\n",
        "  \"\"\"\n",
        "  return model_card, metadata\n",
        "\n",
        "def generate_metadata(model_name, env_id, mean_reward, std_reward):\n",
        "  \"\"\"\n",
        "  Define the tags for the model card\n",
        "  :param model_name: name of the model\n",
        "  :param env_id: name of the environment\n",
        "  :mean_reward: mean reward of the agent\n",
        "  :std_reward: standard deviation of the mean reward of the agent\n",
        "  \"\"\"\n",
        "  metadata = {}\n",
        "  metadata[\"tags\"] = [\n",
        "        env_id,\n",
        "        \"ppo\",\n",
        "        \"deep-reinforcement-learning\",\n",
        "        \"reinforcement-learning\",\n",
        "        \"custom-implementation\",\n",
        "        \"deep-rl-course\"\n",
        "  ]\n",
        "\n",
        "  # Add metrics\n",
        "  eval = metadata_eval_result(\n",
        "      model_pretty_name=model_name,\n",
        "      task_pretty_name=\"reinforcement-learning\",\n",
        "      task_id=\"reinforcement-learning\",\n",
        "      metrics_pretty_name=\"mean_reward\",\n",
        "      metrics_id=\"mean_reward\",\n",
        "      metrics_value=f\"{mean_reward:.2f} +/- {std_reward:.2f}\",\n",
        "      dataset_pretty_name=env_id,\n",
        "      dataset_id=env_id,\n",
        "  )\n",
        "\n",
        "  # Merges both dictionaries\n",
        "  metadata = {**metadata, **eval}\n",
        "\n",
        "  return metadata\n",
        "\n",
        "def _save_model_card(local_path, generated_model_card, metadata):\n",
        "    \"\"\"Saves a model card for the repository.\n",
        "    :param local_path: repository directory\n",
        "    :param generated_model_card: model card generated by _generate_model_card()\n",
        "    :param metadata: metadata\n",
        "    \"\"\"\n",
        "    readme_path = local_path / \"README.md\"\n",
        "    readme = \"\"\n",
        "    if readme_path.exists():\n",
        "        with readme_path.open(\"r\", encoding=\"utf8\") as f:\n",
        "            readme = f.read()\n",
        "    else:\n",
        "        readme = generated_model_card\n",
        "\n",
        "    with readme_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(readme)\n",
        "\n",
        "    # Save our metrics to Readme metadata\n",
        "    metadata_save(readme_path, metadata)\n",
        "\n",
        "def _add_logdir(local_path: Path, logdir: Path):\n",
        "  \"\"\"Adds a logdir to the repository.\n",
        "  :param local_path: repository directory\n",
        "  :param logdir: logdir directory\n",
        "  \"\"\"\n",
        "  if logdir.exists() and logdir.is_dir():\n",
        "    # Add the logdir to the repository under new dir called logs\n",
        "    repo_logdir = local_path / \"logs\"\n",
        "    \n",
        "    # Delete current logs if they exist\n",
        "    if repo_logdir.exists():\n",
        "      shutil.rmtree(repo_logdir)\n",
        "\n",
        "    # Copy logdir into repo logdir\n",
        "    shutil.copytree(logdir, repo_logdir)\n",
        "\n",
        "def make_env(env_id, seed, idx, capture_video, run_name):\n",
        "    def thunk():\n",
        "        env = gym.make(env_id)\n",
        "        env = gym.wrappers.RecordEpisodeStatistics(env)\n",
        "        if capture_video:\n",
        "            if idx == 0:\n",
        "                env = gym.wrappers.RecordVideo(env, f\"videos/{run_name}\")\n",
        "        env.seed(seed)\n",
        "        env.action_space.seed(seed)\n",
        "        env.observation_space.seed(seed)\n",
        "        return env\n",
        "\n",
        "    return thunk\n",
        "\n",
        "\n",
        "def layer_init(layer, std=np.sqrt(2), bias_const=0.0):\n",
        "    torch.nn.init.orthogonal_(layer.weight, std)\n",
        "    torch.nn.init.constant_(layer.bias, bias_const)\n",
        "    return layer\n",
        "\n",
        "\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, envs):\n",
        "        super().__init__()\n",
        "        self.critic = nn.Sequential(\n",
        "            layer_init(nn.Linear(np.array(envs.single_observation_space.shape).prod(), 64)),\n",
        "            nn.Tanh(),\n",
        "            layer_init(nn.Linear(64, 64)),\n",
        "            nn.Tanh(),\n",
        "            layer_init(nn.Linear(64, 1), std=1.0),\n",
        "        )\n",
        "        self.actor = nn.Sequential(\n",
        "            layer_init(nn.Linear(np.array(envs.single_observation_space.shape).prod(), 64)),\n",
        "            nn.Tanh(),\n",
        "            layer_init(nn.Linear(64, 64)),\n",
        "            nn.Tanh(),\n",
        "            layer_init(nn.Linear(64, envs.single_action_space.n), std=0.01),\n",
        "        )\n",
        "\n",
        "    def get_value(self, x):\n",
        "        return self.critic(x)\n",
        "\n",
        "    def get_action_and_value(self, x, action=None):\n",
        "        logits = self.actor(x)\n",
        "        probs = Categorical(logits=logits)\n",
        "        if action is None:\n",
        "            action = probs.sample()\n",
        "        return action, probs.log_prob(action), probs.entropy(), self.critic(x)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    args = parse_args()\n",
        "    run_name = f\"{args.env_id}__{args.exp_name}__{args.seed}__{int(time.time())}\"\n",
        "    if args.track:\n",
        "        import wandb\n",
        "\n",
        "        wandb.init(\n",
        "            project=args.wandb_project_name,\n",
        "            entity=args.wandb_entity,\n",
        "            sync_tensorboard=True,\n",
        "            config=vars(args),\n",
        "            name=run_name,\n",
        "            monitor_gym=True,\n",
        "            save_code=True,\n",
        "        )\n",
        "    writer = SummaryWriter(f\"runs/{run_name}\")\n",
        "    writer.add_text(\n",
        "        \"hyperparameters\",\n",
        "        \"|param|value|\\n|-|-|\\n%s\" % (\"\\n\".join([f\"|{key}|{value}|\" for key, value in vars(args).items()])),\n",
        "    )\n",
        "\n",
        "    # TRY NOT TO MODIFY: seeding\n",
        "    random.seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    torch.backends.cudnn.deterministic = args.torch_deterministic\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() and args.cuda else \"cpu\")\n",
        "\n",
        "    # env setup\n",
        "    envs = gym.vector.SyncVectorEnv(\n",
        "        [make_env(args.env_id, args.seed + i, i, args.capture_video, run_name) for i in range(args.num_envs)]\n",
        "    )\n",
        "    assert isinstance(envs.single_action_space, gym.spaces.Discrete), \"only discrete action space is supported\"\n",
        "\n",
        "    agent = Agent(envs).to(device)\n",
        "    optimizer = optim.Adam(agent.parameters(), lr=args.learning_rate, eps=1e-5)\n",
        "\n",
        "    # ALGO Logic: Storage setup\n",
        "    obs = torch.zeros((args.num_steps, args.num_envs) + envs.single_observation_space.shape).to(device)\n",
        "    actions = torch.zeros((args.num_steps, args.num_envs) + envs.single_action_space.shape).to(device)\n",
        "    logprobs = torch.zeros((args.num_steps, args.num_envs)).to(device)\n",
        "    rewards = torch.zeros((args.num_steps, args.num_envs)).to(device)\n",
        "    dones = torch.zeros((args.num_steps, args.num_envs)).to(device)\n",
        "    values = torch.zeros((args.num_steps, args.num_envs)).to(device)\n",
        "\n",
        "    # TRY NOT TO MODIFY: start the game\n",
        "    global_step = 0\n",
        "    start_time = time.time()\n",
        "    next_obs = torch.Tensor(envs.reset()).to(device)\n",
        "    next_done = torch.zeros(args.num_envs).to(device)\n",
        "    num_updates = args.total_timesteps // args.batch_size\n",
        "\n",
        "    for update in range(1, num_updates + 1):\n",
        "        # Annealing the rate if instructed to do so.\n",
        "        if args.anneal_lr:\n",
        "            frac = 1.0 - (update - 1.0) / num_updates\n",
        "            lrnow = frac * args.learning_rate\n",
        "            optimizer.param_groups[0][\"lr\"] = lrnow\n",
        "\n",
        "        for step in range(0, args.num_steps):\n",
        "            global_step += 1 * args.num_envs\n",
        "            obs[step] = next_obs\n",
        "            dones[step] = next_done\n",
        "\n",
        "            # ALGO LOGIC: action logic\n",
        "            with torch.no_grad():\n",
        "                action, logprob, _, value = agent.get_action_and_value(next_obs)\n",
        "                values[step] = value.flatten()\n",
        "            actions[step] = action\n",
        "            logprobs[step] = logprob\n",
        "\n",
        "            # TRY NOT TO MODIFY: execute the game and log data.\n",
        "            next_obs, reward, done, info = envs.step(action.cpu().numpy())\n",
        "            rewards[step] = torch.tensor(reward).to(device).view(-1)\n",
        "            next_obs, next_done = torch.Tensor(next_obs).to(device), torch.Tensor(done).to(device)\n",
        "\n",
        "            for item in info:\n",
        "                if \"episode\" in item.keys():\n",
        "                    print(f\"global_step={global_step}, episodic_return={item['episode']['r']}\")\n",
        "                    writer.add_scalar(\"charts/episodic_return\", item[\"episode\"][\"r\"], global_step)\n",
        "                    writer.add_scalar(\"charts/episodic_length\", item[\"episode\"][\"l\"], global_step)\n",
        "                    break\n",
        "\n",
        "        # bootstrap value if not done\n",
        "        with torch.no_grad():\n",
        "            next_value = agent.get_value(next_obs).reshape(1, -1)\n",
        "            if args.gae:\n",
        "                advantages = torch.zeros_like(rewards).to(device)\n",
        "                lastgaelam = 0\n",
        "                for t in reversed(range(args.num_steps)):\n",
        "                    if t == args.num_steps - 1:\n",
        "                        nextnonterminal = 1.0 - next_done\n",
        "                        nextvalues = next_value\n",
        "                    else:\n",
        "                        nextnonterminal = 1.0 - dones[t + 1]\n",
        "                        nextvalues = values[t + 1]\n",
        "                    delta = rewards[t] + args.gamma * nextvalues * nextnonterminal - values[t]\n",
        "                    advantages[t] = lastgaelam = delta + args.gamma * args.gae_lambda * nextnonterminal * lastgaelam\n",
        "                returns = advantages + values\n",
        "            else:\n",
        "                returns = torch.zeros_like(rewards).to(device)\n",
        "                for t in reversed(range(args.num_steps)):\n",
        "                    if t == args.num_steps - 1:\n",
        "                        nextnonterminal = 1.0 - next_done\n",
        "                        next_return = next_value\n",
        "                    else:\n",
        "                        nextnonterminal = 1.0 - dones[t + 1]\n",
        "                        next_return = returns[t + 1]\n",
        "                    returns[t] = rewards[t] + args.gamma * nextnonterminal * next_return\n",
        "                advantages = returns - values\n",
        "\n",
        "        # flatten the batch\n",
        "        b_obs = obs.reshape((-1,) + envs.single_observation_space.shape)\n",
        "        b_logprobs = logprobs.reshape(-1)\n",
        "        b_actions = actions.reshape((-1,) + envs.single_action_space.shape)\n",
        "        b_advantages = advantages.reshape(-1)\n",
        "        b_returns = returns.reshape(-1)\n",
        "        b_values = values.reshape(-1)\n",
        "\n",
        "        # Optimizing the policy and value network\n",
        "        b_inds = np.arange(args.batch_size)\n",
        "        clipfracs = []\n",
        "        for epoch in range(args.update_epochs):\n",
        "            np.random.shuffle(b_inds)\n",
        "            for start in range(0, args.batch_size, args.minibatch_size):\n",
        "                end = start + args.minibatch_size\n",
        "                mb_inds = b_inds[start:end]\n",
        "\n",
        "                _, newlogprob, entropy, newvalue = agent.get_action_and_value(b_obs[mb_inds], b_actions.long()[mb_inds])\n",
        "                logratio = newlogprob - b_logprobs[mb_inds]\n",
        "                ratio = logratio.exp()\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    # calculate approx_kl http://joschu.net/blog/kl-approx.html\n",
        "                    old_approx_kl = (-logratio).mean()\n",
        "                    approx_kl = ((ratio - 1) - logratio).mean()\n",
        "                    clipfracs += [((ratio - 1.0).abs() > args.clip_coef).float().mean().item()]\n",
        "\n",
        "                mb_advantages = b_advantages[mb_inds]\n",
        "                if args.norm_adv:\n",
        "                    mb_advantages = (mb_advantages - mb_advantages.mean()) / (mb_advantages.std() + 1e-8)\n",
        "\n",
        "                # Policy loss\n",
        "                pg_loss1 = -mb_advantages * ratio\n",
        "                pg_loss2 = -mb_advantages * torch.clamp(ratio, 1 - args.clip_coef, 1 + args.clip_coef)\n",
        "                pg_loss = torch.max(pg_loss1, pg_loss2).mean()\n",
        "\n",
        "                # Value loss\n",
        "                newvalue = newvalue.view(-1)\n",
        "                if args.clip_vloss:\n",
        "                    v_loss_unclipped = (newvalue - b_returns[mb_inds]) ** 2\n",
        "                    v_clipped = b_values[mb_inds] + torch.clamp(\n",
        "                        newvalue - b_values[mb_inds],\n",
        "                        -args.clip_coef,\n",
        "                        args.clip_coef,\n",
        "                    )\n",
        "                    v_loss_clipped = (v_clipped - b_returns[mb_inds]) ** 2\n",
        "                    v_loss_max = torch.max(v_loss_unclipped, v_loss_clipped)\n",
        "                    v_loss = 0.5 * v_loss_max.mean()\n",
        "                else:\n",
        "                    v_loss = 0.5 * ((newvalue - b_returns[mb_inds]) ** 2).mean()\n",
        "\n",
        "                entropy_loss = entropy.mean()\n",
        "                loss = pg_loss - args.ent_coef * entropy_loss + v_loss * args.vf_coef\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                nn.utils.clip_grad_norm_(agent.parameters(), args.max_grad_norm)\n",
        "                optimizer.step()\n",
        "\n",
        "            if args.target_kl is not None:\n",
        "                if approx_kl > args.target_kl:\n",
        "                    break\n",
        "\n",
        "        y_pred, y_true = b_values.cpu().numpy(), b_returns.cpu().numpy()\n",
        "        var_y = np.var(y_true)\n",
        "        explained_var = np.nan if var_y == 0 else 1 - np.var(y_true - y_pred) / var_y\n",
        "\n",
        "        # TRY NOT TO MODIFY: record rewards for plotting purposes\n",
        "        writer.add_scalar(\"charts/learning_rate\", optimizer.param_groups[0][\"lr\"], global_step)\n",
        "        writer.add_scalar(\"losses/value_loss\", v_loss.item(), global_step)\n",
        "        writer.add_scalar(\"losses/policy_loss\", pg_loss.item(), global_step)\n",
        "        writer.add_scalar(\"losses/entropy\", entropy_loss.item(), global_step)\n",
        "        writer.add_scalar(\"losses/old_approx_kl\", old_approx_kl.item(), global_step)\n",
        "        writer.add_scalar(\"losses/approx_kl\", approx_kl.item(), global_step)\n",
        "        writer.add_scalar(\"losses/clipfrac\", np.mean(clipfracs), global_step)\n",
        "        writer.add_scalar(\"losses/explained_variance\", explained_var, global_step)\n",
        "        print(\"SPS:\", int(global_step / (time.time() - start_time)))\n",
        "        writer.add_scalar(\"charts/SPS\", int(global_step / (time.time() - start_time)), global_step)\n",
        "\n",
        "    envs.close()\n",
        "    writer.close()\n",
        "\n",
        "    # Create the evaluation environment\n",
        "    eval_env = gym.make(args.env_id)\n",
        "\n",
        "    package_to_hub(repo_id = args.repo_id,\n",
        "                model = agent, # The model we want to save\n",
        "                hyperparameters = args,\n",
        "                eval_env = gym.make(args.env_id),\n",
        "                logs= f\"runs/{run_name}\",\n",
        "                )\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JquRrWytA6eo"
      },
      "source": [
        "To be able to share your model with the community there are three more steps to follow:\n",
        "\n",
        "1Ô∏è‚É£ (If it's not already done) create an account to HF ‚û° https://huggingface.co/join\n",
        "\n",
        "2Ô∏è‚É£ Sign in and then, you need to store your authentication token from the Hugging Face website.\n",
        "- Create a new token (https://huggingface.co/settings/tokens) **with write role**\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/create-token.jpg\" alt=\"Create HF Token\">\n",
        "\n",
        "- Copy the token \n",
        "- Run the cell below and paste the token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GZiFBBlzxzxY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "6c8583681c3f49e3a853edef77cac551",
            "81f83c6288aa4aa78e60c22e89b4286a",
            "d0882b870e294a82917e6927e47ee8cc",
            "f870d9f9dd114886b1fdd155d3fdda6d",
            "31d9a98c5f5a4add9ddee7c417371230",
            "224fc3066a4e473291f74be46501c210",
            "2daf2824e5e94f5ea03961bbe23aff27",
            "64c5e9265b724ef3bd78af1c2d82a40a",
            "ac0d599cf7d34d7cba7a3b5bb84a60c9",
            "5fff87e93c2a44e0914587724387f358",
            "d8848dcbd4a84ce2b44f853fcea46918",
            "e54fb8d3646a420e8dcb706b2479b0cb",
            "8cca2a9dcf064b82ad530063cf426e54",
            "333573acb4bc48dba4e6ee02fa636a9c",
            "9e4301aec28e45f8bce297463c5a43ed",
            "294704d14de149ca9d5c9d0e64236931",
            "710a727749ac4b60b6252ff3412c8a51",
            "99564c26504c4c8091ef396a6e5c4521",
            "5c055104496f4f4bb7edc84e2e61fdfb",
            "6f5d03f184dd42bfa3d0ce24b2d74c00",
            "8d7c286d9d5a4b1ab846eb377c367fa5",
            "14a9bdeef8964ce69d93fe5701aa19cd",
            "9f91f8d71ecb4c17a4f6435a4ccc19af",
            "087b6d05646341a4ad3643f5fd604d5f",
            "c371cb058acc42b88607ab9e1af3c351",
            "543240d77185406993b2add823e9c1fe",
            "9f28383ec57d45f7b3f2c148857146a9",
            "01355e25b7da48db9fa909c3841d6f5c",
            "386b39685fe64013b1cafad3d89918d3",
            "1d2dd42df2b543338f65f83354b541aa",
            "9ff12b57896f49f6a2e82167588602fc",
            "4ac626e0518f4bbb9c74005c0d5b2a10"
          ]
        },
        "outputId": "6de97371-7e72-4559-9382-1c85792a3c52"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c8583681c3f49e3a853edef77cac551"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()\n",
        "!git config --global credential.helper store"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tsf2uv0g_4p"
      },
      "source": [
        "If you don't want to use a Google Colab or a Jupyter Notebook, you need to use this command instead: `huggingface-cli login`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRqkGvk7pFQ6"
      },
      "source": [
        "## Let's start the training üî•\n",
        "- ‚ö†Ô∏è ‚ö†Ô∏è ‚ö†Ô∏è  Don't use **the same repo id with the one you used for the Unit 1** \n",
        "- Now that you've coded from scratch PPO and added the Hugging Face Integration, we're ready to start the training üî•"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tmEArP8ug2l"
      },
      "source": [
        "- First, you need to copy all your code to a file you create called `ppo.py`"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit9/step1.png\" alt=\"PPO\"/>"
      ],
      "metadata": {
        "id": "Sq0My0LOjPYR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit9/step2.png\" alt=\"PPO\"/>"
      ],
      "metadata": {
        "id": "A8C-Q5ZyjUe3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrS80GmMu_j5"
      },
      "source": [
        "- Now we just need to run this python script using `python <name-of-python-script>.py` with the additional parameters we defined with `argparse`\n",
        "\n",
        "- You should modify more hyperparameters otherwise the training will not be super stable."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python ppo.py --env-id=\"LunarLander-v2\" --repo-id=\"QuickSilver007/rl2v2unit8_ppo-CartPole-v1\" --total-timesteps=500000"
      ],
      "metadata": {
        "id": "KXLih6mKseBs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "073beabd-a5cb-477d-bcf4-7bdabb86c77e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-25 11:29:15.819091: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-25 11:29:17.089883: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "global_step=268, episodic_return=-211.7703857421875\n",
            "global_step=292, episodic_return=-82.17555236816406\n",
            "global_step=332, episodic_return=-117.72103881835938\n",
            "global_step=396, episodic_return=-266.8280944824219\n",
            "SPS: 505\n",
            "global_step=624, episodic_return=-138.3221893310547\n",
            "global_step=688, episodic_return=-207.28933715820312\n",
            "global_step=800, episodic_return=-110.49622344970703\n",
            "global_step=852, episodic_return=-155.33351135253906\n",
            "global_step=916, episodic_return=-205.8883819580078\n",
            "global_step=984, episodic_return=-68.13983154296875\n",
            "SPS: 716\n",
            "global_step=1076, episodic_return=-73.36843872070312\n",
            "global_step=1228, episodic_return=-199.31430053710938\n",
            "global_step=1256, episodic_return=-123.6518783569336\n",
            "global_step=1412, episodic_return=-259.53594970703125\n",
            "global_step=1528, episodic_return=-300.8560485839844\n",
            "SPS: 835\n",
            "global_step=1572, episodic_return=-195.32655334472656\n",
            "global_step=1684, episodic_return=-195.7460174560547\n",
            "global_step=1696, episodic_return=-114.40122985839844\n",
            "global_step=1780, episodic_return=-176.10885620117188\n",
            "global_step=1824, episodic_return=-57.63154602050781\n",
            "SPS: 914\n",
            "global_step=2092, episodic_return=-331.1439208984375\n",
            "global_step=2128, episodic_return=-378.2339172363281\n",
            "global_step=2240, episodic_return=-174.28829956054688\n",
            "global_step=2256, episodic_return=-400.1274108886719\n",
            "SPS: 965\n",
            "global_step=2568, episodic_return=-102.3829574584961\n",
            "global_step=2576, episodic_return=-500.38787841796875\n",
            "global_step=2684, episodic_return=-240.80870056152344\n",
            "global_step=2724, episodic_return=-353.93896484375\n",
            "global_step=2852, episodic_return=-190.5560302734375\n",
            "global_step=2884, episodic_return=-85.94679260253906\n",
            "global_step=3008, episodic_return=-208.89598083496094\n",
            "SPS: 1009\n",
            "global_step=3216, episodic_return=-73.61285400390625\n",
            "global_step=3276, episodic_return=-161.2835693359375\n",
            "global_step=3352, episodic_return=-91.8058090209961\n",
            "SPS: 1037\n",
            "global_step=3608, episodic_return=-123.38191223144531\n",
            "global_step=3612, episodic_return=-142.07603454589844\n",
            "global_step=3728, episodic_return=-117.09647369384766\n",
            "global_step=3732, episodic_return=-318.2276611328125\n",
            "global_step=3872, episodic_return=-126.6348876953125\n",
            "global_step=3928, episodic_return=-264.09344482421875\n",
            "global_step=3988, episodic_return=-229.62991333007812\n",
            "SPS: 1061\n",
            "global_step=4204, episodic_return=-150.57427978515625\n",
            "global_step=4240, episodic_return=-461.2374572753906\n",
            "global_step=4320, episodic_return=-258.60650634765625\n",
            "global_step=4404, episodic_return=-116.6824722290039\n",
            "global_step=4508, episodic_return=-152.61807250976562\n",
            "SPS: 1081\n",
            "global_step=4616, episodic_return=-426.1807861328125\n",
            "global_step=4628, episodic_return=-95.1292495727539\n",
            "global_step=4832, episodic_return=-102.75806427001953\n",
            "global_step=4960, episodic_return=-78.57405090332031\n",
            "global_step=5092, episodic_return=-212.12908935546875\n",
            "global_step=5100, episodic_return=-130.36477661132812\n",
            "SPS: 1094\n",
            "global_step=5140, episodic_return=-118.46503448486328\n",
            "global_step=5356, episodic_return=-320.7373352050781\n",
            "global_step=5436, episodic_return=-194.5828857421875\n",
            "global_step=5448, episodic_return=-350.4385070800781\n",
            "global_step=5472, episodic_return=-153.38677978515625\n",
            "SPS: 1085\n",
            "global_step=5732, episodic_return=-303.3362121582031\n",
            "global_step=5780, episodic_return=-94.46571350097656\n",
            "global_step=5832, episodic_return=-93.66807556152344\n",
            "global_step=5896, episodic_return=-319.04071044921875\n",
            "global_step=6132, episodic_return=-117.13848876953125\n",
            "global_step=6136, episodic_return=-134.13018798828125\n",
            "SPS: 1073\n",
            "global_step=6304, episodic_return=-307.49298095703125\n",
            "global_step=6328, episodic_return=-75.07951354980469\n",
            "global_step=6432, episodic_return=-149.43972778320312\n",
            "global_step=6484, episodic_return=-402.8076171875\n",
            "SPS: 1063\n",
            "global_step=6808, episodic_return=-255.737060546875\n",
            "global_step=6820, episodic_return=-72.34929656982422\n",
            "global_step=6936, episodic_return=-170.99514770507812\n",
            "global_step=6956, episodic_return=-117.1292495727539\n",
            "global_step=7112, episodic_return=-118.89468383789062\n",
            "global_step=7164, episodic_return=-171.75718688964844\n",
            "SPS: 1051\n",
            "global_step=7200, episodic_return=-108.21176147460938\n",
            "global_step=7416, episodic_return=-116.0070571899414\n",
            "global_step=7436, episodic_return=-220.81092834472656\n",
            "global_step=7500, episodic_return=-154.7963409423828\n",
            "global_step=7528, episodic_return=-147.6127471923828\n",
            "SPS: 1040\n",
            "global_step=7772, episodic_return=-99.91722869873047\n",
            "global_step=7796, episodic_return=-106.74697875976562\n",
            "global_step=7804, episodic_return=-100.08012390136719\n",
            "global_step=7856, episodic_return=-235.509765625\n",
            "global_step=8116, episodic_return=-213.961181640625\n",
            "global_step=8148, episodic_return=-154.99624633789062\n",
            "SPS: 1024\n",
            "global_step=8228, episodic_return=-224.66773986816406\n",
            "global_step=8324, episodic_return=-127.06689453125\n",
            "global_step=8460, episodic_return=-123.08806610107422\n",
            "global_step=8552, episodic_return=-149.17135620117188\n",
            "global_step=8576, episodic_return=-120.0771484375\n",
            "global_step=8592, episodic_return=-300.425537109375\n",
            "SPS: 1008\n",
            "global_step=8892, episodic_return=-38.87814712524414\n",
            "global_step=9000, episodic_return=-103.82239532470703\n",
            "global_step=9060, episodic_return=-190.47518920898438\n",
            "global_step=9068, episodic_return=-183.4873809814453\n",
            "SPS: 991\n",
            "global_step=9268, episodic_return=-109.17926025390625\n",
            "global_step=9336, episodic_return=-176.97427368164062\n",
            "global_step=9400, episodic_return=-147.6763153076172\n",
            "global_step=9452, episodic_return=-133.96218872070312\n",
            "global_step=9556, episodic_return=-139.20040893554688\n",
            "global_step=9664, episodic_return=-86.6394271850586\n",
            "global_step=9724, episodic_return=-99.6059799194336\n",
            "SPS: 975\n",
            "global_step=9848, episodic_return=-213.27682495117188\n",
            "global_step=9952, episodic_return=-185.65509033203125\n",
            "global_step=9992, episodic_return=-125.17420959472656\n",
            "global_step=9996, episodic_return=-110.6244888305664\n",
            "global_step=10152, episodic_return=-93.76022338867188\n",
            "SPS: 976\n",
            "global_step=10268, episodic_return=-87.34385681152344\n",
            "global_step=10308, episodic_return=-90.34424591064453\n",
            "global_step=10380, episodic_return=-124.6688461303711\n",
            "global_step=10416, episodic_return=-180.87295532226562\n",
            "global_step=10584, episodic_return=-119.42666625976562\n",
            "global_step=10628, episodic_return=-99.82502746582031\n",
            "global_step=10688, episodic_return=-257.99652099609375\n",
            "SPS: 983\n",
            "global_step=10796, episodic_return=-115.04842376708984\n",
            "global_step=11068, episodic_return=-132.644287109375\n",
            "global_step=11076, episodic_return=-161.50689697265625\n",
            "global_step=11144, episodic_return=-192.5733184814453\n",
            "SPS: 991\n",
            "global_step=11396, episodic_return=-70.74700927734375\n",
            "global_step=11440, episodic_return=-274.78118896484375\n",
            "global_step=11468, episodic_return=-426.3091735839844\n",
            "global_step=11600, episodic_return=-129.8217010498047\n",
            "global_step=11656, episodic_return=-256.5888671875\n",
            "global_step=11772, episodic_return=-91.0107192993164\n",
            "SPS: 998\n",
            "global_step=11796, episodic_return=-246.9517364501953\n",
            "global_step=12044, episodic_return=-133.91575622558594\n",
            "global_step=12120, episodic_return=-58.0318489074707\n",
            "global_step=12168, episodic_return=-128.26995849609375\n",
            "global_step=12200, episodic_return=-145.67425537109375\n",
            "SPS: 1008\n",
            "global_step=12328, episodic_return=-79.22097778320312\n",
            "global_step=12468, episodic_return=-170.7176971435547\n",
            "global_step=12472, episodic_return=-164.51504516601562\n",
            "global_step=12576, episodic_return=-268.7440185546875\n",
            "global_step=12692, episodic_return=-107.71829223632812\n",
            "global_step=12744, episodic_return=-63.89856719970703\n",
            "SPS: 1017\n",
            "global_step=12844, episodic_return=-124.54617309570312\n",
            "global_step=12856, episodic_return=-106.79534149169922\n",
            "global_step=13188, episodic_return=-96.9945068359375\n",
            "global_step=13208, episodic_return=-79.70831298828125\n",
            "global_step=13212, episodic_return=-234.03099060058594\n",
            "global_step=13244, episodic_return=-311.52288818359375\n",
            "SPS: 1023\n",
            "global_step=13488, episodic_return=-97.74441528320312\n",
            "global_step=13532, episodic_return=-40.77055740356445\n",
            "global_step=13548, episodic_return=-97.9156494140625\n",
            "global_step=13616, episodic_return=-176.19268798828125\n",
            "global_step=13812, episodic_return=-94.94111633300781\n",
            "SPS: 1031\n",
            "global_step=13928, episodic_return=-80.79181671142578\n",
            "global_step=13988, episodic_return=-109.41002655029297\n",
            "global_step=14000, episodic_return=-477.60943603515625\n",
            "global_step=14240, episodic_return=-152.3157958984375\n",
            "global_step=14304, episodic_return=-108.84136199951172\n",
            "global_step=14320, episodic_return=-80.25328063964844\n",
            "SPS: 1039\n",
            "global_step=14428, episodic_return=-382.9418029785156\n",
            "global_step=14628, episodic_return=-94.06193542480469\n",
            "global_step=14680, episodic_return=-138.93218994140625\n",
            "global_step=14748, episodic_return=-214.38157653808594\n",
            "SPS: 1045\n",
            "global_step=14956, episodic_return=-389.507568359375\n",
            "global_step=14980, episodic_return=-77.56552124023438\n",
            "global_step=15032, episodic_return=-268.06768798828125\n",
            "global_step=15048, episodic_return=-95.38529968261719\n",
            "global_step=15240, episodic_return=-141.6136474609375\n",
            "SPS: 1050\n",
            "global_step=15444, episodic_return=-94.72364044189453\n",
            "global_step=15500, episodic_return=-126.12117004394531\n",
            "global_step=15504, episodic_return=-102.02256774902344\n",
            "global_step=15648, episodic_return=-102.43756103515625\n",
            "global_step=15804, episodic_return=-82.92793273925781\n",
            "global_step=15872, episodic_return=-94.31559753417969\n",
            "SPS: 1054\n",
            "global_step=16020, episodic_return=-19.176925659179688\n",
            "global_step=16092, episodic_return=-91.9297103881836\n",
            "global_step=16136, episodic_return=-76.09026336669922\n",
            "global_step=16264, episodic_return=-281.7947692871094\n",
            "global_step=16320, episodic_return=-105.28343963623047\n",
            "SPS: 1059\n",
            "global_step=16472, episodic_return=-123.69017791748047\n",
            "global_step=16552, episodic_return=-2.7506866455078125\n",
            "global_step=16580, episodic_return=-73.32603454589844\n",
            "global_step=16596, episodic_return=-235.9828338623047\n",
            "SPS: 1064\n",
            "global_step=16904, episodic_return=-112.99451446533203\n",
            "global_step=16928, episodic_return=-181.18215942382812\n",
            "global_step=17028, episodic_return=-147.30276489257812\n",
            "global_step=17064, episodic_return=-130.32785034179688\n",
            "global_step=17128, episodic_return=-85.81192779541016\n",
            "global_step=17188, episodic_return=-52.104740142822266\n",
            "SPS: 1069\n",
            "global_step=17428, episodic_return=-301.8824462890625\n",
            "global_step=17456, episodic_return=-181.10208129882812\n",
            "global_step=17624, episodic_return=-120.49894714355469\n",
            "global_step=17712, episodic_return=-211.35150146484375\n",
            "global_step=17752, episodic_return=-108.30179595947266\n",
            "SPS: 1073\n",
            "global_step=17964, episodic_return=-126.42713165283203\n",
            "global_step=18024, episodic_return=-204.78054809570312\n",
            "global_step=18036, episodic_return=-42.690956115722656\n",
            "global_step=18292, episodic_return=-260.2373046875\n",
            "global_step=18308, episodic_return=-168.745361328125\n",
            "global_step=18368, episodic_return=-93.79035186767578\n",
            "SPS: 1077\n",
            "global_step=18448, episodic_return=-102.69937896728516\n",
            "global_step=18572, episodic_return=-59.02809524536133\n",
            "global_step=18688, episodic_return=-91.74261474609375\n",
            "global_step=18692, episodic_return=-86.52510833740234\n",
            "global_step=18780, episodic_return=-127.17344665527344\n",
            "global_step=18916, episodic_return=-201.7253875732422\n",
            "SPS: 1081\n",
            "global_step=19128, episodic_return=-185.78799438476562\n",
            "global_step=19160, episodic_return=-64.71650695800781\n",
            "global_step=19228, episodic_return=-83.88630676269531\n",
            "SPS: 1085\n",
            "global_step=19508, episodic_return=-68.63934326171875\n",
            "global_step=19532, episodic_return=-129.0211944580078\n",
            "global_step=19572, episodic_return=-292.2498474121094\n",
            "global_step=19648, episodic_return=-244.67262268066406\n",
            "global_step=19916, episodic_return=-157.7929229736328\n",
            "global_step=19940, episodic_return=-343.6722412109375\n",
            "global_step=19956, episodic_return=-134.3370361328125\n",
            "SPS: 1089\n",
            "global_step=20040, episodic_return=-164.6525421142578\n",
            "global_step=20228, episodic_return=-113.02397155761719\n",
            "global_step=20288, episodic_return=-62.027565002441406\n",
            "global_step=20300, episodic_return=-123.939208984375\n",
            "global_step=20304, episodic_return=-204.14273071289062\n",
            "SPS: 1094\n",
            "global_step=20500, episodic_return=-54.32046890258789\n",
            "global_step=20544, episodic_return=-99.38809204101562\n",
            "global_step=20576, episodic_return=-26.912704467773438\n",
            "global_step=20672, episodic_return=-120.83479309082031\n",
            "global_step=20884, episodic_return=-66.75664520263672\n",
            "global_step=20964, episodic_return=-104.9637222290039\n",
            "SPS: 1097\n",
            "global_step=21044, episodic_return=-153.63851928710938\n",
            "global_step=21136, episodic_return=-103.32842254638672\n",
            "global_step=21272, episodic_return=-339.5203552246094\n",
            "global_step=21412, episodic_return=-107.08364868164062\n",
            "SPS: 1100\n",
            "global_step=21584, episodic_return=-77.70802307128906\n",
            "global_step=21628, episodic_return=-249.833984375\n",
            "global_step=21748, episodic_return=-84.26126098632812\n",
            "global_step=21792, episodic_return=-151.4707794189453\n",
            "global_step=21940, episodic_return=-116.31241607666016\n",
            "SPS: 1103\n",
            "global_step=22096, episodic_return=-60.15590286254883\n",
            "global_step=22120, episodic_return=-462.35260009765625\n",
            "global_step=22356, episodic_return=-175.50164794921875\n",
            "global_step=22364, episodic_return=-67.15457153320312\n",
            "global_step=22384, episodic_return=-152.39712524414062\n",
            "SPS: 1104\n",
            "global_step=22616, episodic_return=-62.674068450927734\n",
            "global_step=22696, episodic_return=-321.6158447265625\n",
            "global_step=22856, episodic_return=-183.4110107421875\n",
            "global_step=23008, episodic_return=-115.66020202636719\n",
            "global_step=23024, episodic_return=-103.34162139892578\n",
            "SPS: 1098\n",
            "global_step=23080, episodic_return=-164.37893676757812\n",
            "global_step=23136, episodic_return=-304.63751220703125\n",
            "global_step=23308, episodic_return=-200.10101318359375\n",
            "global_step=23312, episodic_return=-90.08892059326172\n",
            "global_step=23412, episodic_return=-146.55258178710938\n",
            "global_step=23416, episodic_return=-98.72163391113281\n",
            "SPS: 1095\n",
            "global_step=23640, episodic_return=-113.15531158447266\n",
            "global_step=23704, episodic_return=-214.50759887695312\n",
            "global_step=23764, episodic_return=-162.54747009277344\n",
            "global_step=23852, episodic_return=-221.19920349121094\n",
            "SPS: 1091\n",
            "global_step=24092, episodic_return=-180.17401123046875\n",
            "global_step=24204, episodic_return=-171.98138427734375\n",
            "global_step=24248, episodic_return=-203.9083251953125\n",
            "global_step=24340, episodic_return=-274.655029296875\n",
            "global_step=24536, episodic_return=-280.61419677734375\n",
            "SPS: 1086\n",
            "global_step=24664, episodic_return=-60.76526641845703\n",
            "global_step=24732, episodic_return=-133.0423583984375\n",
            "global_step=24992, episodic_return=-137.5548553466797\n",
            "global_step=24996, episodic_return=-139.3187713623047\n",
            "SPS: 1078\n",
            "global_step=25200, episodic_return=-166.74002075195312\n",
            "global_step=25208, episodic_return=-69.13108825683594\n",
            "global_step=25296, episodic_return=-112.99947357177734\n",
            "global_step=25404, episodic_return=-145.1910400390625\n",
            "SPS: 1072\n",
            "global_step=25616, episodic_return=-141.99249267578125\n",
            "global_step=25680, episodic_return=-240.1024932861328\n",
            "global_step=25752, episodic_return=-80.72515869140625\n",
            "global_step=25768, episodic_return=-123.67784881591797\n",
            "global_step=25956, episodic_return=-107.16069793701172\n",
            "global_step=26020, episodic_return=-255.4408721923828\n",
            "global_step=26076, episodic_return=-125.64985656738281\n",
            "SPS: 1066\n",
            "global_step=26180, episodic_return=-192.2627410888672\n",
            "global_step=26308, episodic_return=-99.74740600585938\n",
            "global_step=26484, episodic_return=-158.8106231689453\n",
            "global_step=26548, episodic_return=-154.95358276367188\n",
            "SPS: 1060\n",
            "global_step=26644, episodic_return=-216.6835479736328\n",
            "global_step=26652, episodic_return=-141.7469940185547\n",
            "global_step=26836, episodic_return=-75.22041320800781\n",
            "global_step=26968, episodic_return=-69.02586364746094\n",
            "global_step=27032, episodic_return=-140.09579467773438\n",
            "global_step=27128, episodic_return=-99.85543823242188\n",
            "SPS: 1057\n",
            "global_step=27164, episodic_return=-102.83106994628906\n",
            "global_step=27300, episodic_return=-116.53107452392578\n",
            "global_step=27560, episodic_return=-181.7276153564453\n",
            "global_step=27628, episodic_return=-156.71368408203125\n",
            "SPS: 1061\n",
            "global_step=27660, episodic_return=-113.56349182128906\n",
            "global_step=27744, episodic_return=-164.8162384033203\n",
            "global_step=27884, episodic_return=-94.06121063232422\n",
            "global_step=27924, episodic_return=-82.26289367675781\n",
            "global_step=28048, episodic_return=-156.791748046875\n",
            "SPS: 1064\n",
            "global_step=28180, episodic_return=-412.31005859375\n",
            "global_step=28276, episodic_return=-186.88645935058594\n",
            "global_step=28480, episodic_return=-458.504150390625\n",
            "global_step=28504, episodic_return=-118.32257843017578\n",
            "global_step=28624, episodic_return=-141.32455444335938\n",
            "SPS: 1067\n",
            "global_step=28744, episodic_return=-81.89266967773438\n",
            "global_step=28836, episodic_return=-71.35687255859375\n",
            "global_step=29012, episodic_return=-66.70697021484375\n",
            "global_step=29032, episodic_return=-208.19967651367188\n",
            "SPS: 1069\n",
            "global_step=29252, episodic_return=-542.16455078125\n",
            "global_step=29272, episodic_return=-79.84716796875\n",
            "global_step=29352, episodic_return=-124.64593505859375\n",
            "global_step=29508, episodic_return=-263.1705627441406\n",
            "global_step=29516, episodic_return=-109.49635314941406\n",
            "SPS: 1072\n",
            "global_step=29732, episodic_return=-142.062744140625\n",
            "global_step=29752, episodic_return=-143.636962890625\n",
            "global_step=29848, episodic_return=-226.47055053710938\n",
            "global_step=29972, episodic_return=-277.6827392578125\n",
            "global_step=30072, episodic_return=44.7105712890625\n",
            "SPS: 1074\n",
            "global_step=30216, episodic_return=-154.8302459716797\n",
            "global_step=30248, episodic_return=-99.20480346679688\n",
            "global_step=30292, episodic_return=-202.88412475585938\n",
            "global_step=30628, episodic_return=-178.6766815185547\n",
            "global_step=30648, episodic_return=-152.6254425048828\n",
            "global_step=30672, episodic_return=-344.1504211425781\n",
            "global_step=30700, episodic_return=-208.55589294433594\n",
            "SPS: 1077\n",
            "global_step=30900, episodic_return=-97.21958923339844\n",
            "global_step=31004, episodic_return=-109.47811126708984\n",
            "global_step=31132, episodic_return=-28.52289581298828\n",
            "global_step=31208, episodic_return=-50.11397171020508\n",
            "SPS: 1080\n",
            "global_step=31340, episodic_return=-98.75838470458984\n",
            "global_step=31404, episodic_return=-105.48906707763672\n",
            "global_step=31512, episodic_return=-142.6708984375\n",
            "global_step=31632, episodic_return=-98.40776062011719\n",
            "global_step=31668, episodic_return=-166.48577880859375\n",
            "SPS: 1082\n",
            "global_step=31820, episodic_return=-338.5352783203125\n",
            "global_step=31856, episodic_return=-179.4644775390625\n",
            "global_step=32024, episodic_return=-2.7130889892578125\n",
            "global_step=32096, episodic_return=-102.03238677978516\n",
            "global_step=32148, episodic_return=-15.757797241210938\n",
            "SPS: 1084\n",
            "global_step=32336, episodic_return=-99.90862274169922\n",
            "global_step=32368, episodic_return=-243.9179229736328\n",
            "global_step=32440, episodic_return=-126.15754699707031\n",
            "global_step=32484, episodic_return=-124.26245880126953\n",
            "SPS: 1087\n",
            "global_step=32864, episodic_return=-222.65060424804688\n",
            "global_step=32884, episodic_return=-292.53887939453125\n",
            "global_step=32956, episodic_return=-168.75320434570312\n",
            "global_step=32960, episodic_return=-88.96796417236328\n",
            "global_step=33180, episodic_return=-59.9710693359375\n",
            "global_step=33220, episodic_return=-76.54475402832031\n",
            "SPS: 1089\n",
            "global_step=33336, episodic_return=-60.11772918701172\n",
            "global_step=33572, episodic_return=-169.7044677734375\n",
            "global_step=33668, episodic_return=-203.8448486328125\n",
            "global_step=33700, episodic_return=-119.955322265625\n",
            "SPS: 1091\n",
            "global_step=33956, episodic_return=-190.60821533203125\n",
            "global_step=33968, episodic_return=-34.17887878417969\n",
            "global_step=33980, episodic_return=-113.9546890258789\n",
            "global_step=34104, episodic_return=-206.62380981445312\n",
            "global_step=34240, episodic_return=-66.42701721191406\n",
            "global_step=34272, episodic_return=-57.91189193725586\n",
            "SPS: 1092\n",
            "global_step=34448, episodic_return=-158.60972595214844\n",
            "global_step=34496, episodic_return=-140.85797119140625\n",
            "global_step=34568, episodic_return=-96.79786682128906\n",
            "global_step=34572, episodic_return=-31.909423828125\n",
            "global_step=34772, episodic_return=-85.77194213867188\n",
            "SPS: 1095\n",
            "global_step=34824, episodic_return=-64.16224670410156\n",
            "global_step=34880, episodic_return=-103.29170989990234\n",
            "global_step=34984, episodic_return=-164.95343017578125\n",
            "global_step=35092, episodic_return=-126.81188201904297\n",
            "global_step=35316, episodic_return=-138.60491943359375\n",
            "SPS: 1097\n",
            "global_step=35348, episodic_return=-293.73626708984375\n",
            "global_step=35552, episodic_return=-102.05925750732422\n",
            "global_step=35612, episodic_return=-113.07756805419922\n",
            "global_step=35716, episodic_return=-142.63772583007812\n",
            "global_step=35744, episodic_return=-124.2269058227539\n",
            "SPS: 1099\n",
            "global_step=35884, episodic_return=-77.0284423828125\n",
            "global_step=36000, episodic_return=-80.89981842041016\n",
            "global_step=36072, episodic_return=-114.71275329589844\n",
            "global_step=36084, episodic_return=-133.3808135986328\n",
            "global_step=36208, episodic_return=-132.37120056152344\n",
            "global_step=36348, episodic_return=-127.83880615234375\n",
            "SPS: 1101\n",
            "global_step=36384, episodic_return=-101.85458374023438\n",
            "global_step=36400, episodic_return=-173.48782348632812\n",
            "global_step=36672, episodic_return=-108.73692321777344\n",
            "global_step=36756, episodic_return=-218.05758666992188\n",
            "global_step=36772, episodic_return=-129.8214569091797\n",
            "global_step=36848, episodic_return=-92.85258483886719\n",
            "SPS: 1103\n",
            "global_step=36944, episodic_return=-73.47834777832031\n",
            "global_step=37048, episodic_return=-113.32392120361328\n",
            "global_step=37152, episodic_return=-221.47674560546875\n",
            "global_step=37296, episodic_return=-130.47499084472656\n",
            "global_step=37300, episodic_return=-182.7244110107422\n",
            "global_step=37352, episodic_return=-89.93534851074219\n",
            "SPS: 1105\n",
            "global_step=37408, episodic_return=-110.02545928955078\n",
            "global_step=37652, episodic_return=-179.7310028076172\n",
            "global_step=37768, episodic_return=-73.75492095947266\n",
            "global_step=37836, episodic_return=-119.22611999511719\n",
            "global_step=37864, episodic_return=-32.88667297363281\n",
            "SPS: 1106\n",
            "global_step=38088, episodic_return=19.92426300048828\n",
            "global_step=38172, episodic_return=-118.00405883789062\n",
            "global_step=38372, episodic_return=-141.93075561523438\n",
            "global_step=38392, episodic_return=-113.85307312011719\n",
            "SPS: 1108\n",
            "global_step=38516, episodic_return=-61.253318786621094\n",
            "global_step=38532, episodic_return=-93.24125671386719\n",
            "global_step=38704, episodic_return=-140.15782165527344\n",
            "global_step=38748, episodic_return=-117.78691101074219\n",
            "global_step=38864, episodic_return=-84.30481719970703\n",
            "global_step=38892, episodic_return=-119.15743255615234\n",
            "SPS: 1110\n",
            "global_step=39104, episodic_return=-167.5484619140625\n",
            "global_step=39224, episodic_return=-145.29489135742188\n",
            "global_step=39328, episodic_return=-369.1000671386719\n",
            "global_step=39368, episodic_return=-102.00907135009766\n",
            "SPS: 1111\n",
            "global_step=39528, episodic_return=-153.61227416992188\n",
            "global_step=39672, episodic_return=-209.39138793945312\n",
            "global_step=39868, episodic_return=-110.32856750488281\n",
            "global_step=39904, episodic_return=-239.13104248046875\n",
            "global_step=39932, episodic_return=-113.0052261352539\n",
            "SPS: 1109\n",
            "global_step=40204, episodic_return=-203.9461669921875\n",
            "global_step=40304, episodic_return=-115.02377319335938\n",
            "global_step=40392, episodic_return=-241.52767944335938\n",
            "global_step=40416, episodic_return=-123.96702575683594\n",
            "SPS: 1106\n",
            "global_step=40556, episodic_return=-143.6221923828125\n",
            "global_step=40712, episodic_return=-88.16145324707031\n",
            "global_step=40812, episodic_return=-86.10665130615234\n",
            "global_step=40904, episodic_return=-172.67758178710938\n",
            "SPS: 1103\n",
            "global_step=40980, episodic_return=-178.52316284179688\n",
            "global_step=41044, episodic_return=-106.28331756591797\n",
            "global_step=41080, episodic_return=-74.25062561035156\n",
            "global_step=41300, episodic_return=-96.95997619628906\n",
            "global_step=41312, episodic_return=-142.97198486328125\n",
            "global_step=41388, episodic_return=-102.1924819946289\n",
            "SPS: 1101\n",
            "global_step=41520, episodic_return=-252.20018005371094\n",
            "global_step=41572, episodic_return=-103.45703125\n",
            "global_step=41712, episodic_return=-38.33083724975586\n",
            "global_step=41800, episodic_return=-74.94744110107422\n",
            "global_step=41816, episodic_return=-132.2457733154297\n",
            "SPS: 1098\n",
            "global_step=42116, episodic_return=-292.33026123046875\n",
            "global_step=42216, episodic_return=-125.99651336669922\n",
            "global_step=42248, episodic_return=-322.97930908203125\n",
            "global_step=42496, episodic_return=-246.02488708496094\n",
            "SPS: 1094\n",
            "global_step=42520, episodic_return=-55.32190704345703\n",
            "global_step=42692, episodic_return=-142.91500854492188\n",
            "global_step=42724, episodic_return=-40.438438415527344\n",
            "global_step=42796, episodic_return=-64.23855590820312\n",
            "SPS: 1090\n",
            "global_step=43060, episodic_return=-45.15345764160156\n",
            "global_step=43068, episodic_return=-149.86273193359375\n",
            "global_step=43176, episodic_return=-208.3345489501953\n",
            "global_step=43316, episodic_return=-48.202423095703125\n",
            "global_step=43352, episodic_return=-72.42320251464844\n",
            "SPS: 1086\n",
            "global_step=43740, episodic_return=-245.20578002929688\n",
            "global_step=43764, episodic_return=-77.98336029052734\n",
            "global_step=43792, episodic_return=-123.91651916503906\n",
            "global_step=43832, episodic_return=-133.5662841796875\n",
            "SPS: 1082\n",
            "global_step=44140, episodic_return=-104.84434509277344\n",
            "global_step=44300, episodic_return=-228.23536682128906\n",
            "global_step=44344, episodic_return=-199.74942016601562\n",
            "global_step=44440, episodic_return=-109.11372375488281\n",
            "global_step=44464, episodic_return=-115.30850219726562\n",
            "SPS: 1081\n",
            "global_step=44764, episodic_return=-115.85250091552734\n",
            "global_step=44812, episodic_return=-58.961997985839844\n",
            "global_step=44992, episodic_return=-416.7328186035156\n",
            "SPS: 1083\n",
            "global_step=45092, episodic_return=-128.00050354003906\n",
            "global_step=45116, episodic_return=-49.18419647216797\n",
            "global_step=45328, episodic_return=-112.67085266113281\n",
            "global_step=45364, episodic_return=-75.94585418701172\n",
            "global_step=45372, episodic_return=-131.93270874023438\n",
            "global_step=45520, episodic_return=-98.7669677734375\n",
            "SPS: 1084\n",
            "global_step=45852, episodic_return=-81.52723693847656\n",
            "global_step=45884, episodic_return=-219.90533447265625\n",
            "global_step=45896, episodic_return=-219.95013427734375\n",
            "global_step=46060, episodic_return=-165.26644897460938\n",
            "SPS: 1086\n",
            "global_step=46196, episodic_return=-52.47129821777344\n",
            "global_step=46264, episodic_return=-84.26152038574219\n",
            "global_step=46368, episodic_return=-115.92110443115234\n",
            "global_step=46380, episodic_return=-113.9953384399414\n",
            "global_step=46560, episodic_return=-75.11830139160156\n",
            "SPS: 1088\n",
            "global_step=46652, episodic_return=-90.30148315429688\n",
            "global_step=46668, episodic_return=-78.80168151855469\n",
            "global_step=46672, episodic_return=-24.837753295898438\n",
            "global_step=46920, episodic_return=-79.391845703125\n",
            "global_step=46988, episodic_return=-101.80516052246094\n",
            "global_step=47096, episodic_return=-129.92999267578125\n",
            "global_step=47100, episodic_return=-124.70729064941406\n",
            "SPS: 1090\n",
            "global_step=47252, episodic_return=-112.61540222167969\n",
            "global_step=47504, episodic_return=-216.05783081054688\n",
            "global_step=47532, episodic_return=-156.33212280273438\n",
            "global_step=47576, episodic_return=-68.75480651855469\n",
            "SPS: 1091\n",
            "global_step=47756, episodic_return=-328.6019287109375\n",
            "global_step=47776, episodic_return=-107.26534271240234\n",
            "global_step=47924, episodic_return=-52.943275451660156\n",
            "global_step=48052, episodic_return=-98.8171615600586\n",
            "global_step=48092, episodic_return=-48.4908332824707\n",
            "SPS: 1093\n",
            "global_step=48224, episodic_return=-79.8768539428711\n",
            "global_step=48320, episodic_return=-129.89242553710938\n",
            "global_step=48496, episodic_return=-113.41162872314453\n",
            "global_step=48524, episodic_return=-102.67565155029297\n",
            "SPS: 1095\n",
            "global_step=48756, episodic_return=-260.28326416015625\n",
            "global_step=48784, episodic_return=-67.52501678466797\n",
            "global_step=48808, episodic_return=-87.18899536132812\n",
            "global_step=48836, episodic_return=-130.7833709716797\n",
            "global_step=49076, episodic_return=-98.19779968261719\n",
            "global_step=49144, episodic_return=-63.24079132080078\n",
            "SPS: 1096\n",
            "global_step=49280, episodic_return=-93.93865203857422\n",
            "global_step=49296, episodic_return=-135.4613037109375\n",
            "global_step=49620, episodic_return=-101.58177185058594\n",
            "global_step=49636, episodic_return=-176.75009155273438\n",
            "global_step=49652, episodic_return=-126.46566772460938\n",
            "SPS: 1098\n",
            "global_step=49736, episodic_return=-322.668212890625\n",
            "global_step=49948, episodic_return=-134.76364135742188\n",
            "global_step=50048, episodic_return=-64.95159912109375\n",
            "global_step=50056, episodic_return=-223.70462036132812\n",
            "SPS: 1099\n",
            "global_step=50184, episodic_return=-158.93431091308594\n",
            "global_step=50224, episodic_return=-54.83857727050781\n",
            "global_step=50380, episodic_return=-121.53289794921875\n",
            "global_step=50520, episodic_return=-364.46820068359375\n",
            "global_step=50632, episodic_return=-135.08087158203125\n",
            "SPS: 1101\n",
            "global_step=50752, episodic_return=-220.77035522460938\n",
            "global_step=51032, episodic_return=-101.89527893066406\n",
            "global_step=51136, episodic_return=-204.22021484375\n",
            "global_step=51184, episodic_return=-179.21185302734375\n",
            "SPS: 1102\n",
            "global_step=51212, episodic_return=-351.52349853515625\n",
            "global_step=51588, episodic_return=-58.15477752685547\n",
            "global_step=51616, episodic_return=-136.64959716796875\n",
            "global_step=51668, episodic_return=-137.96142578125\n",
            "SPS: 1102\n",
            "global_step=51716, episodic_return=13.617179870605469\n",
            "global_step=51892, episodic_return=-60.672630310058594\n",
            "global_step=51956, episodic_return=-99.29985046386719\n",
            "global_step=52144, episodic_return=-129.73468017578125\n",
            "SPS: 1104\n",
            "global_step=52256, episodic_return=-349.7469482421875\n",
            "global_step=52392, episodic_return=-126.69752502441406\n",
            "global_step=52416, episodic_return=-297.5941162109375\n",
            "global_step=52548, episodic_return=-129.4854736328125\n",
            "global_step=52680, episodic_return=-332.7987060546875\n",
            "SPS: 1105\n",
            "global_step=52836, episodic_return=-120.57465362548828\n",
            "global_step=52884, episodic_return=-251.23463439941406\n",
            "global_step=52936, episodic_return=-62.32023239135742\n",
            "global_step=53112, episodic_return=-276.49517822265625\n",
            "SPS: 1106\n",
            "global_step=53328, episodic_return=-157.81121826171875\n",
            "global_step=53376, episodic_return=-72.36994171142578\n",
            "global_step=53432, episodic_return=-182.1766357421875\n",
            "global_step=53628, episodic_return=-106.56779479980469\n",
            "global_step=53744, episodic_return=-186.26824951171875\n",
            "SPS: 1108\n",
            "global_step=53928, episodic_return=-92.55532836914062\n",
            "global_step=53960, episodic_return=-86.79754638671875\n",
            "global_step=54036, episodic_return=-84.88932037353516\n",
            "global_step=54208, episodic_return=-88.77252960205078\n",
            "global_step=54260, episodic_return=-375.8231201171875\n",
            "SPS: 1109\n",
            "global_step=54428, episodic_return=10.943412780761719\n",
            "global_step=54448, episodic_return=-287.69891357421875\n",
            "global_step=54680, episodic_return=-140.39804077148438\n",
            "global_step=54684, episodic_return=-269.3592834472656\n",
            "global_step=54784, episodic_return=-113.23992919921875\n",
            "SPS: 1110\n",
            "global_step=54792, episodic_return=-78.88827514648438\n",
            "global_step=55228, episodic_return=-213.27418518066406\n",
            "global_step=55252, episodic_return=-156.90225219726562\n",
            "global_step=55264, episodic_return=-53.131988525390625\n",
            "SPS: 1111\n",
            "global_step=55324, episodic_return=-177.31338500976562\n",
            "global_step=55684, episodic_return=-232.4411163330078\n",
            "global_step=55708, episodic_return=-129.72906494140625\n",
            "global_step=55804, episodic_return=-136.91790771484375\n",
            "SPS: 1113\n",
            "global_step=55856, episodic_return=-191.93382263183594\n",
            "global_step=56156, episodic_return=-103.9703598022461\n",
            "global_step=56208, episodic_return=-201.3462371826172\n",
            "global_step=56288, episodic_return=-23.278106689453125\n",
            "SPS: 1114\n",
            "global_step=56428, episodic_return=-56.41461944580078\n",
            "global_step=56480, episodic_return=-188.34071350097656\n",
            "global_step=56660, episodic_return=-91.03668975830078\n",
            "global_step=56760, episodic_return=-82.36865234375\n",
            "SPS: 1115\n",
            "global_step=56872, episodic_return=-149.32278442382812\n",
            "global_step=56952, episodic_return=-135.74661254882812\n",
            "global_step=56980, episodic_return=-96.8624038696289\n",
            "global_step=57296, episodic_return=-212.7842254638672\n",
            "SPS: 1113\n",
            "global_step=57376, episodic_return=-166.25555419921875\n",
            "global_step=57440, episodic_return=-58.823665618896484\n",
            "global_step=57644, episodic_return=-113.7244873046875\n",
            "global_step=57648, episodic_return=-143.09144592285156\n",
            "SPS: 1110\n",
            "global_step=57880, episodic_return=-110.69171142578125\n",
            "global_step=57908, episodic_return=-304.86566162109375\n",
            "global_step=57968, episodic_return=-211.45333862304688\n",
            "global_step=57988, episodic_return=-55.97698211669922\n",
            "global_step=58212, episodic_return=-148.96890258789062\n",
            "global_step=58240, episodic_return=-66.47430419921875\n",
            "global_step=58292, episodic_return=-124.9631118774414\n",
            "SPS: 1109\n",
            "global_step=58632, episodic_return=-263.54962158203125\n",
            "global_step=58636, episodic_return=-434.5724792480469\n",
            "global_step=58676, episodic_return=-128.720703125\n",
            "global_step=58740, episodic_return=-74.8846664428711\n",
            "SPS: 1107\n",
            "global_step=59028, episodic_return=-156.70916748046875\n",
            "global_step=59052, episodic_return=-110.31706237792969\n",
            "global_step=59232, episodic_return=-239.50759887695312\n",
            "SPS: 1104\n",
            "global_step=59428, episodic_return=-92.3707046508789\n",
            "global_step=59496, episodic_return=-124.28285217285156\n",
            "global_step=59504, episodic_return=-114.52548217773438\n",
            "global_step=59648, episodic_return=-70.26829528808594\n",
            "global_step=59784, episodic_return=-197.83377075195312\n",
            "global_step=59836, episodic_return=-98.38066101074219\n",
            "SPS: 1101\n",
            "global_step=59968, episodic_return=-125.2354736328125\n",
            "global_step=60116, episodic_return=-76.39249420166016\n",
            "global_step=60212, episodic_return=-105.40062713623047\n",
            "global_step=60248, episodic_return=-45.285831451416016\n",
            "SPS: 1097\n",
            "global_step=60424, episodic_return=-147.4812469482422\n",
            "global_step=60520, episodic_return=-123.5143051147461\n",
            "global_step=60548, episodic_return=-105.7506103515625\n",
            "global_step=60636, episodic_return=-111.12237548828125\n",
            "global_step=60816, episodic_return=-194.720947265625\n",
            "global_step=60840, episodic_return=-128.6549072265625\n",
            "SPS: 1095\n",
            "global_step=61012, episodic_return=-229.58877563476562\n",
            "global_step=61092, episodic_return=-62.121273040771484\n",
            "global_step=61188, episodic_return=-141.57089233398438\n",
            "global_step=61248, episodic_return=-84.45707702636719\n",
            "global_step=61320, episodic_return=-105.62677001953125\n",
            "SPS: 1092\n",
            "global_step=61552, episodic_return=-172.02505493164062\n",
            "global_step=61564, episodic_return=-127.18622589111328\n",
            "global_step=61704, episodic_return=-129.3251190185547\n",
            "global_step=61780, episodic_return=-255.748291015625\n",
            "SPS: 1094\n",
            "global_step=61996, episodic_return=-284.4449157714844\n",
            "global_step=62036, episodic_return=-80.36079406738281\n",
            "global_step=62060, episodic_return=-40.784095764160156\n",
            "global_step=62320, episodic_return=-74.0922622680664\n",
            "global_step=62368, episodic_return=-252.79534912109375\n",
            "global_step=62436, episodic_return=-35.98213195800781\n",
            "SPS: 1094\n",
            "global_step=62552, episodic_return=-108.00018310546875\n",
            "global_step=62600, episodic_return=-77.5501708984375\n",
            "global_step=62652, episodic_return=-64.41058349609375\n",
            "global_step=62920, episodic_return=-342.8841552734375\n",
            "SPS: 1095\n",
            "global_step=63088, episodic_return=-40.419132232666016\n",
            "global_step=63096, episodic_return=-29.70812225341797\n",
            "global_step=63196, episodic_return=-62.405967712402344\n",
            "global_step=63248, episodic_return=-115.40145874023438\n",
            "global_step=63456, episodic_return=-106.35449981689453\n",
            "SPS: 1097\n",
            "global_step=63600, episodic_return=-61.2201042175293\n",
            "global_step=63676, episodic_return=-203.11277770996094\n",
            "global_step=63940, episodic_return=-235.98374938964844\n",
            "SPS: 1097\n",
            "global_step=64060, episodic_return=-111.47868347167969\n",
            "global_step=64084, episodic_return=-263.95269775390625\n",
            "global_step=64256, episodic_return=-104.95164489746094\n",
            "global_step=64276, episodic_return=-181.43499755859375\n",
            "global_step=64464, episodic_return=-93.07908630371094\n",
            "SPS: 1098\n",
            "global_step=64596, episodic_return=-71.99411010742188\n",
            "global_step=64908, episodic_return=-111.62825775146484\n",
            "global_step=64928, episodic_return=-436.12237548828125\n",
            "global_step=64956, episodic_return=-87.49807739257812\n",
            "SPS: 1099\n",
            "global_step=65188, episodic_return=-227.96194458007812\n",
            "global_step=65244, episodic_return=-30.904388427734375\n",
            "global_step=65296, episodic_return=-268.3785400390625\n",
            "SPS: 1100\n",
            "global_step=65608, episodic_return=-86.14742279052734\n",
            "global_step=65744, episodic_return=-327.5406799316406\n",
            "global_step=65764, episodic_return=-55.318965911865234\n",
            "global_step=65856, episodic_return=-328.3576354980469\n",
            "SPS: 1101\n",
            "global_step=66152, episodic_return=-118.40287780761719\n",
            "global_step=66156, episodic_return=-105.72606658935547\n",
            "global_step=66308, episodic_return=-290.67010498046875\n",
            "global_step=66384, episodic_return=-255.30184936523438\n",
            "SPS: 1102\n",
            "global_step=66656, episodic_return=-118.93446350097656\n",
            "global_step=66776, episodic_return=-103.96041870117188\n",
            "global_step=66828, episodic_return=69.17201232910156\n",
            "global_step=66868, episodic_return=-50.4040641784668\n",
            "global_step=66928, episodic_return=-89.14826965332031\n",
            "global_step=67056, episodic_return=-88.22425842285156\n",
            "SPS: 1103\n",
            "global_step=67180, episodic_return=-75.66964721679688\n",
            "global_step=67200, episodic_return=-110.80612182617188\n",
            "global_step=67248, episodic_return=-48.75835418701172\n",
            "global_step=67516, episodic_return=-104.87992858886719\n",
            "global_step=67544, episodic_return=-154.1053466796875\n",
            "global_step=67584, episodic_return=-120.62602996826172\n",
            "SPS: 1104\n",
            "global_step=67592, episodic_return=-80.33712005615234\n",
            "global_step=67952, episodic_return=-198.1940155029297\n",
            "global_step=67972, episodic_return=-82.8477783203125\n",
            "global_step=68012, episodic_return=-72.3237075805664\n",
            "SPS: 1105\n",
            "global_step=68288, episodic_return=-202.4752197265625\n",
            "global_step=68492, episodic_return=-148.7977294921875\n",
            "global_step=68532, episodic_return=-17.108016967773438\n",
            "SPS: 1105\n",
            "global_step=68636, episodic_return=-84.66581726074219\n",
            "global_step=68904, episodic_return=-113.93950653076172\n",
            "global_step=68928, episodic_return=-139.0657958984375\n",
            "SPS: 1106\n",
            "global_step=69156, episodic_return=-144.72364807128906\n",
            "global_step=69220, episodic_return=-75.11518859863281\n",
            "global_step=69392, episodic_return=-151.19149780273438\n",
            "global_step=69568, episodic_return=-79.24950408935547\n",
            "global_step=69620, episodic_return=-89.44478607177734\n",
            "SPS: 1107\n",
            "global_step=69808, episodic_return=-295.1378173828125\n",
            "global_step=69936, episodic_return=-96.60882568359375\n",
            "global_step=69940, episodic_return=-202.0789794921875\n",
            "SPS: 1108\n",
            "global_step=70236, episodic_return=-141.2274932861328\n",
            "global_step=70348, episodic_return=-329.3742980957031\n",
            "global_step=70476, episodic_return=-93.76143646240234\n",
            "SPS: 1109\n",
            "global_step=70712, episodic_return=-112.58927917480469\n",
            "global_step=70728, episodic_return=-86.02726745605469\n",
            "global_step=70756, episodic_return=-56.34996795654297\n",
            "global_step=70976, episodic_return=-124.86436462402344\n",
            "global_step=71136, episodic_return=-154.91024780273438\n",
            "SPS: 1109\n",
            "global_step=71216, episodic_return=-156.93362426757812\n",
            "global_step=71248, episodic_return=-44.49488067626953\n",
            "global_step=71528, episodic_return=-92.58612060546875\n",
            "global_step=71552, episodic_return=-77.57511901855469\n",
            "global_step=71680, episodic_return=-191.93832397460938\n",
            "SPS: 1110\n",
            "global_step=71700, episodic_return=-128.4920654296875\n",
            "global_step=71864, episodic_return=6.98724365234375\n",
            "global_step=72040, episodic_return=-97.50968933105469\n",
            "global_step=72060, episodic_return=-46.68588638305664\n",
            "SPS: 1111\n",
            "global_step=72280, episodic_return=-86.30033111572266\n",
            "global_step=72332, episodic_return=-91.55206298828125\n",
            "global_step=72416, episodic_return=-99.6776123046875\n",
            "global_step=72480, episodic_return=-75.93367004394531\n",
            "global_step=72696, episodic_return=-100.81790161132812\n",
            "SPS: 1112\n",
            "global_step=72752, episodic_return=-138.08624267578125\n",
            "global_step=72764, episodic_return=-41.88628005981445\n",
            "global_step=72788, episodic_return=-234.47589111328125\n",
            "global_step=73132, episodic_return=-224.9090576171875\n",
            "global_step=73140, episodic_return=-36.36963653564453\n",
            "SPS: 1113\n",
            "global_step=73340, episodic_return=-96.21800231933594\n",
            "global_step=73716, episodic_return=-122.98146057128906\n",
            "SPS: 1113\n",
            "global_step=73772, episodic_return=-136.11111450195312\n",
            "global_step=73800, episodic_return=-104.54486083984375\n",
            "global_step=73812, episodic_return=-51.741310119628906\n",
            "global_step=74148, episodic_return=-45.2353515625\n",
            "SPS: 1111\n",
            "global_step=74300, episodic_return=-116.36543273925781\n",
            "global_step=74332, episodic_return=-357.3727722167969\n",
            "global_step=74564, episodic_return=-104.52841186523438\n",
            "SPS: 1109\n",
            "global_step=74832, episodic_return=-192.03335571289062\n",
            "global_step=74932, episodic_return=-202.37423706054688\n",
            "global_step=75044, episodic_return=-248.2064208984375\n",
            "SPS: 1107\n",
            "global_step=75340, episodic_return=-100.22008514404297\n",
            "global_step=75364, episodic_return=-368.0900573730469\n",
            "global_step=75444, episodic_return=-246.4121551513672\n",
            "global_step=75668, episodic_return=-276.1307373046875\n",
            "global_step=75720, episodic_return=-74.5726547241211\n",
            "SPS: 1105\n",
            "global_step=75896, episodic_return=-77.64840698242188\n",
            "global_step=76060, episodic_return=-118.10481262207031\n",
            "global_step=76068, episodic_return=-203.1822509765625\n",
            "global_step=76180, episodic_return=-107.88310241699219\n",
            "SPS: 1102\n",
            "global_step=76460, episodic_return=-13.430572509765625\n",
            "global_step=76476, episodic_return=-112.53219604492188\n",
            "global_step=76656, episodic_return=-72.47433471679688\n",
            "SPS: 1099\n",
            "global_step=76824, episodic_return=-84.97933959960938\n",
            "global_step=76880, episodic_return=-58.43484115600586\n",
            "global_step=76972, episodic_return=-147.96286010742188\n",
            "global_step=77204, episodic_return=-77.4886474609375\n",
            "global_step=77300, episodic_return=-210.09857177734375\n",
            "SPS: 1096\n",
            "global_step=77580, episodic_return=-94.92881774902344\n",
            "global_step=77744, episodic_return=-224.5456085205078\n",
            "global_step=77800, episodic_return=-50.307151794433594\n",
            "SPS: 1093\n",
            "global_step=77856, episodic_return=-123.96868896484375\n",
            "global_step=78108, episodic_return=-129.9220428466797\n",
            "global_step=78136, episodic_return=-137.70489501953125\n",
            "global_step=78152, episodic_return=-255.83868408203125\n",
            "SPS: 1092\n",
            "global_step=78572, episodic_return=-100.33033752441406\n",
            "global_step=78720, episodic_return=-17.26134490966797\n",
            "global_step=78768, episodic_return=-326.09906005859375\n",
            "SPS: 1093\n",
            "global_step=78924, episodic_return=-15.549476623535156\n",
            "global_step=78984, episodic_return=-100.7031478881836\n",
            "global_step=79136, episodic_return=-111.39339447021484\n",
            "global_step=79164, episodic_return=-140.7931671142578\n",
            "SPS: 1093\n",
            "global_step=79388, episodic_return=-16.47747039794922\n",
            "global_step=79424, episodic_return=-22.360366821289062\n",
            "global_step=79580, episodic_return=-85.72139739990234\n",
            "global_step=79608, episodic_return=-228.37342834472656\n",
            "SPS: 1094\n",
            "global_step=80144, episodic_return=-158.1645050048828\n",
            "global_step=80308, episodic_return=-92.17788696289062\n",
            "global_step=80332, episodic_return=-61.61371612548828\n",
            "SPS: 1094\n",
            "global_step=80508, episodic_return=-110.2251968383789\n",
            "global_step=80688, episodic_return=-17.847328186035156\n",
            "global_step=80828, episodic_return=-211.9744873046875\n",
            "SPS: 1094\n",
            "global_step=81096, episodic_return=-71.62171936035156\n",
            "global_step=81288, episodic_return=-231.3480987548828\n",
            "SPS: 1094\n",
            "global_step=81472, episodic_return=-191.95697021484375\n",
            "global_step=81752, episodic_return=-48.7946662902832\n",
            "SPS: 1094\n",
            "global_step=81924, episodic_return=-42.93434143066406\n",
            "global_step=82148, episodic_return=-462.15032958984375\n",
            "global_step=82152, episodic_return=-53.49657440185547\n",
            "SPS: 1095\n",
            "global_step=82536, episodic_return=-167.28292846679688\n",
            "global_step=82916, episodic_return=-70.86637878417969\n",
            "SPS: 1094\n",
            "global_step=83248, episodic_return=-68.89694213867188\n",
            "global_step=83260, episodic_return=-241.99977111816406\n",
            "SPS: 1093\n",
            "global_step=83540, episodic_return=-27.011672973632812\n",
            "global_step=83592, episodic_return=-76.81708526611328\n",
            "global_step=83700, episodic_return=-28.842636108398438\n",
            "global_step=83804, episodic_return=-107.31214141845703\n",
            "SPS: 1094\n",
            "global_step=84048, episodic_return=-80.53462219238281\n",
            "global_step=84148, episodic_return=-33.7213134765625\n",
            "global_step=84200, episodic_return=-1.3586502075195312\n",
            "global_step=84344, episodic_return=-46.15888595581055\n",
            "SPS: 1094\n",
            "global_step=84688, episodic_return=-11.874214172363281\n",
            "global_step=84732, episodic_return=-73.18815612792969\n",
            "global_step=84808, episodic_return=15.714645385742188\n",
            "global_step=84820, episodic_return=-68.33390808105469\n",
            "SPS: 1095\n",
            "global_step=85372, episodic_return=-69.49081420898438\n",
            "global_step=85416, episodic_return=-266.66204833984375\n",
            "SPS: 1095\n",
            "global_step=85692, episodic_return=-257.61883544921875\n",
            "global_step=85812, episodic_return=-56.72275924682617\n",
            "global_step=85872, episodic_return=-15.551704406738281\n",
            "SPS: 1095\n",
            "global_step=86140, episodic_return=26.542686462402344\n",
            "global_step=86368, episodic_return=-77.67106628417969\n",
            "SPS: 1095\n",
            "global_step=86936, episodic_return=-12.77276611328125\n",
            "SPS: 1094\n",
            "global_step=87088, episodic_return=-14.90771484375\n",
            "global_step=87304, episodic_return=-100.33606719970703\n",
            "global_step=87320, episodic_return=-121.63015747070312\n",
            "global_step=87336, episodic_return=-334.95892333984375\n",
            "SPS: 1094\n",
            "global_step=87712, episodic_return=-65.23938751220703\n",
            "global_step=87984, episodic_return=-44.00811004638672\n",
            "SPS: 1094\n",
            "global_step=88080, episodic_return=-5.4571533203125\n",
            "global_step=88084, episodic_return=-3.4487152099609375\n",
            "global_step=88160, episodic_return=-40.12059020996094\n",
            "global_step=88556, episodic_return=-58.61961364746094\n",
            "SPS: 1095\n",
            "global_step=88604, episodic_return=-84.72452545166016\n",
            "global_step=88696, episodic_return=-95.77548217773438\n",
            "global_step=88720, episodic_return=-79.99462890625\n",
            "global_step=89036, episodic_return=-18.535446166992188\n",
            "SPS: 1095\n",
            "global_step=89104, episodic_return=-19.736038208007812\n",
            "global_step=89172, episodic_return=-0.40764617919921875\n",
            "global_step=89240, episodic_return=-20.66039276123047\n",
            "SPS: 1094\n",
            "global_step=89704, episodic_return=-14.545486450195312\n",
            "global_step=89872, episodic_return=-49.7969970703125\n",
            "global_step=89908, episodic_return=-85.55579376220703\n",
            "SPS: 1092\n",
            "global_step=90332, episodic_return=-23.86737060546875\n",
            "global_step=90460, episodic_return=-90.66632080078125\n",
            "SPS: 1090\n",
            "global_step=90764, episodic_return=-115.90119171142578\n",
            "global_step=90788, episodic_return=32.146728515625\n",
            "global_step=90792, episodic_return=-123.64363098144531\n",
            "global_step=90896, episodic_return=-38.79216384887695\n",
            "SPS: 1088\n",
            "global_step=91212, episodic_return=-105.10250091552734\n",
            "global_step=91284, episodic_return=7.173973083496094\n",
            "global_step=91300, episodic_return=-15.1273193359375\n",
            "global_step=91532, episodic_return=14.902931213378906\n",
            "SPS: 1086\n",
            "global_step=92084, episodic_return=-11.801826477050781\n",
            "global_step=92132, episodic_return=4.79400634765625\n",
            "SPS: 1083\n",
            "global_step=92244, episodic_return=-146.18426513671875\n",
            "global_step=92552, episodic_return=-24.541717529296875\n",
            "global_step=92572, episodic_return=-63.21925354003906\n",
            "SPS: 1080\n",
            "global_step=92820, episodic_return=-33.26890563964844\n",
            "global_step=93120, episodic_return=-52.96416473388672\n",
            "SPS: 1076\n",
            "global_step=93256, episodic_return=-55.12034225463867\n",
            "global_step=93336, episodic_return=-26.141952514648438\n",
            "SPS: 1074\n",
            "global_step=93816, episodic_return=-1.76751708984375\n",
            "global_step=93908, episodic_return=-35.31132507324219\n",
            "SPS: 1073\n",
            "SPS: 1070\n",
            "global_step=94764, episodic_return=-286.99114990234375\n",
            "global_step=94800, episodic_return=-7.20599365234375\n",
            "global_step=95152, episodic_return=-213.03001403808594\n",
            "SPS: 1067\n",
            "global_step=95624, episodic_return=-24.794334411621094\n",
            "global_step=95652, episodic_return=-122.45018005371094\n",
            "global_step=95664, episodic_return=-76.84315490722656\n",
            "SPS: 1066\n",
            "SPS: 1065\n",
            "global_step=96328, episodic_return=-10.54791259765625\n",
            "SPS: 1062\n",
            "global_step=97120, episodic_return=61.301025390625\n",
            "global_step=97132, episodic_return=-50.247703552246094\n",
            "SPS: 1059\n",
            "global_step=97312, episodic_return=-124.95740509033203\n",
            "global_step=97388, episodic_return=-139.63131713867188\n",
            "SPS: 1059\n",
            "global_step=97960, episodic_return=-66.65248107910156\n",
            "global_step=98256, episodic_return=-175.09130859375\n",
            "global_step=98268, episodic_return=-58.260189056396484\n",
            "SPS: 1059\n",
            "global_step=98808, episodic_return=30.677947998046875\n",
            "SPS: 1059\n",
            "SPS: 1057\n",
            "global_step=99388, episodic_return=-20.249786376953125\n",
            "global_step=99684, episodic_return=-5.490203857421875\n",
            "SPS: 1055\n",
            "global_step=99848, episodic_return=16.11186981201172\n",
            "global_step=99904, episodic_return=-31.369155883789062\n",
            "SPS: 1054\n",
            "global_step=100716, episodic_return=-40.99757385253906\n",
            "SPS: 1052\n",
            "global_step=101060, episodic_return=-1.0414581298828125\n",
            "global_step=101132, episodic_return=29.103185653686523\n",
            "global_step=101312, episodic_return=-38.8133544921875\n",
            "SPS: 1050\n",
            "global_step=101380, episodic_return=-2.188201904296875\n",
            "global_step=101592, episodic_return=-35.15422058105469\n",
            "global_step=101836, episodic_return=41.07707214355469\n",
            "SPS: 1050\n",
            "global_step=102352, episodic_return=6.6203155517578125\n",
            "SPS: 1049\n",
            "SPS: 1045\n",
            "SPS: 1038\n",
            "SPS: 1029\n",
            "global_step=103972, episodic_return=-80.05268096923828\n",
            "SPS: 1021\n",
            "global_step=104612, episodic_return=-71.85763549804688\n",
            "SPS: 1016\n",
            "global_step=105380, episodic_return=124.2387466430664\n",
            "SPS: 1011\n",
            "global_step=105592, episodic_return=-15.58570671081543\n",
            "global_step=105836, episodic_return=45.08066177368164\n",
            "global_step=105888, episodic_return=0.4905242919921875\n",
            "SPS: 1009\n",
            "global_step=106168, episodic_return=-38.65171432495117\n",
            "SPS: 1009\n",
            "global_step=106620, episodic_return=-45.57927703857422\n",
            "global_step=106860, episodic_return=-22.316085815429688\n",
            "global_step=106948, episodic_return=-66.3117446899414\n",
            "SPS: 1008\n",
            "global_step=107324, episodic_return=-61.68942642211914\n",
            "SPS: 1007\n",
            "global_step=107696, episodic_return=-70.95088195800781\n",
            "SPS: 1005\n",
            "global_step=108412, episodic_return=-24.55315399169922\n",
            "global_step=108460, episodic_return=-80.13217163085938\n",
            "SPS: 1003\n",
            "global_step=108612, episodic_return=69.35676574707031\n",
            "SPS: 1002\n",
            "global_step=109404, episodic_return=25.63799285888672\n",
            "SPS: 1000\n",
            "SPS: 997\n",
            "global_step=110224, episodic_return=26.895904541015625\n",
            "SPS: 993\n",
            "global_step=110724, episodic_return=-149.80856323242188\n",
            "global_step=110860, episodic_return=18.12881088256836\n",
            "global_step=111092, episodic_return=-97.30817413330078\n",
            "SPS: 990\n",
            "global_step=111444, episodic_return=-116.9958267211914\n",
            "SPS: 988\n",
            "global_step=111908, episodic_return=-43.29473876953125\n",
            "global_step=112064, episodic_return=-25.500717163085938\n",
            "SPS: 985\n",
            "SPS: 982\n",
            "global_step=112796, episodic_return=-0.6646881103515625\n",
            "SPS: 976\n",
            "global_step=113384, episodic_return=-103.32461547851562\n",
            "global_step=113416, episodic_return=12.670417785644531\n",
            "SPS: 971\n",
            "SPS: 968\n",
            "global_step=114468, episodic_return=-87.30403137207031\n",
            "global_step=114620, episodic_return=-34.474037170410156\n",
            "global_step=114652, episodic_return=-42.863304138183594\n",
            "SPS: 965\n",
            "global_step=114724, episodic_return=20.739978790283203\n",
            "SPS: 965\n",
            "global_step=115208, episodic_return=-263.4573059082031\n",
            "global_step=115332, episodic_return=36.450775146484375\n",
            "SPS: 966\n",
            "global_step=115752, episodic_return=-48.70831298828125\n",
            "global_step=115768, episodic_return=3.5492706298828125\n",
            "SPS: 966\n",
            "global_step=116516, episodic_return=34.08868408203125\n",
            "global_step=116668, episodic_return=-226.38912963867188\n",
            "global_step=116676, episodic_return=-38.92121887207031\n",
            "SPS: 965\n",
            "SPS: 965\n",
            "global_step=117456, episodic_return=17.833290100097656\n",
            "SPS: 962\n",
            "global_step=117908, episodic_return=-60.934669494628906\n",
            "global_step=117944, episodic_return=2.06890869140625\n",
            "SPS: 961\n",
            "global_step=118528, episodic_return=-25.146400451660156\n",
            "SPS: 959\n",
            "global_step=118940, episodic_return=-91.16757202148438\n",
            "SPS: 958\n",
            "global_step=119732, episodic_return=-178.91305541992188\n",
            "SPS: 955\n",
            "global_step=120280, episodic_return=-81.32376098632812\n",
            "global_step=120316, episodic_return=-15.227012634277344\n",
            "SPS: 953\n",
            "global_step=120336, episodic_return=19.84404754638672\n",
            "SPS: 953\n",
            "SPS: 952\n",
            "global_step=121744, episodic_return=-27.741477966308594\n",
            "SPS: 947\n",
            "global_step=122100, episodic_return=-165.57884216308594\n",
            "SPS: 942\n",
            "global_step=122528, episodic_return=106.50367736816406\n",
            "global_step=122752, episodic_return=25.629425048828125\n",
            "SPS: 939\n",
            "global_step=123336, episodic_return=48.47157287597656\n",
            "SPS: 935\n",
            "global_step=123496, episodic_return=-6.457725524902344\n",
            "SPS: 932\n",
            "global_step=124316, episodic_return=102.28173065185547\n",
            "global_step=124328, episodic_return=-5.8875579833984375\n",
            "SPS: 930\n",
            "global_step=124640, episodic_return=-50.99806213378906\n",
            "SPS: 930\n",
            "global_step=125128, episodic_return=-13.70404052734375\n",
            "SPS: 929\n",
            "global_step=125676, episodic_return=-19.236099243164062\n",
            "global_step=125916, episodic_return=-50.01203155517578\n",
            "SPS: 927\n",
            "global_step=126200, episodic_return=5.134773254394531\n",
            "global_step=126328, episodic_return=-60.968807220458984\n",
            "SPS: 926\n",
            "global_step=126528, episodic_return=78.72167205810547\n",
            "global_step=126700, episodic_return=2.813720703125\n",
            "SPS: 926\n",
            "global_step=127072, episodic_return=22.211891174316406\n",
            "SPS: 927\n",
            "global_step=127532, episodic_return=-7.178558349609375\n",
            "global_step=127992, episodic_return=-48.47554397583008\n",
            "SPS: 926\n",
            "global_step=128248, episodic_return=-10.923454284667969\n",
            "SPS: 926\n",
            "global_step=128928, episodic_return=35.339630126953125\n",
            "global_step=128972, episodic_return=-91.55450439453125\n",
            "SPS: 925\n",
            "global_step=129172, episodic_return=42.82249450683594\n",
            "SPS: 925\n",
            "SPS: 924\n",
            "global_step=130200, episodic_return=131.9591522216797\n",
            "SPS: 923\n",
            "global_step=130800, episodic_return=13.042617797851562\n",
            "SPS: 921\n",
            "global_step=131212, episodic_return=-104.20304870605469\n",
            "global_step=131548, episodic_return=1.5196685791015625\n",
            "SPS: 919\n",
            "SPS: 916\n",
            "global_step=132144, episodic_return=-96.01631164550781\n",
            "global_step=132360, episodic_return=-7.29937744140625\n",
            "SPS: 914\n",
            "SPS: 912\n",
            "global_step=133628, episodic_return=-18.88109588623047\n",
            "SPS: 908\n",
            "SPS: 904\n",
            "global_step=134484, episodic_return=-180.01071166992188\n",
            "SPS: 902\n",
            "SPS: 900\n",
            "global_step=135548, episodic_return=123.43844604492188\n",
            "SPS: 897\n",
            "SPS: 895\n",
            "global_step=136360, episodic_return=64.29669952392578\n",
            "SPS: 893\n",
            "SPS: 891\n",
            "global_step=137404, episodic_return=-42.078285217285156\n",
            "global_step=137492, episodic_return=-37.8841667175293\n",
            "global_step=137628, episodic_return=101.43009185791016\n",
            "SPS: 890\n",
            "SPS: 889\n",
            "global_step=138484, episodic_return=-54.17496871948242\n",
            "SPS: 889\n",
            "global_step=138968, episodic_return=-60.890506744384766\n",
            "SPS: 888\n",
            "global_step=139372, episodic_return=-38.5395622253418\n",
            "global_step=139616, episodic_return=-40.2826042175293\n",
            "SPS: 887\n",
            "global_step=140112, episodic_return=25.92534637451172\n",
            "SPS: 887\n",
            "SPS: 885\n",
            "global_step=140916, episodic_return=-59.52368927001953\n",
            "SPS: 882\n",
            "global_step=141560, episodic_return=1.440277099609375\n",
            "global_step=141760, episodic_return=4.991111755371094\n",
            "SPS: 879\n",
            "SPS: 875\n",
            "global_step=142484, episodic_return=68.80455017089844\n",
            "SPS: 873\n",
            "SPS: 871\n",
            "global_step=143616, episodic_return=54.68196487426758\n",
            "global_step=143744, episodic_return=27.043785095214844\n",
            "SPS: 869\n",
            "SPS: 867\n",
            "SPS: 863\n",
            "SPS: 858\n",
            "global_step=145560, episodic_return=46.13092803955078\n",
            "global_step=145760, episodic_return=57.82844543457031\n",
            "SPS: 855\n",
            "SPS: 852\n",
            "SPS: 848\n",
            "SPS: 841\n",
            "global_step=147616, episodic_return=30.940214157104492\n",
            "global_step=147744, episodic_return=-189.63455200195312\n",
            "SPS: 835\n",
            "global_step=148020, episodic_return=-52.913177490234375\n",
            "SPS: 833\n",
            "SPS: 831\n",
            "SPS: 829\n",
            "global_step=149560, episodic_return=-48.43187713623047\n",
            "global_step=149668, episodic_return=-60.02058792114258\n",
            "SPS: 828\n",
            "SPS: 827\n",
            "SPS: 825\n",
            "SPS: 822\n",
            "global_step=151616, episodic_return=63.184688568115234\n",
            "global_step=151988, episodic_return=-43.00520324707031\n",
            "global_step=152020, episodic_return=12.66256332397461\n",
            "SPS: 821\n",
            "SPS: 820\n",
            "SPS: 819\n",
            "SPS: 817\n",
            "global_step=153668, episodic_return=-84.86905670166016\n",
            "SPS: 815\n",
            "SPS: 810\n",
            "SPS: 803\n",
            "global_step=155616, episodic_return=68.46587371826172\n",
            "SPS: 797\n",
            "global_step=155988, episodic_return=-5.954165458679199\n",
            "global_step=156020, episodic_return=25.82327651977539\n",
            "SPS: 794\n",
            "SPS: 793\n",
            "global_step=157120, episodic_return=24.749961853027344\n",
            "SPS: 792\n",
            "global_step=157668, episodic_return=3.361114501953125\n",
            "SPS: 789\n",
            "global_step=158060, episodic_return=35.033721923828125\n",
            "SPS: 788\n",
            "SPS: 787\n",
            "global_step=159112, episodic_return=-12.067367553710938\n",
            "SPS: 785\n",
            "global_step=159616, episodic_return=91.48048400878906\n",
            "SPS: 784\n",
            "global_step=160020, episodic_return=118.50689697265625\n",
            "SPS: 784\n",
            "SPS: 782\n",
            "SPS: 780\n",
            "SPS: 777\n",
            "global_step=162060, episodic_return=62.604034423828125\n",
            "SPS: 775\n",
            "global_step=162656, episodic_return=-125.3620376586914\n",
            "SPS: 774\n",
            "global_step=163112, episodic_return=129.2236785888672\n",
            "SPS: 774\n",
            "SPS: 773\n",
            "global_step=164020, episodic_return=-24.720853805541992\n",
            "SPS: 772\n",
            "SPS: 771\n",
            "SPS: 769\n",
            "SPS: 766\n",
            "global_step=166060, episodic_return=82.00069427490234\n",
            "SPS: 764\n",
            "global_step=166656, episodic_return=62.79087448120117\n",
            "SPS: 763\n",
            "global_step=167112, episodic_return=0.9198371171951294\n",
            "SPS: 761\n",
            "SPS: 759\n",
            "global_step=168020, episodic_return=85.54119110107422\n",
            "SPS: 757\n",
            "SPS: 753\n",
            "SPS: 750\n",
            "SPS: 747\n",
            "global_step=170060, episodic_return=3.8192636966705322\n",
            "SPS: 745\n",
            "global_step=170656, episodic_return=-123.27323913574219\n",
            "SPS: 743\n",
            "global_step=171112, episodic_return=0.16106247901916504\n",
            "SPS: 743\n",
            "global_step=172020, episodic_return=-81.0046615600586\n",
            "SPS: 742\n",
            "SPS: 741\n",
            "SPS: 740\n",
            "SPS: 737\n",
            "global_step=174060, episodic_return=60.49808883666992\n",
            "SPS: 733\n",
            "SPS: 729\n",
            "global_step=174656, episodic_return=40.74597930908203\n",
            "SPS: 727\n",
            "global_step=175112, episodic_return=21.11452865600586\n",
            "SPS: 726\n",
            "global_step=176020, episodic_return=49.437042236328125\n",
            "SPS: 725\n",
            "SPS: 724\n",
            "SPS: 723\n",
            "SPS: 721\n",
            "global_step=178060, episodic_return=-11.230499267578125\n",
            "SPS: 720\n",
            "global_step=178656, episodic_return=103.74940490722656\n",
            "SPS: 719\n",
            "global_step=179112, episodic_return=69.4847412109375\n",
            "SPS: 718\n",
            "SPS: 717\n",
            "global_step=180020, episodic_return=53.934478759765625\n",
            "SPS: 716\n",
            "SPS: 714\n",
            "SPS: 712\n",
            "SPS: 710\n",
            "global_step=182060, episodic_return=-22.620677947998047\n",
            "SPS: 709\n",
            "global_step=182656, episodic_return=49.19614791870117\n",
            "SPS: 708\n",
            "global_step=183112, episodic_return=-15.63680648803711\n",
            "SPS: 707\n",
            "SPS: 707\n",
            "global_step=184020, episodic_return=-55.063453674316406\n",
            "SPS: 706\n",
            "SPS: 706\n",
            "SPS: 704\n",
            "SPS: 702\n",
            "global_step=186060, episodic_return=-50.62977600097656\n",
            "SPS: 700\n",
            "global_step=186656, episodic_return=-79.87356567382812\n",
            "SPS: 698\n",
            "global_step=187112, episodic_return=-53.25651931762695\n",
            "SPS: 696\n",
            "SPS: 695\n",
            "global_step=188020, episodic_return=1.5143929719924927\n",
            "SPS: 694\n",
            "SPS: 693\n",
            "SPS: 691\n",
            "SPS: 689\n",
            "global_step=190060, episodic_return=-67.54192352294922\n",
            "SPS: 687\n",
            "global_step=190656, episodic_return=-51.66487121582031\n",
            "SPS: 685\n",
            "global_step=191112, episodic_return=-51.46366500854492\n",
            "SPS: 684\n",
            "SPS: 683\n",
            "global_step=192020, episodic_return=-14.26209545135498\n",
            "SPS: 682\n",
            "SPS: 679\n",
            "SPS: 676\n",
            "SPS: 673\n",
            "global_step=194060, episodic_return=1.228153944015503\n",
            "SPS: 672\n",
            "global_step=194656, episodic_return=-68.49412536621094\n",
            "SPS: 670\n",
            "global_step=195112, episodic_return=-39.19304275512695\n",
            "SPS: 670\n",
            "global_step=196020, episodic_return=-93.85095977783203\n",
            "SPS: 669\n",
            "SPS: 669\n",
            "SPS: 669\n",
            "SPS: 668\n",
            "global_step=198060, episodic_return=-44.5633544921875\n",
            "SPS: 666\n",
            "global_step=198656, episodic_return=-42.134151458740234\n",
            "SPS: 664\n",
            "global_step=199112, episodic_return=-13.38833236694336\n",
            "SPS: 663\n",
            "SPS: 662\n",
            "global_step=200020, episodic_return=-30.346654891967773\n",
            "SPS: 661\n",
            "SPS: 661\n",
            "SPS: 660\n",
            "SPS: 658\n",
            "global_step=202060, episodic_return=-47.62922286987305\n",
            "SPS: 657\n",
            "global_step=202656, episodic_return=-84.36062622070312\n",
            "SPS: 656\n",
            "global_step=203112, episodic_return=-102.91777038574219\n",
            "SPS: 656\n",
            "SPS: 655\n",
            "global_step=204020, episodic_return=-61.75510787963867\n",
            "SPS: 655\n",
            "SPS: 654\n",
            "SPS: 653\n",
            "SPS: 651\n",
            "global_step=206060, episodic_return=-56.16116714477539\n",
            "SPS: 649\n",
            "global_step=206656, episodic_return=-37.79510498046875\n",
            "SPS: 648\n",
            "global_step=207112, episodic_return=-59.398075103759766\n",
            "SPS: 648\n",
            "SPS: 647\n",
            "global_step=208020, episodic_return=-50.57527542114258\n",
            "SPS: 647\n",
            "SPS: 646\n",
            "SPS: 646\n",
            "SPS: 645\n",
            "global_step=210060, episodic_return=-54.71323013305664\n",
            "SPS: 644\n",
            "global_step=210656, episodic_return=-13.874820709228516\n",
            "SPS: 642\n",
            "global_step=211112, episodic_return=-25.688655853271484\n",
            "SPS: 641\n",
            "SPS: 640\n",
            "global_step=212020, episodic_return=-22.684764862060547\n",
            "SPS: 640\n",
            "SPS: 639\n",
            "SPS: 639\n",
            "SPS: 638\n",
            "global_step=214060, episodic_return=-39.12874221801758\n",
            "SPS: 637\n",
            "global_step=214656, episodic_return=-59.944766998291016\n",
            "SPS: 636\n",
            "global_step=215112, episodic_return=-58.857452392578125\n",
            "SPS: 636\n",
            "global_step=216020, episodic_return=-111.33854675292969\n",
            "SPS: 636\n",
            "SPS: 636\n",
            "SPS: 635\n",
            "SPS: 634\n",
            "global_step=218060, episodic_return=-47.592281341552734\n",
            "SPS: 632\n",
            "SPS: 630\n",
            "global_step=218656, episodic_return=-99.46440124511719\n",
            "global_step=219112, episodic_return=-42.59720993041992\n",
            "SPS: 630\n",
            "SPS: 630\n",
            "global_step=220020, episodic_return=-51.83399200439453\n",
            "SPS: 629\n",
            "SPS: 629\n",
            "SPS: 628\n",
            "SPS: 627\n",
            "global_step=222060, episodic_return=-30.783096313476562\n",
            "SPS: 626\n",
            "global_step=222656, episodic_return=-78.27091217041016\n",
            "SPS: 626\n",
            "global_step=223112, episodic_return=-66.3800277709961\n",
            "SPS: 625\n",
            "SPS: 625\n",
            "global_step=224020, episodic_return=-70.88790130615234\n",
            "SPS: 624\n",
            "SPS: 623\n",
            "SPS: 621\n",
            "SPS: 620\n",
            "global_step=226060, episodic_return=-35.75208282470703\n",
            "SPS: 620\n",
            "global_step=226656, episodic_return=-62.2041130065918\n",
            "SPS: 619\n",
            "global_step=227112, episodic_return=-26.884597778320312\n",
            "SPS: 619\n",
            "SPS: 619\n",
            "global_step=228020, episodic_return=-34.9421501159668\n",
            "SPS: 619\n",
            "SPS: 619\n",
            "SPS: 619\n",
            "SPS: 619\n",
            "global_step=230060, episodic_return=-46.312957763671875\n",
            "SPS: 618\n",
            "global_step=230656, episodic_return=-45.23693084716797\n",
            "SPS: 617\n",
            "global_step=231112, episodic_return=-44.226173400878906\n",
            "SPS: 617\n",
            "SPS: 616\n",
            "global_step=232020, episodic_return=-41.77759552001953\n",
            "SPS: 615\n",
            "SPS: 614\n",
            "SPS: 613\n",
            "SPS: 612\n",
            "global_step=234060, episodic_return=-68.3807144165039\n",
            "SPS: 611\n",
            "global_step=234656, episodic_return=-25.246065139770508\n",
            "SPS: 611\n",
            "global_step=235112, episodic_return=-5.286251544952393\n",
            "SPS: 611\n",
            "global_step=236020, episodic_return=-33.860164642333984\n",
            "SPS: 611\n",
            "SPS: 611\n",
            "SPS: 611\n",
            "SPS: 609\n",
            "global_step=238060, episodic_return=-20.16845703125\n",
            "SPS: 608\n",
            "SPS: 606\n",
            "global_step=238656, episodic_return=-30.261585235595703\n",
            "SPS: 606\n",
            "global_step=239112, episodic_return=-29.399778366088867\n",
            "SPS: 605\n",
            "global_step=240020, episodic_return=-82.86615753173828\n",
            "SPS: 604\n",
            "SPS: 604\n",
            "SPS: 604\n",
            "SPS: 603\n",
            "global_step=242060, episodic_return=-67.84119415283203\n",
            "SPS: 603\n",
            "global_step=242656, episodic_return=-24.240510940551758\n",
            "SPS: 602\n",
            "global_step=243112, episodic_return=-20.642475128173828\n",
            "SPS: 602\n",
            "SPS: 601\n",
            "global_step=244020, episodic_return=-71.76614379882812\n",
            "SPS: 600\n",
            "SPS: 599\n",
            "SPS: 599\n",
            "SPS: 598\n",
            "global_step=246060, episodic_return=-28.65255355834961\n",
            "SPS: 597\n",
            "global_step=246656, episodic_return=-63.34761428833008\n",
            "SPS: 597\n",
            "global_step=247112, episodic_return=-78.18943786621094\n",
            "SPS: 596\n",
            "SPS: 596\n",
            "global_step=248020, episodic_return=-62.80747604370117\n",
            "SPS: 596\n",
            "SPS: 596\n",
            "SPS: 595\n",
            "SPS: 593\n",
            "global_step=250060, episodic_return=-39.976470947265625\n",
            "SPS: 591\n",
            "global_step=250656, episodic_return=-45.52886199951172\n",
            "SPS: 590\n",
            "global_step=251112, episodic_return=-51.848323822021484\n",
            "SPS: 589\n",
            "SPS: 589\n",
            "global_step=252020, episodic_return=-62.48799514770508\n",
            "SPS: 589\n",
            "SPS: 589\n",
            "SPS: 589\n",
            "SPS: 588\n",
            "global_step=254060, episodic_return=-16.28303337097168\n",
            "SPS: 588\n",
            "global_step=254656, episodic_return=-51.326168060302734\n",
            "SPS: 588\n",
            "global_step=255112, episodic_return=-38.59412384033203\n",
            "SPS: 587\n",
            "SPS: 586\n",
            "global_step=256020, episodic_return=-22.327932357788086\n",
            "SPS: 586\n",
            "SPS: 585\n",
            "SPS: 584\n",
            "SPS: 584\n",
            "global_step=258060, episodic_return=-46.686279296875\n",
            "SPS: 583\n",
            "global_step=258656, episodic_return=-38.160179138183594\n",
            "SPS: 583\n",
            "global_step=259112, episodic_return=-69.34596252441406\n",
            "SPS: 583\n",
            "global_step=260020, episodic_return=-61.07309341430664\n",
            "SPS: 583\n",
            "SPS: 583\n",
            "SPS: 583\n",
            "SPS: 582\n",
            "global_step=262060, episodic_return=-9.130935668945312\n",
            "SPS: 581\n",
            "global_step=262656, episodic_return=-47.494815826416016\n",
            "SPS: 580\n",
            "global_step=263112, episodic_return=-23.519805908203125\n",
            "SPS: 579\n",
            "SPS: 579\n",
            "global_step=264020, episodic_return=-50.984230041503906\n",
            "SPS: 579\n",
            "SPS: 579\n",
            "SPS: 578\n",
            "SPS: 578\n",
            "global_step=266060, episodic_return=-74.84449768066406\n",
            "SPS: 577\n",
            "global_step=266656, episodic_return=-64.95589447021484\n",
            "SPS: 577\n",
            "global_step=267112, episodic_return=-36.287296295166016\n",
            "SPS: 576\n",
            "SPS: 576\n",
            "global_step=268020, episodic_return=-24.316911697387695\n",
            "SPS: 575\n",
            "SPS: 575\n",
            "SPS: 573\n",
            "SPS: 573\n",
            "global_step=270060, episodic_return=-43.10078811645508\n",
            "SPS: 572\n",
            "global_step=270656, episodic_return=-74.01128387451172\n",
            "SPS: 572\n",
            "global_step=271112, episodic_return=-60.64280319213867\n",
            "SPS: 572\n",
            "SPS: 572\n",
            "global_step=272020, episodic_return=-19.526798248291016\n",
            "SPS: 572\n",
            "SPS: 572\n",
            "SPS: 572\n",
            "SPS: 571\n",
            "global_step=274016, episodic_return=-150.0262451171875\n",
            "global_step=274060, episodic_return=-36.33306121826172\n",
            "SPS: 570\n",
            "SPS: 570\n",
            "global_step=275112, episodic_return=-43.466365814208984\n",
            "SPS: 569\n",
            "SPS: 569\n",
            "global_step=276020, episodic_return=-12.206266403198242\n",
            "SPS: 569\n",
            "SPS: 568\n",
            "SPS: 568\n",
            "global_step=278016, episodic_return=-41.331871032714844\n",
            "SPS: 567\n",
            "global_step=278060, episodic_return=6.6959228515625\n",
            "SPS: 567\n",
            "SPS: 566\n",
            "global_step=279112, episodic_return=28.108610153198242\n",
            "SPS: 566\n",
            "global_step=280020, episodic_return=-16.57001304626465\n",
            "SPS: 565\n",
            "SPS: 565\n",
            "SPS: 564\n",
            "SPS: 563\n",
            "global_step=282016, episodic_return=7.87861442565918\n",
            "global_step=282060, episodic_return=-54.019290924072266\n",
            "SPS: 562\n",
            "SPS: 562\n",
            "global_step=283112, episodic_return=-10.262788772583008\n",
            "SPS: 562\n",
            "global_step=283596, episodic_return=-142.4476318359375\n",
            "SPS: 562\n",
            "SPS: 562\n",
            "SPS: 562\n",
            "SPS: 561\n",
            "SPS: 561\n",
            "global_step=286016, episodic_return=69.80583953857422\n",
            "global_step=286060, episodic_return=59.37175750732422\n",
            "SPS: 560\n",
            "SPS: 559\n",
            "global_step=287112, episodic_return=62.97687530517578\n",
            "SPS: 558\n",
            "global_step=287596, episodic_return=24.885751724243164\n",
            "SPS: 558\n",
            "SPS: 558\n",
            "SPS: 558\n",
            "SPS: 558\n",
            "SPS: 557\n",
            "global_step=290016, episodic_return=45.208946228027344\n",
            "global_step=290060, episodic_return=-23.28411865234375\n",
            "SPS: 557\n",
            "SPS: 557\n",
            "global_step=291112, episodic_return=-32.59333801269531\n",
            "SPS: 557\n",
            "global_step=291596, episodic_return=-31.098508834838867\n",
            "SPS: 557\n",
            "SPS: 557\n",
            "global_step=292776, episodic_return=-127.82011413574219\n",
            "SPS: 557\n",
            "SPS: 557\n",
            "global_step=293664, episodic_return=-71.12945556640625\n",
            "SPS: 557\n",
            "global_step=294016, episodic_return=35.477542877197266\n",
            "SPS: 556\n",
            "SPS: 556\n",
            "SPS: 556\n",
            "global_step=295596, episodic_return=13.797531127929688\n",
            "SPS: 556\n",
            "global_step=296024, episodic_return=-127.20974731445312\n",
            "SPS: 556\n",
            "SPS: 556\n",
            "global_step=297152, episodic_return=110.89816284179688\n",
            "SPS: 555\n",
            "global_step=297664, episodic_return=18.439329147338867\n",
            "SPS: 555\n",
            "SPS: 555\n",
            "SPS: 555\n",
            "SPS: 554\n",
            "global_step=299596, episodic_return=49.74264144897461\n",
            "global_step=299660, episodic_return=-87.72974395751953\n",
            "global_step=300024, episodic_return=22.877065658569336\n",
            "SPS: 554\n",
            "SPS: 554\n",
            "SPS: 553\n",
            "global_step=301152, episodic_return=68.73847198486328\n",
            "SPS: 553\n",
            "SPS: 552\n",
            "SPS: 552\n",
            "global_step=302816, episodic_return=-176.6797637939453\n",
            "SPS: 552\n",
            "global_step=303596, episodic_return=49.917694091796875\n",
            "SPS: 551\n",
            "global_step=304024, episodic_return=17.496990203857422\n",
            "SPS: 551\n",
            "SPS: 552\n",
            "global_step=305152, episodic_return=2.5711910724639893\n",
            "SPS: 552\n",
            "SPS: 551\n",
            "SPS: 551\n",
            "global_step=306256, episodic_return=-99.01991271972656\n",
            "SPS: 551\n",
            "SPS: 550\n",
            "global_step=307596, episodic_return=40.94798278808594\n",
            "SPS: 549\n",
            "global_step=308024, episodic_return=52.17932891845703\n",
            "SPS: 549\n",
            "SPS: 548\n",
            "global_step=309152, episodic_return=31.10085678100586\n",
            "SPS: 548\n",
            "SPS: 548\n",
            "global_step=310028, episodic_return=-112.43136596679688\n",
            "global_step=310256, episodic_return=76.28781127929688\n",
            "SPS: 547\n",
            "SPS: 547\n",
            "SPS: 547\n",
            "SPS: 546\n",
            "global_step=312024, episodic_return=35.341609954833984\n",
            "SPS: 546\n",
            "global_step=312604, episodic_return=180.02658081054688\n",
            "SPS: 545\n",
            "global_step=313152, episodic_return=53.99638748168945\n",
            "SPS: 544\n",
            "SPS: 544\n",
            "global_step=314028, episodic_return=76.08700561523438\n",
            "SPS: 544\n",
            "global_step=314600, episodic_return=-104.97125244140625\n",
            "SPS: 544\n",
            "SPS: 544\n",
            "global_step=315756, episodic_return=127.53401184082031\n",
            "SPS: 543\n",
            "SPS: 543\n",
            "SPS: 543\n",
            "global_step=317152, episodic_return=-84.4510269165039\n",
            "global_step=317384, episodic_return=-109.89083099365234\n",
            "SPS: 543\n",
            "SPS: 543\n",
            "global_step=318028, episodic_return=-58.40696716308594\n",
            "SPS: 543\n",
            "SPS: 543\n",
            "SPS: 542\n",
            "global_step=319756, episodic_return=23.1785945892334\n",
            "SPS: 541\n",
            "SPS: 541\n",
            "SPS: 540\n",
            "global_step=321052, episodic_return=86.99632263183594\n",
            "global_step=321344, episodic_return=-108.89971923828125\n",
            "global_step=321384, episodic_return=16.193010330200195\n",
            "SPS: 540\n",
            "SPS: 540\n",
            "SPS: 540\n",
            "SPS: 540\n",
            "SPS: 540\n",
            "global_step=323756, episodic_return=39.82600402832031\n",
            "SPS: 539\n",
            "global_step=324280, episodic_return=-140.703857421875\n",
            "global_step=324440, episodic_return=-140.9761962890625\n",
            "SPS: 539\n",
            "global_step=324980, episodic_return=107.28166961669922\n",
            "SPS: 539\n",
            "SPS: 539\n",
            "SPS: 539\n",
            "SPS: 538\n",
            "SPS: 538\n",
            "global_step=327436, episodic_return=-149.31236267089844\n",
            "SPS: 537\n",
            "SPS: 537\n",
            "global_step=328280, episodic_return=44.08918380737305\n",
            "global_step=328440, episodic_return=15.940667152404785\n",
            "SPS: 537\n",
            "global_step=328980, episodic_return=50.91937255859375\n",
            "SPS: 537\n",
            "SPS: 537\n",
            "SPS: 537\n",
            "SPS: 537\n",
            "global_step=330964, episodic_return=-151.1078338623047\n",
            "SPS: 536\n",
            "SPS: 536\n",
            "global_step=332280, episodic_return=78.20428466796875\n",
            "SPS: 535\n",
            "global_step=332440, episodic_return=19.94343376159668\n",
            "SPS: 534\n",
            "global_step=332980, episodic_return=64.37507629394531\n",
            "SPS: 534\n",
            "SPS: 534\n",
            "global_step=334204, episodic_return=108.61491394042969\n",
            "SPS: 534\n",
            "SPS: 534\n",
            "global_step=335136, episodic_return=-123.31951141357422\n",
            "SPS: 534\n",
            "SPS: 533\n",
            "SPS: 533\n",
            "global_step=336440, episodic_return=26.037630081176758\n",
            "SPS: 532\n",
            "global_step=336980, episodic_return=-31.761032104492188\n",
            "SPS: 532\n",
            "SPS: 532\n",
            "global_step=338152, episodic_return=84.8818130493164\n",
            "SPS: 531\n",
            "SPS: 531\n",
            "global_step=339004, episodic_return=-83.11968231201172\n",
            "SPS: 531\n",
            "global_step=339668, episodic_return=-91.69366455078125\n",
            "SPS: 531\n",
            "SPS: 530\n",
            "global_step=340980, episodic_return=35.515010833740234\n",
            "SPS: 530\n",
            "SPS: 530\n",
            "SPS: 530\n",
            "global_step=342152, episodic_return=-15.152417182922363\n",
            "SPS: 530\n",
            "global_step=343004, episodic_return=-21.448354721069336\n",
            "SPS: 530\n",
            "SPS: 530\n",
            "global_step=343668, episodic_return=41.30961990356445\n",
            "SPS: 529\n",
            "SPS: 529\n",
            "global_step=344980, episodic_return=3.56550931930542\n",
            "SPS: 529\n",
            "SPS: 528\n",
            "SPS: 528\n",
            "global_step=346152, episodic_return=-3.714665412902832\n",
            "SPS: 528\n",
            "global_step=347004, episodic_return=-3.757737398147583\n",
            "SPS: 528\n",
            "SPS: 528\n",
            "global_step=347668, episodic_return=41.23155212402344\n",
            "SPS: 528\n",
            "SPS: 528\n",
            "global_step=348788, episodic_return=-86.3837661743164\n",
            "global_step=348980, episodic_return=-15.65841293334961\n",
            "SPS: 528\n",
            "SPS: 528\n",
            "SPS: 528\n",
            "SPS: 527\n",
            "global_step=351004, episodic_return=48.2413330078125\n",
            "SPS: 526\n",
            "global_step=351668, episodic_return=25.06128692626953\n",
            "SPS: 526\n",
            "SPS: 526\n",
            "SPS: 525\n",
            "global_step=352788, episodic_return=14.066254615783691\n",
            "global_step=352980, episodic_return=7.987933158874512\n",
            "SPS: 525\n",
            "SPS: 526\n",
            "SPS: 525\n",
            "SPS: 525\n",
            "global_step=355004, episodic_return=23.62337875366211\n",
            "SPS: 525\n",
            "global_step=355668, episodic_return=46.17171859741211\n",
            "SPS: 525\n",
            "SPS: 524\n",
            "global_step=356788, episodic_return=58.75310134887695\n",
            "SPS: 524\n",
            "global_step=356980, episodic_return=51.288272857666016\n",
            "SPS: 524\n",
            "SPS: 523\n",
            "global_step=357948, episodic_return=-98.02271270751953\n",
            "SPS: 523\n",
            "SPS: 523\n",
            "SPS: 523\n",
            "global_step=359668, episodic_return=40.643104553222656\n",
            "SPS: 523\n",
            "SPS: 522\n",
            "global_step=360788, episodic_return=29.17138671875\n",
            "SPS: 522\n",
            "global_step=360980, episodic_return=51.85454177856445\n",
            "SPS: 522\n",
            "global_step=361948, episodic_return=59.62456512451172\n",
            "SPS: 522\n",
            "SPS: 522\n",
            "SPS: 522\n",
            "global_step=363068, episodic_return=-108.81204986572266\n",
            "global_step=363416, episodic_return=-119.52195739746094\n",
            "SPS: 522\n",
            "SPS: 521\n",
            "SPS: 521\n",
            "global_step=364980, episodic_return=75.05418395996094\n",
            "SPS: 521\n",
            "SPS: 521\n",
            "global_step=365948, episodic_return=8.965306282043457\n",
            "SPS: 521\n",
            "global_step=366200, episodic_return=-108.09221649169922\n",
            "SPS: 521\n",
            "SPS: 521\n",
            "global_step=367416, episodic_return=61.46945571899414\n",
            "SPS: 521\n",
            "SPS: 521\n",
            "global_step=368320, episodic_return=91.51154327392578\n",
            "SPS: 521\n",
            "global_step=368824, episodic_return=-108.773681640625\n",
            "SPS: 521\n",
            "SPS: 521\n",
            "SPS: 520\n",
            "global_step=370200, episodic_return=34.77093505859375\n",
            "SPS: 520\n",
            "SPS: 519\n",
            "global_step=371416, episodic_return=57.576011657714844\n",
            "SPS: 519\n",
            "global_step=371740, episodic_return=113.49884796142578\n",
            "SPS: 519\n",
            "global_step=372320, episodic_return=6.227441787719727\n",
            "SPS: 520\n",
            "SPS: 520\n",
            "SPS: 520\n",
            "global_step=374200, episodic_return=20.40261459350586\n",
            "SPS: 519\n",
            "SPS: 519\n",
            "global_step=374816, episodic_return=-127.92015838623047\n",
            "SPS: 519\n",
            "global_step=375416, episodic_return=53.49939727783203\n",
            "global_step=375740, episodic_return=40.3845329284668\n",
            "SPS: 519\n",
            "SPS: 520\n",
            "SPS: 520\n",
            "SPS: 519\n",
            "SPS: 518\n",
            "global_step=378200, episodic_return=32.037078857421875\n",
            "SPS: 518\n",
            "global_step=378816, episodic_return=33.89529037475586\n",
            "SPS: 518\n",
            "SPS: 518\n",
            "global_step=379416, episodic_return=3.2765495777130127\n",
            "global_step=379740, episodic_return=13.491716384887695\n",
            "SPS: 518\n",
            "SPS: 518\n",
            "SPS: 518\n",
            "global_step=381352, episodic_return=-71.96184539794922\n",
            "SPS: 518\n",
            "SPS: 517\n",
            "global_step=382200, episodic_return=0.6897403001785278\n",
            "SPS: 517\n",
            "global_step=382680, episodic_return=-140.49351501464844\n",
            "SPS: 517\n",
            "global_step=383476, episodic_return=-73.1340103149414\n",
            "SPS: 517\n",
            "global_step=383740, episodic_return=71.1065444946289\n",
            "SPS: 517\n",
            "SPS: 516\n",
            "SPS: 516\n",
            "SPS: 516\n",
            "global_step=385748, episodic_return=91.23746490478516\n",
            "SPS: 515\n",
            "SPS: 515\n",
            "global_step=386680, episodic_return=60.58905792236328\n",
            "global_step=386696, episodic_return=-92.12185668945312\n",
            "SPS: 515\n",
            "global_step=387476, episodic_return=12.944355010986328\n",
            "SPS: 515\n",
            "SPS: 516\n",
            "SPS: 516\n",
            "SPS: 516\n",
            "global_step=389356, episodic_return=148.04771423339844\n",
            "global_step=389536, episodic_return=-123.3845443725586\n",
            "SPS: 515\n",
            "SPS: 515\n",
            "global_step=390156, episodic_return=84.01483917236328\n",
            "SPS: 515\n",
            "SPS: 515\n",
            "global_step=391476, episodic_return=53.66097640991211\n",
            "SPS: 515\n",
            "SPS: 515\n",
            "global_step=392416, episodic_return=-85.75363159179688\n",
            "SPS: 515\n",
            "SPS: 515\n",
            "global_step=393356, episodic_return=74.05010986328125\n",
            "SPS: 515\n",
            "global_step=394156, episodic_return=86.72319030761719\n",
            "SPS: 515\n",
            "SPS: 515\n",
            "SPS: 515\n",
            "global_step=395476, episodic_return=46.417091369628906\n",
            "global_step=395628, episodic_return=-70.46184539794922\n",
            "SPS: 515\n",
            "SPS: 515\n",
            "global_step=396416, episodic_return=16.14175796508789\n",
            "SPS: 515\n",
            "SPS: 515\n",
            "SPS: 515\n",
            "global_step=398156, episodic_return=43.79232406616211\n",
            "SPS: 514\n",
            "global_step=398408, episodic_return=119.49095916748047\n",
            "SPS: 514\n",
            "SPS: 514\n",
            "global_step=399476, episodic_return=70.31404113769531\n",
            "SPS: 514\n",
            "SPS: 513\n",
            "global_step=400416, episodic_return=67.63475799560547\n",
            "SPS: 513\n",
            "global_step=401108, episodic_return=133.97225952148438\n",
            "SPS: 513\n",
            "SPS: 513\n",
            "global_step=402184, episodic_return=-69.64053344726562\n",
            "global_step=402408, episodic_return=27.482927322387695\n",
            "SPS: 513\n",
            "SPS: 513\n",
            "SPS: 513\n",
            "SPS: 513\n",
            "global_step=404416, episodic_return=26.975305557250977\n",
            "SPS: 512\n",
            "SPS: 511\n",
            "global_step=405108, episodic_return=26.64171600341797\n",
            "SPS: 511\n",
            "SPS: 511\n",
            "global_step=406184, episodic_return=52.48518753051758\n",
            "global_step=406408, episodic_return=45.5136604309082\n",
            "global_step=406456, episodic_return=-58.85870361328125\n",
            "SPS: 511\n",
            "SPS: 511\n",
            "SPS: 511\n",
            "global_step=407848, episodic_return=172.80398559570312\n",
            "SPS: 511\n",
            "SPS: 512\n",
            "global_step=408848, episodic_return=142.1527862548828\n",
            "SPS: 512\n",
            "global_step=409424, episodic_return=-55.85459899902344\n",
            "SPS: 512\n",
            "global_step=409796, episodic_return=113.33208465576172\n",
            "SPS: 512\n",
            "SPS: 512\n",
            "global_step=410800, episodic_return=-80.6869125366211\n",
            "SPS: 512\n",
            "global_step=411556, episodic_return=-109.52880859375\n",
            "SPS: 512\n",
            "global_step=411764, episodic_return=-101.67852020263672\n",
            "SPS: 512\n",
            "SPS: 511\n",
            "SPS: 511\n",
            "SPS: 511\n",
            "global_step=413796, episodic_return=18.620342254638672\n",
            "SPS: 511\n",
            "global_step=414348, episodic_return=-71.50814819335938\n",
            "SPS: 511\n",
            "global_step=414756, episodic_return=-157.57518005371094\n",
            "global_step=414800, episodic_return=-70.17326354980469\n",
            "global_step=415188, episodic_return=-0.9984207153320312\n",
            "SPS: 511\n",
            "SPS: 511\n",
            "SPS: 511\n",
            "SPS: 511\n",
            "SPS: 511\n",
            "SPS: 511\n",
            "SPS: 510\n",
            "global_step=418348, episodic_return=39.68976593017578\n",
            "global_step=418756, episodic_return=19.57932472229004\n",
            "global_step=418800, episodic_return=32.81723403930664\n",
            "SPS: 510\n",
            "global_step=419188, episodic_return=5.613768577575684\n",
            "SPS: 510\n",
            "SPS: 510\n",
            "SPS: 510\n",
            "SPS: 510\n",
            "SPS: 510\n",
            "global_step=421688, episodic_return=148.94155883789062\n",
            "global_step=421864, episodic_return=140.66729736328125\n",
            "SPS: 510\n",
            "SPS: 510\n",
            "global_step=422756, episodic_return=55.36441421508789\n",
            "SPS: 510\n",
            "global_step=423188, episodic_return=26.754192352294922\n",
            "SPS: 510\n",
            "SPS: 510\n",
            "global_step=424004, episodic_return=154.6500244140625\n",
            "global_step=424160, episodic_return=152.63999938964844\n",
            "SPS: 510\n",
            "SPS: 510\n",
            "SPS: 510\n",
            "SPS: 509\n",
            "SPS: 509\n",
            "global_step=426756, episodic_return=20.043304443359375\n",
            "global_step=426760, episodic_return=142.00665283203125\n",
            "SPS: 509\n",
            "SPS: 509\n",
            "global_step=427992, episodic_return=106.76404571533203\n",
            "SPS: 509\n",
            "global_step=428160, episodic_return=71.20073699951172\n",
            "SPS: 509\n",
            "SPS: 509\n",
            "SPS: 509\n",
            "SPS: 509\n",
            "SPS: 509\n",
            "global_step=430756, episodic_return=40.4202880859375\n",
            "global_step=430760, episodic_return=50.16553497314453\n",
            "SPS: 509\n",
            "SPS: 508\n",
            "global_step=431992, episodic_return=75.03253173828125\n",
            "SPS: 508\n",
            "global_step=432160, episodic_return=82.84656524658203\n",
            "SPS: 508\n",
            "SPS: 508\n",
            "SPS: 508\n",
            "global_step=434056, episodic_return=125.23637390136719\n",
            "SPS: 508\n",
            "SPS: 507\n",
            "global_step=434760, episodic_return=47.2237434387207\n",
            "SPS: 507\n",
            "SPS: 507\n",
            "global_step=435992, episodic_return=72.20059967041016\n",
            "global_step=436160, episodic_return=72.91487884521484\n",
            "SPS: 507\n",
            "SPS: 508\n",
            "SPS: 508\n",
            "SPS: 507\n",
            "global_step=437944, episodic_return=130.0584259033203\n",
            "global_step=438056, episodic_return=69.88717651367188\n",
            "SPS: 507\n",
            "SPS: 507\n",
            "global_step=439096, episodic_return=122.18109130859375\n",
            "SPS: 507\n",
            "global_step=439444, episodic_return=84.54341888427734\n",
            "SPS: 507\n",
            "SPS: 507\n",
            "SPS: 507\n",
            "global_step=440976, episodic_return=107.03927612304688\n",
            "SPS: 507\n",
            "global_step=441588, episodic_return=-105.81491088867188\n",
            "SPS: 507\n",
            "global_step=442056, episodic_return=17.16097068786621\n",
            "SPS: 507\n",
            "SPS: 507\n",
            "SPS: 507\n",
            "global_step=443420, episodic_return=-137.90943908691406\n",
            "global_step=443444, episodic_return=57.41517639160156\n",
            "SPS: 507\n",
            "SPS: 507\n",
            "global_step=444612, episodic_return=166.83493041992188\n",
            "SPS: 507\n",
            "SPS: 506\n",
            "global_step=445592, episodic_return=-85.2913589477539\n",
            "SPS: 506\n",
            "global_step=446056, episodic_return=55.95685577392578\n",
            "SPS: 506\n",
            "global_step=446492, episodic_return=-128.0619659423828\n",
            "SPS: 506\n",
            "SPS: 506\n",
            "SPS: 506\n",
            "global_step=448164, episodic_return=115.28609466552734\n",
            "SPS: 506\n",
            "global_step=448676, episodic_return=-118.22859954833984\n",
            "SPS: 505\n",
            "SPS: 505\n",
            "global_step=449592, episodic_return=43.18389892578125\n",
            "SPS: 505\n",
            "global_step=450492, episodic_return=49.49598693847656\n",
            "SPS: 505\n",
            "SPS: 505\n",
            "SPS: 505\n",
            "SPS: 505\n",
            "global_step=452164, episodic_return=28.470151901245117\n",
            "SPS: 504\n",
            "global_step=452676, episodic_return=20.2947998046875\n",
            "SPS: 504\n",
            "global_step=453592, episodic_return=71.09757995605469\n",
            "SPS: 504\n",
            "SPS: 503\n",
            "global_step=454492, episodic_return=11.476780891418457\n",
            "SPS: 503\n",
            "global_step=455060, episodic_return=140.02969360351562\n",
            "SPS: 503\n",
            "SPS: 503\n",
            "global_step=456164, episodic_return=79.33155059814453\n",
            "SPS: 503\n",
            "SPS: 504\n",
            "SPS: 504\n",
            "global_step=457404, episodic_return=-111.86157989501953\n",
            "global_step=457592, episodic_return=46.00602340698242\n",
            "SPS: 504\n",
            "SPS: 503\n",
            "SPS: 503\n",
            "global_step=459060, episodic_return=44.75848388671875\n",
            "SPS: 503\n",
            "SPS: 503\n",
            "global_step=460164, episodic_return=-74.5833740234375\n",
            "SPS: 503\n",
            "global_step=460788, episodic_return=135.94729614257812\n",
            "SPS: 503\n",
            "SPS: 503\n",
            "SPS: 503\n",
            "global_step=462060, episodic_return=146.96768188476562\n",
            "SPS: 503\n",
            "SPS: 502\n",
            "global_step=462904, episodic_return=-101.1673355102539\n",
            "SPS: 502\n",
            "SPS: 502\n",
            "global_step=464164, episodic_return=50.34721374511719\n",
            "SPS: 502\n",
            "SPS: 502\n",
            "SPS: 501\n",
            "SPS: 501\n",
            "global_step=466060, episodic_return=18.463756561279297\n",
            "SPS: 501\n",
            "global_step=466904, episodic_return=48.4693603515625\n",
            "SPS: 500\n",
            "SPS: 500\n",
            "SPS: 500\n",
            "global_step=468164, episodic_return=60.535850524902344\n",
            "SPS: 500\n",
            "global_step=468496, episodic_return=-78.63123321533203\n",
            "SPS: 500\n",
            "SPS: 500\n",
            "SPS: 500\n",
            "SPS: 499\n",
            "global_step=470904, episodic_return=53.95661926269531\n",
            "SPS: 499\n",
            "global_step=471172, episodic_return=-94.62578582763672\n",
            "SPS: 499\n",
            "SPS: 499\n",
            "global_step=472164, episodic_return=36.430973052978516\n",
            "global_step=472496, episodic_return=62.907596588134766\n",
            "SPS: 499\n",
            "global_step=472848, episodic_return=-48.83805465698242\n",
            "SPS: 499\n",
            "SPS: 499\n",
            "SPS: 499\n",
            "SPS: 499\n",
            "global_step=474904, episodic_return=53.047645568847656\n",
            "SPS: 499\n",
            "SPS: 499\n",
            "SPS: 498\n",
            "global_step=476164, episodic_return=36.802398681640625\n",
            "global_step=476496, episodic_return=55.93803405761719\n",
            "SPS: 498\n",
            "global_step=476848, episodic_return=66.05059051513672\n",
            "SPS: 498\n",
            "SPS: 498\n",
            "SPS: 498\n",
            "SPS: 498\n",
            "global_step=478904, episodic_return=52.32932662963867\n",
            "SPS: 498\n",
            "SPS: 498\n",
            "global_step=480164, episodic_return=29.96028709411621\n",
            "SPS: 498\n",
            "global_step=480496, episodic_return=84.69617462158203\n",
            "SPS: 498\n",
            "global_step=480848, episodic_return=48.7946662902832\n",
            "SPS: 498\n",
            "SPS: 498\n",
            "SPS: 498\n",
            "SPS: 497\n",
            "global_step=482904, episodic_return=72.33638763427734\n",
            "SPS: 497\n",
            "SPS: 496\n",
            "global_step=484164, episodic_return=43.41938781738281\n",
            "SPS: 496\n",
            "global_step=484496, episodic_return=53.34809112548828\n",
            "global_step=484848, episodic_return=25.185274124145508\n",
            "SPS: 496\n",
            "SPS: 496\n",
            "SPS: 496\n",
            "SPS: 496\n",
            "global_step=486904, episodic_return=36.966163635253906\n",
            "SPS: 496\n",
            "global_step=487048, episodic_return=-102.79122924804688\n",
            "SPS: 496\n",
            "global_step=487692, episodic_return=-105.29765319824219\n",
            "SPS: 496\n",
            "global_step=487988, episodic_return=138.94602966308594\n",
            "SPS: 496\n",
            "SPS: 496\n",
            "global_step=489120, episodic_return=-106.72352600097656\n",
            "SPS: 496\n",
            "global_step=489748, episodic_return=106.84610748291016\n",
            "SPS: 496\n",
            "global_step=490396, episodic_return=-47.668128967285156\n",
            "SPS: 496\n",
            "global_step=490612, episodic_return=-63.18695068359375\n",
            "SPS: 496\n",
            "SPS: 496\n",
            "SPS: 496\n",
            "SPS: 496\n",
            "global_step=492580, episodic_return=-149.18519592285156\n",
            "SPS: 496\n",
            "global_step=493120, episodic_return=58.215370178222656\n",
            "global_step=493252, episodic_return=-98.17098236083984\n",
            "SPS: 496\n",
            "SPS: 496\n",
            "global_step=494396, episodic_return=63.7194938659668\n",
            "SPS: 496\n",
            "SPS: 496\n",
            "SPS: 496\n",
            "SPS: 496\n",
            "global_step=496580, episodic_return=57.641944885253906\n",
            "SPS: 495\n",
            "global_step=497120, episodic_return=78.2001724243164\n",
            "SPS: 494\n",
            "global_step=497252, episodic_return=63.90666580200195\n",
            "SPS: 494\n",
            "global_step=497884, episodic_return=163.9649200439453\n",
            "SPS: 494\n",
            "SPS: 494\n",
            "SPS: 494\n",
            "global_step=499328, episodic_return=-118.89259338378906\n",
            "SPS: 494\n",
            "\u001b[38;5;4m‚Ñπ This function will save, evaluate, generate a video of your agent,\n",
            "create a model card and push everything to the hub. It might take up to 1min.\n",
            "This is a work in progress: if you encounter a bug, please open an issue.\u001b[0m\n",
            "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (600, 400) to (608, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
            "\u001b[1;34m[swscaler @ 0x6d13440] \u001b[0m\u001b[0;33mWarning: data is not aligned! This can lead to a speed loss\n",
            "\u001b[0m\u001b[38;5;4m‚Ñπ Pushing repo QuickSilver007/rl2v2unit8_ppo-CartPole-v1 to the Hugging\n",
            "Face Hub\u001b[0m\n",
            "Upload 2 LFS files:   0% 0/2 [00:00<?, ?it/s]\n",
            "events.out.tfevents.1685014158.ea0ae8e4338b.18513.0:   0% 0.00/667k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model.pt:   0% 0.00/42.6k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "events.out.tfevents.1685014158.ea0ae8e4338b.18513.0:   1% 8.19k/667k [00:00<00:11, 57.8kB/s]\u001b[A\n",
            "\n",
            "model.pt:  19% 8.19k/42.6k [00:00<00:00, 58.0kB/s]\u001b[A\u001b[A\n",
            "model.pt: 100% 42.6k/42.6k [00:00<00:00, 119kB/s] \n",
            "events.out.tfevents.1685014158.ea0ae8e4338b.18513.0: 100% 667k/667k [00:00<00:00, 1.47MB/s]\n",
            "Upload 2 LFS files: 100% 2/2 [00:00<00:00,  3.24it/s]\n",
            "\u001b[38;5;4m‚Ñπ Your model is pushed to the Hub. You can view your model here:\n",
            "https://huggingface.co/QuickSilver007/rl2v2unit8_ppo-CartPole-v1/tree/main/\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVsVJ5AdqLE7"
      },
      "source": [
        "## Some additional challenges üèÜ\n",
        "The best way to learn **is to try things by your own**! Why not trying  another environment?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYdl758GqLXT"
      },
      "source": [
        "See you on Unit 8, part 2 where we going to train agents to play Doom üî•\n",
        "## Keep learning, stay awesome ü§ó"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6c8583681c3f49e3a853edef77cac551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d7c286d9d5a4b1ab846eb377c367fa5",
              "IPY_MODEL_14a9bdeef8964ce69d93fe5701aa19cd",
              "IPY_MODEL_9f91f8d71ecb4c17a4f6435a4ccc19af",
              "IPY_MODEL_087b6d05646341a4ad3643f5fd604d5f"
            ],
            "layout": "IPY_MODEL_2daf2824e5e94f5ea03961bbe23aff27"
          }
        },
        "81f83c6288aa4aa78e60c22e89b4286a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64c5e9265b724ef3bd78af1c2d82a40a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ac0d599cf7d34d7cba7a3b5bb84a60c9",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "d0882b870e294a82917e6927e47ee8cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_5fff87e93c2a44e0914587724387f358",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d8848dcbd4a84ce2b44f853fcea46918",
            "value": ""
          }
        },
        "f870d9f9dd114886b1fdd155d3fdda6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_e54fb8d3646a420e8dcb706b2479b0cb",
            "style": "IPY_MODEL_8cca2a9dcf064b82ad530063cf426e54",
            "value": true
          }
        },
        "31d9a98c5f5a4add9ddee7c417371230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_333573acb4bc48dba4e6ee02fa636a9c",
            "style": "IPY_MODEL_9e4301aec28e45f8bce297463c5a43ed",
            "tooltip": ""
          }
        },
        "224fc3066a4e473291f74be46501c210": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_294704d14de149ca9d5c9d0e64236931",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_710a727749ac4b60b6252ff3412c8a51",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "2daf2824e5e94f5ea03961bbe23aff27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "64c5e9265b724ef3bd78af1c2d82a40a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac0d599cf7d34d7cba7a3b5bb84a60c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5fff87e93c2a44e0914587724387f358": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8848dcbd4a84ce2b44f853fcea46918": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e54fb8d3646a420e8dcb706b2479b0cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cca2a9dcf064b82ad530063cf426e54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "333573acb4bc48dba4e6ee02fa636a9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e4301aec28e45f8bce297463c5a43ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "294704d14de149ca9d5c9d0e64236931": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "710a727749ac4b60b6252ff3412c8a51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99564c26504c4c8091ef396a6e5c4521": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c055104496f4f4bb7edc84e2e61fdfb",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6f5d03f184dd42bfa3d0ce24b2d74c00",
            "value": "Connecting..."
          }
        },
        "5c055104496f4f4bb7edc84e2e61fdfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f5d03f184dd42bfa3d0ce24b2d74c00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d7c286d9d5a4b1ab846eb377c367fa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c371cb058acc42b88607ab9e1af3c351",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_543240d77185406993b2add823e9c1fe",
            "value": "Token is valid."
          }
        },
        "14a9bdeef8964ce69d93fe5701aa19cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f28383ec57d45f7b3f2c148857146a9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_01355e25b7da48db9fa909c3841d6f5c",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "9f91f8d71ecb4c17a4f6435a4ccc19af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_386b39685fe64013b1cafad3d89918d3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1d2dd42df2b543338f65f83354b541aa",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "087b6d05646341a4ad3643f5fd604d5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ff12b57896f49f6a2e82167588602fc",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4ac626e0518f4bbb9c74005c0d5b2a10",
            "value": "Login successful"
          }
        },
        "c371cb058acc42b88607ab9e1af3c351": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "543240d77185406993b2add823e9c1fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f28383ec57d45f7b3f2c148857146a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01355e25b7da48db9fa909c3841d6f5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "386b39685fe64013b1cafad3d89918d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d2dd42df2b543338f65f83354b541aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ff12b57896f49f6a2e82167588602fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ac626e0518f4bbb9c74005c0d5b2a10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}